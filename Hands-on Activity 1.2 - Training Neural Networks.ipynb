{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "union-alcohol",
      "metadata": {
        "id": "union-alcohol"
      },
      "source": [
        "# Activity 1.2 : Training Neural Networks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "floppy-teens",
      "metadata": {
        "id": "floppy-teens"
      },
      "source": [
        "#### Objective(s):\n",
        "\n",
        "This activity aims to demonstrate how to train neural networks using keras"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "engaged-modem",
      "metadata": {
        "id": "engaged-modem"
      },
      "source": [
        "#### Intended Learning Outcomes (ILOs):\n",
        "* Demonstrate how to build and train neural networks\n",
        "* Demonstrate how to evaluate and plot the model using training and validation loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "structured-april",
      "metadata": {
        "id": "structured-april"
      },
      "source": [
        "#### Resources:\n",
        "* Jupyter Notebook\n",
        "\n",
        "CI Pima Diabetes Dataset\n",
        "\n",
        "* pima-indians-diabetes.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cutting-fountain",
      "metadata": {
        "id": "cutting-fountain"
      },
      "source": [
        "#### Procedures"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "entertaining-therapist",
      "metadata": {
        "id": "entertaining-therapist"
      },
      "source": [
        "Load the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "differential-native",
      "metadata": {
        "id": "differential-native"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "other-married",
      "metadata": {
        "id": "other-married"
      },
      "outputs": [],
      "source": [
        "## Import Keras objects for Deep Learning\n",
        "\n",
        "from keras.models  import Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, RMSprop"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mexican-newsletter",
      "metadata": {
        "id": "mexican-newsletter"
      },
      "source": [
        "Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_RUawXao70Mk",
        "outputId": "bbfa3f26-36fa-475a-a05b-6a2cf7a242c7"
      },
      "id": "_RUawXao70Mk",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "studied-twelve",
      "metadata": {
        "id": "studied-twelve"
      },
      "outputs": [],
      "source": [
        "filepath = \"/content/drive/MyDrive/datas/pima-indians-diabetes.csv\"\n",
        "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\",\n",
        "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
        "diabetes_df = pd.read_csv(filepath, names=names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "photographic-carnival",
      "metadata": {
        "id": "photographic-carnival"
      },
      "source": [
        "Check the top 5 samples of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "undefined-inventory",
      "metadata": {
        "id": "undefined-inventory",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "278e4b20-42ef-41e5-c3c4-9fdc01a23931"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
              "477               7                     114              76              17   \n",
              "34               10                     122              78              31   \n",
              "412               1                     143              84              23   \n",
              "405               2                     123              48              32   \n",
              "337               5                     115              76               0   \n",
              "\n",
              "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
              "477      110  23.8              0.466   31             0  \n",
              "34         0  27.6              0.512   45             0  \n",
              "412      310  42.4              1.076   22             0  \n",
              "405      165  42.1              0.520   26             0  \n",
              "337        0  31.2              0.343   44             1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-901eecc5-94ef-470e-a0d1-cf6ccb0c7b79\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>times_pregnant</th>\n",
              "      <th>glucose_tolerance_test</th>\n",
              "      <th>blood_pressure</th>\n",
              "      <th>skin_thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pedigree_function</th>\n",
              "      <th>age</th>\n",
              "      <th>has_diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>477</th>\n",
              "      <td>7</td>\n",
              "      <td>114</td>\n",
              "      <td>76</td>\n",
              "      <td>17</td>\n",
              "      <td>110</td>\n",
              "      <td>23.8</td>\n",
              "      <td>0.466</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>10</td>\n",
              "      <td>122</td>\n",
              "      <td>78</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>27.6</td>\n",
              "      <td>0.512</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>412</th>\n",
              "      <td>1</td>\n",
              "      <td>143</td>\n",
              "      <td>84</td>\n",
              "      <td>23</td>\n",
              "      <td>310</td>\n",
              "      <td>42.4</td>\n",
              "      <td>1.076</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>405</th>\n",
              "      <td>2</td>\n",
              "      <td>123</td>\n",
              "      <td>48</td>\n",
              "      <td>32</td>\n",
              "      <td>165</td>\n",
              "      <td>42.1</td>\n",
              "      <td>0.520</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>337</th>\n",
              "      <td>5</td>\n",
              "      <td>115</td>\n",
              "      <td>76</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31.2</td>\n",
              "      <td>0.343</td>\n",
              "      <td>44</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-901eecc5-94ef-470e-a0d1-cf6ccb0c7b79')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-901eecc5-94ef-470e-a0d1-cf6ccb0c7b79 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-901eecc5-94ef-470e-a0d1-cf6ccb0c7b79');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c5e3b868-7200-4d28-9212-5de20ea7d2ba\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c5e3b868-7200-4d28-9212-5de20ea7d2ba')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c5e3b868-7200-4d28-9212-5de20ea7d2ba button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "print(diabetes_df.shape)\n",
        "diabetes_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "systematic-motorcycle",
      "metadata": {
        "id": "systematic-motorcycle",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "8205b98d-24b0-48b7-99ac-a4ebd941cdff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "times_pregnant              int64\n",
              "glucose_tolerance_test      int64\n",
              "blood_pressure              int64\n",
              "skin_thickness              int64\n",
              "insulin                     int64\n",
              "bmi                       float64\n",
              "pedigree_function         float64\n",
              "age                         int64\n",
              "has_diabetes                int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "diabetes_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "collected-lafayette",
      "metadata": {
        "id": "collected-lafayette"
      },
      "outputs": [],
      "source": [
        "X = diabetes_df.iloc[:, :-1].values\n",
        "y = diabetes_df[\"has_diabetes\"].values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acquired-parallel",
      "metadata": {
        "id": "acquired-parallel"
      },
      "source": [
        "Split the data to Train, and Test (75%, 25%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "rational-hollow",
      "metadata": {
        "id": "rational-hollow"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "acceptable-equity",
      "metadata": {
        "id": "acceptable-equity",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3164b0f2-baf8-45c2-d06c-849537f25876"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3489583333333333, 0.6510416666666666)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "np.mean(y), np.mean(1-y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "thick-reconstruction",
      "metadata": {
        "id": "thick-reconstruction"
      },
      "source": [
        "Build a single hidden layer neural network using 12 nodes.\n",
        "Use the sequential model with single layer network and input shape to 8.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dramatic-zealand",
      "metadata": {
        "id": "dramatic-zealand"
      },
      "source": [
        "Normalize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "painted-mathematics",
      "metadata": {
        "id": "painted-mathematics"
      },
      "outputs": [],
      "source": [
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "previous-electricity",
      "metadata": {
        "id": "previous-electricity"
      },
      "source": [
        "Define the model:\n",
        "* Input size is 8-dimensional\n",
        "* 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
        "* Final layer with one node and sigmoid activation (standard for binary classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "found-bowling",
      "metadata": {
        "id": "found-bowling"
      },
      "outputs": [],
      "source": [
        "model  = Sequential([\n",
        "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "level-terminal",
      "metadata": {
        "id": "level-terminal"
      },
      "source": [
        "View the model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "correct-kingdom",
      "metadata": {
        "id": "correct-kingdom",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "74aa716b-2616-4e3a-c94a-1b6019664917"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 12)                108       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121 (484.00 Byte)\n",
            "Trainable params: 121 (484.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "herbal-anderson",
      "metadata": {
        "id": "herbal-anderson"
      },
      "source": [
        "Train the model\n",
        "* Compile the model with optimizer, loss function and metrics\n",
        "* Use the fit function to return the run history.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "happy-prompt",
      "metadata": {
        "id": "happy-prompt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2c04b4ea-7bf3-4573-e89b-85a52b033751"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 1s 16ms/step - loss: 0.7815 - accuracy: 0.3559 - val_loss: 0.7804 - val_accuracy: 0.4167\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7489 - accuracy: 0.4479 - val_loss: 0.7529 - val_accuracy: 0.4688\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7217 - accuracy: 0.5017 - val_loss: 0.7294 - val_accuracy: 0.5365\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6985 - accuracy: 0.5417 - val_loss: 0.7091 - val_accuracy: 0.5677\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6783 - accuracy: 0.5799 - val_loss: 0.6911 - val_accuracy: 0.5990\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6606 - accuracy: 0.6146 - val_loss: 0.6752 - val_accuracy: 0.6146\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6449 - accuracy: 0.6372 - val_loss: 0.6610 - val_accuracy: 0.6042\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6309 - accuracy: 0.6528 - val_loss: 0.6483 - val_accuracy: 0.6146\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6184 - accuracy: 0.6528 - val_loss: 0.6368 - val_accuracy: 0.6302\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6072 - accuracy: 0.6719 - val_loss: 0.6265 - val_accuracy: 0.6354\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5969 - accuracy: 0.6753 - val_loss: 0.6171 - val_accuracy: 0.6562\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5877 - accuracy: 0.6858 - val_loss: 0.6085 - val_accuracy: 0.6562\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5791 - accuracy: 0.6858 - val_loss: 0.6006 - val_accuracy: 0.6667\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5713 - accuracy: 0.6962 - val_loss: 0.5934 - val_accuracy: 0.6667\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.7049 - val_loss: 0.5868 - val_accuracy: 0.6719\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5573 - accuracy: 0.7101 - val_loss: 0.5808 - val_accuracy: 0.6823\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5511 - accuracy: 0.7170 - val_loss: 0.5753 - val_accuracy: 0.6823\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5456 - accuracy: 0.7205 - val_loss: 0.5703 - val_accuracy: 0.6927\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5403 - accuracy: 0.7222 - val_loss: 0.5656 - val_accuracy: 0.6927\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5353 - accuracy: 0.7205 - val_loss: 0.5613 - val_accuracy: 0.6927\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.7274 - val_loss: 0.5573 - val_accuracy: 0.6979\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5265 - accuracy: 0.7274 - val_loss: 0.5537 - val_accuracy: 0.7031\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7309 - val_loss: 0.5504 - val_accuracy: 0.7031\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5189 - accuracy: 0.7361 - val_loss: 0.5474 - val_accuracy: 0.7031\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7396 - val_loss: 0.5445 - val_accuracy: 0.7083\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7378 - val_loss: 0.5419 - val_accuracy: 0.7188\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.7413 - val_loss: 0.5395 - val_accuracy: 0.7188\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7431 - val_loss: 0.5373 - val_accuracy: 0.7188\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5031 - accuracy: 0.7413 - val_loss: 0.5353 - val_accuracy: 0.7292\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7431 - val_loss: 0.5334 - val_accuracy: 0.7292\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7448 - val_loss: 0.5316 - val_accuracy: 0.7292\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4957 - accuracy: 0.7431 - val_loss: 0.5300 - val_accuracy: 0.7344\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4934 - accuracy: 0.7413 - val_loss: 0.5285 - val_accuracy: 0.7344\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.7448 - val_loss: 0.5271 - val_accuracy: 0.7292\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4893 - accuracy: 0.7448 - val_loss: 0.5258 - val_accuracy: 0.7344\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.7517 - val_loss: 0.5246 - val_accuracy: 0.7396\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.7535 - val_loss: 0.5235 - val_accuracy: 0.7396\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.7535 - val_loss: 0.5224 - val_accuracy: 0.7396\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4821 - accuracy: 0.7569 - val_loss: 0.5214 - val_accuracy: 0.7396\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.7587 - val_loss: 0.5205 - val_accuracy: 0.7396\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4790 - accuracy: 0.7622 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4774 - accuracy: 0.7622 - val_loss: 0.5189 - val_accuracy: 0.7396\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4760 - accuracy: 0.7656 - val_loss: 0.5182 - val_accuracy: 0.7448\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.7656 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7639 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7656 - val_loss: 0.5162 - val_accuracy: 0.7500\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.7639 - val_loss: 0.5156 - val_accuracy: 0.7552\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7639 - val_loss: 0.5151 - val_accuracy: 0.7552\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7639 - val_loss: 0.5146 - val_accuracy: 0.7552\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7639 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.7674 - val_loss: 0.5137 - val_accuracy: 0.7500\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7656 - val_loss: 0.5133 - val_accuracy: 0.7500\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4645 - accuracy: 0.7708 - val_loss: 0.5129 - val_accuracy: 0.7500\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4636 - accuracy: 0.7674 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4627 - accuracy: 0.7691 - val_loss: 0.5122 - val_accuracy: 0.7500\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4618 - accuracy: 0.7674 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4610 - accuracy: 0.7708 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4603 - accuracy: 0.7691 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7691 - val_loss: 0.5110 - val_accuracy: 0.7552\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.7726 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4580 - accuracy: 0.7708 - val_loss: 0.5106 - val_accuracy: 0.7500\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4573 - accuracy: 0.7726 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4566 - accuracy: 0.7760 - val_loss: 0.5102 - val_accuracy: 0.7500\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.7778 - val_loss: 0.5101 - val_accuracy: 0.7500\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7778 - val_loss: 0.5099 - val_accuracy: 0.7500\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4547 - accuracy: 0.7795 - val_loss: 0.5098 - val_accuracy: 0.7500\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4542 - accuracy: 0.7760 - val_loss: 0.5097 - val_accuracy: 0.7500\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4536 - accuracy: 0.7778 - val_loss: 0.5096 - val_accuracy: 0.7500\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.7778 - val_loss: 0.5095 - val_accuracy: 0.7500\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4525 - accuracy: 0.7778 - val_loss: 0.5094 - val_accuracy: 0.7500\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4520 - accuracy: 0.7778 - val_loss: 0.5094 - val_accuracy: 0.7552\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4514 - accuracy: 0.7760 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4510 - accuracy: 0.7778 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4505 - accuracy: 0.7760 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.7760 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7778 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.7778 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4488 - accuracy: 0.7812 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.7812 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4481 - accuracy: 0.7760 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4476 - accuracy: 0.7795 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4472 - accuracy: 0.7778 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.7795 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4464 - accuracy: 0.7795 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.7795 - val_loss: 0.5092 - val_accuracy: 0.7552\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4457 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7552\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7795 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7604\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7795 - val_loss: 0.5095 - val_accuracy: 0.7604\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7795 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7795 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7778 - val_loss: 0.5097 - val_accuracy: 0.7604\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7778 - val_loss: 0.5098 - val_accuracy: 0.7604\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4430 - accuracy: 0.7760 - val_loss: 0.5099 - val_accuracy: 0.7604\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7778 - val_loss: 0.5099 - val_accuracy: 0.7604\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7778 - val_loss: 0.5100 - val_accuracy: 0.7552\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7778 - val_loss: 0.5101 - val_accuracy: 0.7552\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4421 - accuracy: 0.7778 - val_loss: 0.5102 - val_accuracy: 0.7552\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4418 - accuracy: 0.7778 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7795 - val_loss: 0.5103 - val_accuracy: 0.7552\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7795 - val_loss: 0.5104 - val_accuracy: 0.7552\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7795 - val_loss: 0.5105 - val_accuracy: 0.7552\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7795 - val_loss: 0.5106 - val_accuracy: 0.7552\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.7795 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.7795 - val_loss: 0.5107 - val_accuracy: 0.7552\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7795 - val_loss: 0.5108 - val_accuracy: 0.7552\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7795 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7778 - val_loss: 0.5109 - val_accuracy: 0.7552\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7778 - val_loss: 0.5110 - val_accuracy: 0.7552\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.7778 - val_loss: 0.5111 - val_accuracy: 0.7552\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7778 - val_loss: 0.5112 - val_accuracy: 0.7552\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7778 - val_loss: 0.5112 - val_accuracy: 0.7552\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7795 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7795 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4385 - accuracy: 0.7795 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7795 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7795 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7812 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7795 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7795 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7760 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7778 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.7760 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.7778 - val_loss: 0.5122 - val_accuracy: 0.7552\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.7778 - val_loss: 0.5123 - val_accuracy: 0.7500\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.7795 - val_loss: 0.5124 - val_accuracy: 0.7500\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7795 - val_loss: 0.5125 - val_accuracy: 0.7500\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7778 - val_loss: 0.5126 - val_accuracy: 0.7500\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7830 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7795 - val_loss: 0.5127 - val_accuracy: 0.7500\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7795 - val_loss: 0.5128 - val_accuracy: 0.7500\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7812 - val_loss: 0.5129 - val_accuracy: 0.7500\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7812 - val_loss: 0.5130 - val_accuracy: 0.7500\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7812 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7812 - val_loss: 0.5131 - val_accuracy: 0.7448\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7795 - val_loss: 0.5133 - val_accuracy: 0.7448\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7847 - val_loss: 0.5134 - val_accuracy: 0.7448\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7812 - val_loss: 0.5135 - val_accuracy: 0.7448\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4349 - accuracy: 0.7830 - val_loss: 0.5136 - val_accuracy: 0.7448\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7795 - val_loss: 0.5137 - val_accuracy: 0.7448\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7830 - val_loss: 0.5138 - val_accuracy: 0.7448\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4345 - accuracy: 0.7899 - val_loss: 0.5139 - val_accuracy: 0.7448\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7865 - val_loss: 0.5140 - val_accuracy: 0.7448\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7865 - val_loss: 0.5141 - val_accuracy: 0.7448\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7865 - val_loss: 0.5142 - val_accuracy: 0.7448\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7882 - val_loss: 0.5143 - val_accuracy: 0.7448\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7865 - val_loss: 0.5145 - val_accuracy: 0.7448\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7882 - val_loss: 0.5146 - val_accuracy: 0.7448\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7865 - val_loss: 0.5147 - val_accuracy: 0.7448\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7882 - val_loss: 0.5148 - val_accuracy: 0.7396\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4332 - accuracy: 0.7865 - val_loss: 0.5149 - val_accuracy: 0.7396\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7882 - val_loss: 0.5150 - val_accuracy: 0.7396\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7847 - val_loss: 0.5151 - val_accuracy: 0.7396\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7899 - val_loss: 0.5152 - val_accuracy: 0.7396\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4328 - accuracy: 0.7899 - val_loss: 0.5153 - val_accuracy: 0.7396\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7899 - val_loss: 0.5154 - val_accuracy: 0.7396\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7882 - val_loss: 0.5156 - val_accuracy: 0.7396\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7917 - val_loss: 0.5157 - val_accuracy: 0.7396\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7899 - val_loss: 0.5158 - val_accuracy: 0.7396\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7899 - val_loss: 0.5159 - val_accuracy: 0.7396\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7899 - val_loss: 0.5160 - val_accuracy: 0.7396\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7917 - val_loss: 0.5161 - val_accuracy: 0.7396\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7899 - val_loss: 0.5162 - val_accuracy: 0.7396\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7882 - val_loss: 0.5163 - val_accuracy: 0.7396\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7882 - val_loss: 0.5163 - val_accuracy: 0.7396\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7899 - val_loss: 0.5164 - val_accuracy: 0.7448\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7882 - val_loss: 0.5165 - val_accuracy: 0.7448\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7899 - val_loss: 0.5166 - val_accuracy: 0.7448\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7899 - val_loss: 0.5166 - val_accuracy: 0.7448\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7899 - val_loss: 0.5167 - val_accuracy: 0.7448\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7899 - val_loss: 0.5168 - val_accuracy: 0.7448\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7882 - val_loss: 0.5169 - val_accuracy: 0.7448\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7899 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7917 - val_loss: 0.5170 - val_accuracy: 0.7448\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7917 - val_loss: 0.5171 - val_accuracy: 0.7448\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7917 - val_loss: 0.5172 - val_accuracy: 0.7448\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.7899 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.7899 - val_loss: 0.5173 - val_accuracy: 0.7500\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7917 - val_loss: 0.5174 - val_accuracy: 0.7500\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7917 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7899 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7917 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.7917 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7917 - val_loss: 0.5177 - val_accuracy: 0.7500\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7917 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7917 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7917 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7934 - val_loss: 0.5179 - val_accuracy: 0.7500\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7934 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.7917 - val_loss: 0.5180 - val_accuracy: 0.7500\n"
          ]
        }
      ],
      "source": [
        "model.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_1 = model.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "unsigned-nevada",
      "metadata": {
        "id": "unsigned-nevada",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "42b14928-fad4-4e38-900c-88d5f38fad15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n",
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "## Like we did for the Random Forest, we generate two kinds of predictions\n",
        "#  One is a hard decision, the other is a probabilitistic score.\n",
        "\n",
        "y_pred_class_nn_1 = (model.predict(X_test_norm) > 0.5).astype(\"int32\")\n",
        "y_pred_prob_nn_1 = model.predict(X_test_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "tough-catering",
      "metadata": {
        "id": "tough-catering",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f39bf02a-5d9d-438f-b4c9-ea115a2c17c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Let's check out the outputs to get a feel for how keras apis work.\n",
        "y_pred_class_nn_1[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "combined-zimbabwe",
      "metadata": {
        "id": "combined-zimbabwe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "9746bf57-9666-4f12-c7c1-5a9038bd0dde"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.37785643],\n",
              "       [0.72676945],\n",
              "       [0.24304809],\n",
              "       [0.16212945],\n",
              "       [0.19512816],\n",
              "       [0.50516886],\n",
              "       [0.02240266],\n",
              "       [0.18402979],\n",
              "       [0.9177369 ],\n",
              "       [0.15036944]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "y_pred_prob_nn_1[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "going-estonia",
      "metadata": {
        "id": "going-estonia"
      },
      "source": [
        "Create the plot_roc function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "supposed-moderator",
      "metadata": {
        "id": "supposed-moderator"
      },
      "outputs": [],
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "second-festival",
      "metadata": {
        "id": "second-festival"
      },
      "source": [
        "Evaluate the model performance and plot the ROC CURVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "eleven-nebraska",
      "metadata": {
        "id": "eleven-nebraska",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "outputId": "eba5f2c6-a6aa-4822-ffc8-983812a5e0a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.750\n",
            "roc-auc is 0.809\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqQAAAKTCAYAAADPORq8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABUUUlEQVR4nO3de1xUdeL/8TcgF0HJyrtZZltq2Vpq+jNss74q7Zblt23FS2rmrdS0KE2tNDXDMs0umJckKxUw18wtViXKLRfK8tJaaaVWXkHNCzojMDDn90crXy+gDMzMmTnn9Xw8eDyc41ze+AF58/mc85kQwzAMAQAAACYJNTsAAAAA7I1CCgAAAFNRSAEAAGAqCikAAABMRSEFAACAqSikAAAAMBWFFAAAAKaqZnaAinC73dq3b59q1qypkJAQs+MAAADgLIZh6Pjx42rYsKFCQz2b8wyKQrpv3z41btzY7BgAAAC4gN27d+uyyy7z6DFBUUhr1qwp6fdPMDY2tvS4y+XSmjVr1LVrV4WHh5sVDz7EGNsD42wPjLP1Mcb2UN445+fnq3HjxqW9zRNBUUhPLdPHxsaeU0ijo6MVGxvLF75FMcb2wDjbA+NsfYyxPVxonCtzeqXHFzV99tln6tatmxo2bKiQkBCtWLHigo9Zu3atWrdurcjISP3hD3/QwoULPQ4KAAAAa/J4htThcKhVq1Z68MEHde+9917w/j///LPuvPNOPfTQQ1q8eLGysrI0aNAgNWjQQPHx8ZUKDQAAYHeGYcjpdPr9dV0ulwoKCmQYhtee0+NC+uc//1l//vOfK3z/OXPm6Morr9SMGTMkSS1atNC6dev08ssvl1tICwsLVVhYWHo7Pz9f0u//AC6Xq/T4qT+ffgzWwhjbA+NsD4yz9THG/mMYhjp16qScnBzTMhw4cEC1atUqvV2Vcff5OaQ5OTnq3LnzGcfi4+P16KOPlvuYpKQkTZo06Zzja9asUXR09DnHMzMzq5wTgY0xtgfG2R4YZ+tjjH2voKDA1DIqSZ988omioqJKb1dlttbnhTQ3N1f16tU741i9evWUn5+vkydPqnr16uc8Zty4cUpMTCy9feqqra5du55zUVNmZqa6dOnCydMWxRjbA+NsD4yz9THG/uNwOEr/vGfPHsXExPj8Nbdv367ExEQlJyfr+++/11133aWIiIjSvz+1ol0ZAXmVfWRkpCIjI885Hh4eXuYXeHnHYR2MsT0wzvbAOFsfY+x7p//71qpVy+eF1DAM7du3T+np6apdu7Z27typiIiIM3JUZcx9/tah9evXV15e3hnH8vLyFBsbW+bsKAAAAALHtm3b1KdPH919991q0KCBT17D5zOkHTp0UEZGxhnHMjMz1aFDB1+/NAAAAKpg//79Gj58uBYvXuzT1/F4hvTEiRPavHmzNm/eLOn3bZ02b96sXbt2Sfr9/M9+/fqV3v+hhx7Szp07NWbMGG3btk2zZ8/W0qVL9dhjj3nnMwAAAIDX/fDDD4qMjNTy5ctVv359n76Wx4X066+/1o033qgbb7xRkpSYmKgbb7xREyZMkPR7kz5VTiXpyiuv1EcffaTMzEy1atVKM2bM0JtvvskepAAAAAHqu+++0/Dhw1VcXKyLLrrI56/n8ZJ9p06dzrsRalnvwtSpUydt2rTJ05cCAACAzt0E//Sr7H1h6dKlWrJkierWrevT1zklIK+yBwAAwO8Mw1DHjh2VnZ3t89fasmWLMjMzy9wP3pcopAAAAAHM6XSWW0bj4uLKfNOgytiyZYsSExOVmprqlefzBIUUAAAgSOTl5Z2x52h0dLRCQkKq/LyHDh1SrVq1lJqaqtq1a1f5+Tzl831IAQAA4B0xMTFnfHijjG7evFm9evVS3bp1TSmjEoUUAADAtoqKijRlyhSlp6eX+S6Z/sKSPQAAgA1t3LhRDodDy5Yt88pMa1UwQwoAAGAzGzZs0NixY9WyZUvTy6jEDCkAAICtuN1u7dmzR0uXLlWtWrXMjiOJQgoAACzk7A3krcCbm+B/9dVXmj17tt566y2vPac3UEgBAIAl+HMD+WC0c+dOPfPMM0pPTzc7yjk4hxQAAFjC+TaQt4KqbIK/adMmXXLJJfr73//ul/em9xQzpAAAwHLO3kDeCiq7CX5OTo4mT56s9PT0gP03oZACAADLObVxPKRVq1YpPT1dsbGxZkcpF4UUAADAgrKzs7Vx40ZNmjTJ7CgXRCEFAACwmJycHE2dOlVpaWlmR6kQCikAAICF5ObmqmHDhkpPT1eNGjXMjlMhXGUPAABgEZ999pkGDx6sRo0aBU0ZlZghBQDAI1bceN1bXC6XCgoK5HA4FB4e7vfX9+YG8sHI4XAoOTlZaWlpqlYtuCpecKUFAMBEbLyOQLV27VpFR0cH5Kb3FcGSPQAAFWT1jdetoiobyAejTz/9VDNnzlTLli3NjlJpzJACAFAJVtx4vapcLpdWr16t+Ph4U5bsT6nsBvLBqLi4WMePH1daWlpQl3AKKQAAlcDG6+dyuVyKiopSTEyMqYXULj7++GMtX75cs2fPNjtKlVFIAQAAgsy3336r119/XampqWZH8QrOIQUAAAgi2dnZuvzyy5WWlqbq1aubHccrKKQAAABBYvXq1XrppZcUERGhqKgos+N4DUv2AIByeXPPTbP3qPQGu+9zCXMZhqGcnBwtWbLEUmVUopACAMrBnptA4MjIyNC+ffv07LPPmh3FJyikAIAysedm+ey2zyXMtXr1ar311ltatGiR2VF8hkIKALggb+y5GSh7VHqDnfa5hLl2796tFi1aaNGiRYqMjDQ7js9QSAEAF+SNPTfZoxLwzMqVK7VkyRKlpqZa/hcgrrIHAAAIMIcPH9by5cv1zjvvWL6MSsyQAgAABJQVK1boyiuv1MKFC82O4jfMkAIAAASI5cuXKz09Xddee63ZUfyKQgoAABAAioqKFBERoXfeecd251mzZA8AkHTuJvhsAg/4z7Jly/Tll19q+vTpZkcxBYUUAMAm+ICJvvjiC61YscJW54yejSV7AMB5N8FnE3jAdz7++GNdd911WrhwoapVs+88oX0/cwBAmc7eBJ9N4AHfSE1N1T//+U916tTJ1mVUopACAM7ijU3wAZxfSUmJfv75Z6WkpNi+jEoUUgAAAL9avHixQkJCNH78eLOjBAzOIQUAAPCT9PR0ZWVlKSEhwewoAYUZUgAAAD/YuXOn4uLidN999yksLMzsOAGFGVIAAAAfW7hwoaZNm6bLLruMMloGZkgBIAicvWm9t7EJPuA7+/fv11dffaU5c+aYHSVgUUgBIMCxaT0QvN5++2116NBBycnJZkcJaCzZA0CAO9+m9d7GJviA97z55pvKycnRH/7wB7OjBDxmSAEgiJy9ab23sQk+4B0FBQW67LLL9OCDDyo0lPm/C6GQAkAQYdN6IPDNnTtXeXl5mjBhgtlRggaFFAAAwEsyMzO1ZcsWvfbaa2ZHCSoUUgAAAC/44IMP1KVLF3Xu3JlTXzzESQ0AAABVlJycrE8++UTVq1enjFYChRQAAKAKioqKVFBQoFmzZlFGK4klewDwAW9uZM+m9UDgeuWVV9SkSRM9/vjjZkcJahRSAPAyNrIH7GHu3LnatWuXRo4caXaUoEchBQAv89VG9mxaDwSObdu2qVu3bmrQoAHL9F5AIQUAH/LmRvZsWg8EhhkzZujgwYOaNm2a2VEsg0IKAD7ERvaAtezYsUOHDx9WUlKS2VEshavsAQAAKmDWrFmKiIjQ1KlTWa3wMmZIAQAALmDatGk6fvy4LrvsMrOjWBKFFAAA4DwcDofat2+vTp06MTPqIxRSAACAcjz33HOKjY1laycf4xxSAACAMixbtkwul0uPPPKI2VEsjxlSAACAs6Smpuqvf/2r7rvvPrOj2AKFFAAA4DTPPvusQkNDFRERYXYU26CQAgAA6Pe3/XU6nWrQoIGGDh1qdhxb4RxSAABge4ZhaMKECVq/fj1l1AQUUgAAYHvTpk1TdHS0brvtNrOj2BJL9gAAwLYMw9CWLVs0aNAg1alTx+w4tsUMKQAAsCXDMDRu3DitXr2aMmoyZkgB2NKpixd8weFw+OR5AXjXli1bVKdOHT3++ONmR7E9CikA2zEMQx07dlR2drbZUQCYwDAMTZ48WcOGDaOMBgiW7AHYjtPp9EsZjYuLU3R0tM9fB0DFGYah0aNHKzY2lmX6AMIMKQBby8vLU0xMjE+eOzo6WiEhIT55bgCeMwxDx48f17333qubb77Z7Dg4DYUUgK3FxMT4rJACCByGYSgxMVGtW7dW3759zY6Ds7BkDwAALO+tt95S06ZNKaMBihlSAABgWYZhKCUlRQ888IDCwsLMjoNyMEMKAAAsyTAMjRw5UkVFRZTRAMcMKQAAsBzDMHTs2DF16NBBvXv3NjsOLoBCCqDKqrrJvMvlUkFBgRwOh8LDw72YrGxsXA9Ym9vt1ogRI/Tggw9SRoMEhRRAlbDJPIBAM3bsWN14441q27at2VFQQRRSAFXir03mfYGN6wFrcbvd2rhxo8aOHatLLrnE7DjwAIUUgNdUdpN5l8ul1atXKz4+3i9L9qewcT1gHW63Ww899JA6dOjAzGgQopAC8JrKbjLvcrkUFRWlmJgYvxZSANbx5ZdfqkOHDhowYIDZUVAJbPsEAACCVklJiZ544gldd911lNEgRiEFAABBye12a8iQIWrVqpViY2PNjoMqYMkeAAAEnZKSEh0/flzDhg1TmzZtzI6DKmKGFAAABJWSkhINHDhQn3/+OWXUIiikAAAgqLz++uvq2rWrunXrZnYUeAlL9gAAICgUFxdr/vz5GjlyJFu2WQwzpAAAIOAVFxdrwIABuuSSSyijFsQMKQAACGhut1tHjhxRjx49WKa3KGZIAQBAwHK5XOrbt69+++03yqiFUUgBAEDAeuSRR3TvvfeqefPmZkeBD7FkDwAAAo7L5dLGjRv14osvsum9DTBDCgAAAkpRUZHuv/9+7d+/nzJqE8yQAvCIYRhyOp2ltx0Oh4lpAFjR559/rt69e+uee+4xOwr8hEIKoMIMw1DHjh2VnZ1tdhQAFlRUVKTHHntMM2bMUFRUlNlx4Ecs2QOoMKfTWW4ZjYuLU3R0tJ8TAbAKl8ul+++/X3/+858pozbEDCmASsnLy1NMTEzp7ejoaDarBlAphYWFcjqdmjBhglq2bGl2HJiAGVIAlRITE3PGB2UUQGUUFBSod+/e+uabbyijNkYhBQAApnn55Zc1aNAgderUyewoMBFL9gAAwO8KCgq0YMECjR07lhUWMEMKAAD8q6CgQL169dLVV19NGYUkZkgBAIAflZSU6PDhwxo5cqRuu+02s+MgQFBIAYs7eyP7qmATfABV4XQ61atXL7322muUUZyBQgpYGBvZAwgkQ4YM0ahRo3T55ZebHQUBhkIKWNj5NrKvCjbBB+AJp9OpzZs3a+7cuWfsXwycQiEFbOLsjeyrgk3wAVSUw+FQz5499cQTT1BGUS4KKWATpzawBwB/+vTTT/XEE0/o1ltvNTsKAliltn1KTk5WkyZNFBUVpfbt22v9+vXnvf+sWbPUrFkzVa9eXY0bN9Zjjz2mgoKCSgUGAACB78SJExo8eLDuuOMOyiguyONCmp6ersTERE2cOFEbN25Uq1atFB8frwMHDpR5/yVLlmjs2LGaOHGitm7dqgULFig9PV3jx4+vcngAABB4Tp48qZ49e6p///6qVo3FWFyYx4V05syZGjx4sAYMGKBrr71Wc+bMUXR0tFJSUsq8f3Z2tuLi4tS7d281adJEXbt2Va9evS44qwoAAILPyZMnVVhYqJkzZ6pjx45mx0GQ8OjXlqKiIm3YsEHjxo0rPRYaGqrOnTsrJyenzMfcfPPNWrRokdavX6927dpp586dysjIUN++fct9ncLCQhUWFpbezs/PlyS5XC65XK7S46f+fPoxWAtjXDVnf78E6r8j42wPjLP1HT58WNOnT1fjxo3Vrl07xtqiyvtersp4e1RIDx06pJKSEtWrV++M4/Xq1dO2bdvKfEzv3r116NAhdezYUYZhqLi4WA899NB5l+yTkpI0adKkc46vWbOmzK1mMjMzPfk0EIQY49/3FD39F7WKOP1c7dWrVysqKsrbsbyKcbYHxtm6UlNT1aNHDx06dEgZGRlmx4GPnf29XJU3YfH5iR1r167V888/r9mzZ6t9+/bavn27Ro0apSlTpuiZZ54p8zHjxo1TYmJi6e38/Hw1btxYXbt2VWxsbOlxl8ulzMxMdenSReHh4b7+VGACxvh3hmGoU6dO5a5EVER8fHzAXmXPONsD42xdx44d06JFi5SSksIY20B538unVrQrw6NCWrt2bYWFhSkvL++M43l5eapfv36Zj3nmmWfUt29fDRo0SJJ0/fXXy+FwaMiQIXrqqacUGnruaayRkZGKjIw853h4eHiZX+DlHYd12H2MHQ5HlcpoXFycLrroooDfO9Tu42wXjLO1HDt2TPfff78mT55cOq6MsT2cPc5VGXOPCmlERITatGmjrKwsde/eXZLkdruVlZWlESNGlPkYp9N5TukMCwuT9PusDwDPVGaDezayB+ALLpdLR48e1XPPPae2bdtyzigqzeMl+8TERPXv319t27ZVu3btNGvWLDkcDg0YMECS1K9fPzVq1EhJSUmSpG7dumnmzJm68cYbS5fsn3nmGXXr1q20mAKoODa4BxAIjh49qoSEBC1atEht27Y1Ow6CnMeFNCEhQQcPHtSECROUm5urG264QatWrSq90GnXrl1nzIg+/fTTCgkJ0dNPP629e/eqTp066tatm6ZOneq9zwIAAPiNYRh68MEHNXXqVNWpU8fsOLCASl3UNGLEiHKX6NeuXXvmC1SrpokTJ2rixImVeSkAABBAjhw5oq1bt2rJkiUBv3MHgkel3joUAADYz+HDh5WQkKCoqCjKKLyK9/MCAAAVsnbtWr3wwgu68cYbzY4Ci6GQAgHIMIwzNhh2OBwmpgFgd7/99ptGjx6tBQsWsGMHfIIleyDAGIahjh07qkaNGqUfZ787GgD4y7Fjx9SzZ089+uijlFH4DDOkQIBxOp3Kzs4u8+/i4uLKfPtcAPCFQ4cOKTw8XG+++aauuOIKs+PAwpghBQJYXl6eTpw4Ufrx+eefM0MBwC8OHjyonj17av/+/ZRR+BwzpEAAYxN8AGZ5+eWXNWvWLDVv3tzsKLABCikAACh14MABLV26VM8//7zZUWAjLNkDAABJv58m1KtXL91+++1mR4HNMEMKAABUWFioEydO6PXXX1eLFi3MjgObYYYUAACb279/v+68807VqVOHMgpTUEgBALAxt9utwYMHKzk5WbGxsWbHgU2xZA8AgE3t27dPv/76q5YvX66IiAiz48DGmCEFAMCG9u7dq/vvv1+1a9emjMJ0FFIAAGxo3bp1mjt3rq6++mqzowAUUgAA7GTPnj0aOHCgevToQRlFwOAcUgAAbOLAgQPq16+f5s+fz9sQI6BQSAEAsIE9e/YoNjZWixcvVoMGDcyOA5yBJXsAACzu119/Vb9+/XT06FHKKAIShRQAAIt7/fXXlZKSossvv9zsKECZWLIHAMCifvnlF2VkZGj69OlmRwHOixlSAAAs6Oeff9aDDz6ou+66y+wowAVRSAEAsBin06mioiItXLiQZXoEBQopAAAWsmPHDt1999264oorKKMIGhRSAAAswuVy6ZFHHtHChQsVFRVldhygwrioCQAAC/jpp5905MgRrVy5UtWq8eMdwYUZUgAAgtxPP/2koUOHqlGjRpRRBCW+agEACGKGYeirr77SokWL1LBhQ7PjAJVCIQUAIEj98MMPmjFjhubNm2d2FKBKKKQAAAShXbt2adiwYVq8eLHZUYAq4xxSAACCzI4dO3TxxRdr6dKlql+/vtlxgCqjkAIAEES+//57DRkyRAUFBbr00kvNjgN4BYUUAIAgsmDBAqWmpqpOnTpmRwG8hnNIAQAIAt9++61ycnI0Y8YMs6MAXscMKQAAAW7Lli169NFH1b17d7OjAD7BDCkAAAHs+PHjqlatmtLS0lS7dm2z4wA+wQwpAAAB6ptvvtF9992nq6++mjIKS6OQAgAQgJxOp8aPH68lS5bwdqCwPL7CAQAIMJs2bZIk/eMf/1BoKHNHsD6+ygEACCAbN27Uk08+qSuuuIIyCttghhQAgABhGIa+//57paen6+KLLzY7DuA3FFIAAALA119/rbfeekvJyclmRwH8jkIKAIDJtm3bpqeeekrp6elmRwFMwckpAACY6LvvvlOjRo303nvvqVatWmbHAUxBIQUAwCRffvmlnnjiCRmGodjYWLPjAKZhyR7wAsMw5HQ6vfJcDofDK88DILAZhqH09HSlp6dTRmF7FFKgigzDUMeOHZWdnW12FABBIicnRz/88INmzpxpdhQgILBkD1SR0+n0SRmNi4tTdHS0158XgLmys7M1ZcoU/fWvfzU7ChAwmCEFvCgvL08xMTFeea7o6GiFhIR45bkABIYjR46oVq1aSk9PV82aNc2OAwQMCingRTExMV4rpACs5fPPP9dLL72k999/n3dgAs7CdwQAAD529OhRzZw5U4sXL6aMAmVghhQAAB/617/+pdq1a2v58uWchgOUg1/TAADwkbVr1+qll15SkyZNKKPAeTBDCgCAD7jdbu3du1fp6ensmAFcAIUUQcubm9FXBRvZAzhbVlaWMjIyNGPGDLOjAEGBQoqgxGb0AALVhg0b9OqrryotLc3sKEDQ4BxSBCVfbUZfFWxkD+Drr79Ws2bNlJaWpurVq5sdBwgazJAi6HlzM/qqYCN7wN5Wr16tOXPmKDU1VVFRUWbHAYIKhRRBj83oAZjN7Xbr448/powClUQhBQCgClatWqWjR49q+vTpZkcBghbnkAIAUEn//Oc/9eabb+p///d/zY4CBDUKKQAAlXDw4EE1adJEixcvVmRkpNlxgKBGIQUAwEP/+Mc/NGrUKDVv3pwyCngB55Ai4Jy+4b3L5VJBQYEcDofCw8NL78Nm9ADMkpubq9TUVC1cuJCdNQAvoZAioLDhPYBA9uGHH6p58+ZavHgxZRTwIpbsEVA83fCezegB+Mv777+vRYsW6YorrqCMAl7GDCkCVl5eniIiIrR69WrFx8efsWR/CpvRA/CHkpISFRQU6N133y3z/yIAVUMhRcCKiYlRRESEoqKiFBMTww8BAKb4+9//rs2bN2vKlClmRwEsi0IKAEA5/vWvf2n58uVauHCh2VEAS6OQAgBQhnXr1qlNmzZ6++23Va0aPy4BX+KiJgAAzpKenq558+YpKiqKMgr4AYUUAIDTuFwu/ec//1FKSgplFPATvtMAAPivJUuWqEaNGpo6darZUQBbYYYUAABJqampyszM1J133ml2FMB2mCEFANjevn371Lp1a/Xo0UNhYWFmxwFsh0IKALC1d955R9nZ2ZozZ47ZUQDbopACAGzr559/1r///W/Nnj3b7CiArXEOKQDAlhYvXqxq1app7ty5LNMDJqOQAgBsJyUlRZ9//rkaNWpkdhQAopACAGymuLhYsbGxmj17tkJD+TEIBALOIYVfGYYhp9NZ7t87HA4/pgFgN/PmzdPRo0c1ZswYs6MAOA2FFH5jGIY6duyo7Oxss6MAsKF//OMf+uabb/Taa6+ZHQXAWSik8Bun01nhMhoXF6fo6GgVFxf7OBUAO8jMzNTtt9+uO++8k2V6IABRSGGKvLw8xcTElPv30dHRCgkJ8WMiAFY1e/Zsbd26VZ07d+b/FSBAUUhhipiYmPMWUgDwBqfTqSNHjujVV1+ljAIBjEIKALCk119/XS1atNBTTz1ldhQAF8CJNAAAy5k9e7Z27typ22+/3ewoACqAGVIAgKXs2rVL8fHxevjhh1mmB4IEM6QAAMt4+eWXNWfOHF111VWUUSCIMEMKALCEb7/9Vnl5eUpKSjI7CgAPMUMKAAh6b7zxhurWratp06YxMwoEIWZIAQBB7cUXX9SRI0dUp04ds6MAqCQKKQAgaBUWFqp58+bq1q0bM6NAEKOQAgCC0vPPP69LL71UQ4cONTsKgCriHFIAQNB59913VVBQoCFDhpgdBYAXMEMKAAgqK1eu1N/+9jdFRkayTA9YBDOkAICgMXnyZG3atElRUVGUUcBCmCEFAASFo0eP6qKLLtKoUaPMjgLAy5ghBQAENMMw9Oyzz+rHH3+kjAIWRSEFAAS0qVOnKjw8XO3atTM7CgAfYckeABCQDMPQjh071K9fP11++eVmxwHgQ8yQAgACjmEYeuqpp/TBBx9QRgEboJACAALOl19+qVq1aunxxx83OwoAP6CQAgAChmEYmjZtmlq0aKExY8aYHQeAn1BIAQABwTAMPfnkk4qIiNBFF11kdhwAfsRFTQAA0xmGoZMnT6pz587q2rWr2XEA+BmFFABgKsMw9Pjjj6t9+/ZKSEgwOw4AE1BI4RWGYcjpdJ73Pg6Hw09pAAST5ORkNWnShDIK2BiFFFVmGIY6duyo7Oxss6MACCKGYei9997TQw89pGrV+HEE2BkXNaHKnE6nR2U0Li5O0dHRPkwEINAZhqFRo0bp4MGDlFEAlSukp5ZXoqKi1L59e61fv/689z969KiGDx+uBg0aKDIyUtdcc40yMjIqFRiBLS8vTydOnDjvx+eff66QkBCzowIw0YEDB3TjjTdq+PDhZkcBEAA8/rU0PT1diYmJmjNnjtq3b69Zs2YpPj5eP/zwg+rWrXvO/YuKitSlSxfVrVtXy5YtU6NGjfTrr7+qVq1a3siPABMTE6OYmBizYwAIUG63W48++qiGDx+uAQMGmB0HQIDwuJDOnDlTgwcPLv2PZM6cOfroo4+UkpKisWPHnnP/lJQUHT58WNnZ2QoPD5ckNWnSpGqpAQBBaeHChbrjjjt07bXXmh0FQADxqJAWFRVpw4YNGjduXOmx0NBQde7cWTk5OWU+ZuXKlerQoYOGDx+uDz74QHXq1FHv3r315JNPKiwsrMzHFBYWqrCwsPR2fn6+JMnlcsnlcpUeP/Xn04/B/84eE2+OB2NsD4yz9bndbn3//ffq3r27EhISGGuL4nvZHsob56qMu0eF9NChQyopKVG9evXOOF6vXj1t27atzMfs3LlTn3zyifr06aOMjAxt375dw4YNk8vl0sSJE8t8TFJSkiZNmnTO8TVr1pR5MUxmZqYnnwa8rKCgoPTPq1evVlRUlNdfgzG2B8bZmtxut+bOnatrrrlG//M//8M42wBjbA9nj/OFtn88nxDDMIyK3nnfvn1q1KiRsrOz1aFDh9LjY8aM0b/+9S99+eWX5zzmmmuuUUFBgX7++efSGdGZM2dq+vTp2r9/f5mvU9YMaePGjXXo0CHFxsaWHne5XMrMzFSXLl1KTweAd1V0f9HLLrtMknTkyBGvnkPKGNsD42xtWVlZ2r17t/r06cM4Wxzfy/ZQ3jjn5+erdu3aOnbs2Bl9rSI8miGtXbu2wsLClJeXd8bxvLw81a9fv8zHNGjQQOHh4Wcsz7do0UK5ubkqKipSRETEOY+JjIxUZGTkOcfDw8PL/AIv7ziqpjL7i/pqLBhje2CcrcXtdmvixIkaP368qlevXrqcxzhbH2NsD2ePc1XG3KNtnyIiItSmTRtlZWWVHnO73crKyjpjxvR0cXFx2r59u9xud+mxH3/8UQ0aNCizjCJwsL8ogMoqKSnRkCFD9Ic//EHVq1c3Ow6AAOfxVfaJiYnq37+/2rZtq3bt2mnWrFlyOBylV93369dPjRo1UlJSkiTp4Ycf1uuvv65Ro0bpkUce0U8//aTnn39eI0eO9O5nAp/Ky8u74FJ8dHQ0+4sCUElJiU6ePKn+/fvrlltuMTsOgCDgcSFNSEjQwYMHNWHCBOXm5uqGG27QqlWrSi902rVrl0JD/2/itXHjxlq9erUee+wx/fGPf1SjRo00atQoPfnkk977LOBz7C8KoCJKSko0aNAgJSQk6I477jA7DoAgUan3axsxYoRGjBhR5t+tXbv2nGMdOnTQF198UZmXAgAEkRdffFGdO3emjALwCG8gDACosuLiYqWnp2vMmDHl7jENAOWp1HvZAwBwSnFxsR588EGFhYVRRgFUCjOkAIBKMwxD+/fv1z333KO//vWvZscBEKSYIQUAVEpxcbH69+8vt9tNGQVQJRRSAEClDB06VHfffbeuuOIKs6MACHIs2QMAPOJyufTjjz9q2rRpqlOnjtlxAFgAM6QAgApzuVzq16+ffvrpJ8ooAK+hkAIAKiwjI0MJCQnq3r272VEAWAhL9gCACyoqKtL48eM1bdo0VavGjw4A3sUMKQDgvIqKinT//ffr1ltvpYwC8An+ZwEAlKuwsFBFRUUaPXq0brrpJrPjALAoZkgBAGUqLCxUnz599J///IcyCsCnmCFFKcMw5HQ6S287HA4T0wAw25QpU/Tggw8qLi7O7CgALI5CCkm/l9GOHTsqOzvb7CgATFZQUKD09HRNmTJFISEhZscBYAMs2UOS5HQ6yy2jcXFxio6O9nMiAGYoKChQr169VL9+fcooAL9hhhTnyMvLU0xMTOnt6OhofjABNmAYhvbs2aNhw4apS5cuZscBYCPMkOIcMTExZ3xQRgHrO3nypO677z7FxsZSRgH4HYUUAGzOMAz1799fw4YNU926dc2OA8CGWLIHABtzOp3asWOH5s2bp1q1apkdB4BNMUMKADblcDiUkJCgQ4cOUUYBmIoZUgCwqX/84x96/PHH1alTJ7OjALA5CqkNnL3hfVnYBB+wD4fDoaeeekozZ85UaCgLZQDMRyG1ODa8B3C6U8v0Tz75JGUUQMCgkFrc+Ta8Lwub4APWdeLECUlSUlKSrr/+epPTAMD/oZDayNkb3peFTfABazp+/LgSEhKUlJSkVq1amR0HAM5AIbWRUxvdA7CfSZMm6emnn6aMAghIFFIAsLD8/HwtX75c06dPZ/UDQMDijHYAsKhjx46pR48eat68OWUUQEBjhhQALMjtdmvv3r2aNGmS2rdvb3YcADgvZkgBwGKOHj2qbt26qVGjRpRRAEGBQgoAFuJ2u3X//ffr2Wef1UUXXWR2HACoEJbsAcAijhw5ot27dys1NVU1a9Y0Ow4AVBgzpABgAUeOHFFCQoKKi4spowCCDoUUACxg5cqVmjZtmlq3bm12FADwGEv2ABDEDh8+rGeffVavvPIKWzsBCFrMkAJAkDpy5Ih69uypgQMHUkYBBDVmSAEgCB0+fFjh4eFKTk7W1VdfbXYcAKgSZkgBIMgcOnRIPXr0UG5uLmUUgCVQSAEgyEyaNEkvv/wyZRSAZbBkDwBB4sCBA8rIyNCrr77KOaMALIUZUgAIAgcOHFCvXr3Url07yigAy6GQAkCAKy4u1v79+/Xaa6/p2muvNTsOAHgdhRQAAlhubq7uvPNOXXPNNZRRAJZFIQWAAOVyudS/f3+98sorql69utlxAMBnuKgJAALQ/v379dtvv+n9999XdHS02XEAwKeYIQWAALNv3z716dNHERERlFEAtsAMKQAEmIyMDM2dO5d9RgHYBoU0SBiGIafT6fHjHA6HD9IA8IW9e/fqxRdf1CuvvGJ2FADwKwppEDAMQx07dlR2drbZUQD4yP79+9W3b1/NmzfP7CgA4HcU0iDgdDqrXEbj4uI4Fw0IULm5uapRo4YWLlyoyy+/3Ow4AOB3FNIgk5eXp5iYGI8fFx0dzbu7AAFo165d6t+/vxYtWkQZBWBbFNIgExMTU6lCCiAwJSUlKSUlRY0aNTI7CgCYhkIKACb49ddf9dlnn+mNN94wOwoAmI59SAHAz3755RcNGDBAf/rTn8yOAgABgUIKAH5UVFSk3377TW+99ZauuOIKs+MAQECgkAKAn+zcuVN33323/vjHP1JGAeA0nEMKAH5w8uRJDR06VCkpKQoPDzc7DgAEFAopAPjY9u3b5XK59OGHHyoyMtLsOAAQcFiyBwAf2r59u4YOHarY2FjKKACUg0IKAD6UlZWld955h31GAeA8WLIHAB/48ccfNXfuXM2YMcPsKAAQ8CikAOBlO3fu1MMPP6xFixaZHQUAggKFFAC8aNeuXapTp46WLFmievXqmR0HAIIC55ACgJds3bpVAwYMUFFREWUUADxAIQUALzAMQy+//LKWLFmiSy+91Ow4ABBUWLIHgCr67rvv9J///Efz5s0zOwoABCVmSAGgCr799luNGjVKnTt3NjsKAAQtCikAVFJBQYGcTqdSU1NVp04ds+MAQNCikAJAJfznP//Rfffdp7Zt21JGAaCKOIcUADx07NgxjR49WkuWLFFoKL/XA0BVUUgBwAObN29WTEyMPvzwQ4WHh5sdBwAsgV/tAaCCNm3apDFjxujSSy+ljAKAF1FIAaCCvvzyS6WlpemSSy4xOwoAWApL9l5gGIacTqfPnt/hcPjsuQFc2IYNG/Tee+9p2rRpZkcBAEuikFaRYRjq2LGjsrOzzY4CwAe+/fZbjR8/Xunp6WZHAQDLYsm+ipxOp9/KaFxcnKKjo/3yWgCkn376SZdffrnS09NVq1Yts+MAgGUxQ+pFeXl5iomJ8dnzR0dHKyQkxGfPD+D/rF+/Xs8884yWLVtGGQUAH6OQelFMTIxPCykA/3C73VqwYIGWLl2qmjVrmh0HACyPQgoAp/niiy+0d+9ezZ071+woAGAbnEMKAP+Vk5OjyZMnq0uXLmZHAQBbYYYUAPT79mphYWFKT09nmR4A/IwZUgC2t27dOvXv31833XQTZRQATMAMqYfO3gSfTeuB4HbgwAG98MILSk1NZRcLADAJM6QeOLUJfo0aNUo/6tWrZ3YsAJW0bt06OZ1OrVixQjVq1DA7DgDYFoXUA+fbBJ9N64Hg8q9//UsvvPCC6tSpo7CwMLPjAICtsWRfSWdvgs+m9UDwMAxDW7duVVpaGnsHA0AAoJBWEpvgA8Hp008/1dq1azVp0iSzowAA/otCCsA2vvjiC82aNUupqalmRwEAnIZzSAHYwrfffqsWLVooNTWV870BIMBQSAFYXmZmpp555hlFRkZSRgEgAFFIAVhacXGxVqxYodTUVEVFRZkdBwBQBs4hBWBZq1evlsvlUnJystlRAADnwQwpAEtatWqV5s2bp86dO5sdBQBwAcyQArCc/Px8XXrppVqyZIkiIyPNjgMAuABmSAFYyocffqhHHnlEN910E2UUAIIEM6QALOPXX3/VO++8o3fffdfsKAAADzBDCsAS/vnPf6patWpKS0tjZhQAggyFFEDQ++CDD/T222+rTp06Cg3lvzUACDb8zw0gqBmGoby8PL3zzjuKiIgwOw4AoBI4hxRA0Fq+fLl+/PFHjR071uwoAIAqoJACCEqZmZlatmyZ3n77bbOjAACqiEIKIOhs2LBB7dq1U6dOnRQeHm52HABAFXEOKYCgsnTpUr388suKiYmhjAKARVBIAQSNkydP6osvvtDChQtVrRoLPABgFfyPDiAopKWlqW7dupo5c6bZUQAAXsYMKYCAl5qaqlWrVulPf/qT2VEAAD7ADCmAgHb48GE1b95cPXr0UFhYmNlxAAA+QCEFELDeffddffnll3r99dfNjgIA8CEK6QUYhiGn0ylJcjgcJqcB7OP777/X2rVrNW/ePLOjAAB8jHNIz8MwDHXs2FE1atRQjRo1VK9ePbMjAbbw3nvvqU6dOnrzzTdZpgcAG6hUIU1OTlaTJk0UFRWl9u3ba/369RV6XFpamkJCQtS9e/fKvKzfOZ1OZWdnn3M8Li5O0dHRJiQCrO+tt95SZmamLr30UoWEhJgdBwDgBx4X0vT0dCUmJmrixInauHGjWrVqpfj4eB04cOC8j/vll1/0xBNP6JZbbql0WDPl5eXpxIkTOnHihD7//HN+UAI+4Ha7JUlz5sxRaCgLOABgFx7/jz9z5kwNHjxYAwYM0LXXXqs5c+YoOjpaKSkp5T6mpKREffr00aRJk9S0adMqBTZLTExM6QdlFPC+zMxMvfHGGxowYABlFABsxqOLmoqKirRhwwaNGzeu9FhoaKg6d+6snJycch83efJk1a1bVwMHDtTnn39+wdcpLCxUYWFh6e38/HxJksvlksvlKj1+6s+nH/Oms1/LV6+D8vl6jBEYli5dqh07dmjatGmMtYXx/Wx9jLE9lDfOVRl3jwrpoUOHVFJScs7FPfXq1dO2bdvKfMy6deu0YMECbd68ucKvk5SUpEmTJp1zfM2aNWWeu5mZmVnh5/ZEQUFB6Z9Xr16tqKgon7wOLsxXYwzzbdu2TZdffrmGDBmirKwss+PAD/h+tj7G2B7OHudTuxJVhk+3fTp+/Lj69u2r+fPnq3bt2hV+3Lhx45SYmFh6Oz8/X40bN1bXrl0VGxtbetzlcikzM1NdunRReHi4V7NLZ27zFB8fr5iYGK+/Bs7P12MMc82bN0+//vqrRowYoY8//phxtji+n62PMbaH8sb51Ip2ZXhUSGvXrq2wsDDl5eWdcTwvL0/169c/5/47duzQL7/8om7dupUeO3XRQrVq1fTDDz/oqquuOudxkZGRioyMPOd4eHh4mV/g5R2vqtOf01evgYrh3996jh07pv379ys5OVnFxcWSGGe7YJytjzG2h7PHuSpj7tGVAxEREWrTps0Zy2put1tZWVnq0KHDOfdv3ry5tmzZos2bN5d+3H333brtttu0efNmNW7cuNLBAQSv2bNna9u2bXruuee4SBAA4PmSfWJiovr376+2bduqXbt2mjVrlhwOhwYMGCBJ6tevnxo1aqSkpCRFRUWpZcuWZzy+Vq1aknTOcQD2kJycrJ9++kkPP/yw2VEAAAHC40KakJCggwcPasKECcrNzdUNN9ygVatWlV7otGvXLrZsAVCmAwcO6JZbbtGwYcOYGQUAlKrURU0jRozQiBEjyvy7tWvXnvexCxcurMxLAghys2bN0qFDh/Tcc8+ZHQUAEGB8epU9AEjS+vXrtWfPHk2fPt3sKACAAMTaOgCfWrBggZo1a6bp06ezTA8AKBMzpAB8Zvr06frtt98UGxtLGQUAlItCCsAniouL1bBhQz3xxBOUUQDAeVFIAXjdtGnT1KBBA/Xv39/sKACAIMA5pAC8asGCBXI4HOrXr5/ZUQAAQYIZUgBe88knn6hnz56Kjo5mmR4AUGEUUgBeMWXKFJWUlOj22283OwoAIMhQSAFU2YEDBxQZGakxY8aYHQUAEIQ4hxRAlUyePFkHDhygjAIAKo1CCqDSJk+erNDQULVs2dLsKACAIMaSPQCPGYah/fv3q0ePHmrevLnZcQAAQY4ZUgAeMQxDzzzzjNLS0iijAACvYIb0NIZhyOl0lt52OBwmpgECU1ZWlmrUqKHExESzowAALIJC+l+GYahjx47Kzs42OwoQkAzD0CuvvKKhQ4eqc+fOZscBAFgIS/b/5XQ6yy2jcXFxio6O9nMiIHAYhqGxY8equLhY1atXNzsOAMBimCEtQ15enmJiYkpv864zsDPDMFRYWKgOHTqoe/fuZscBAFgQhbQMMTExZxRSwK4Mw9Do0aPVsWNHyigAwGdYsgdQrpkzZ6px48aUUQCATzFDCuAchmFo1apVGj58uKKiosyOAwCwOGZIAZzBMAw9+uij2rFjB2UUAOAXzJACOMOuXbt03XXXaciQIWZHAQDYBDOkACT9PjP62GOPye12U0YBAH5FIQUgSXrsscfUrFkzXXnllWZHAQDYDEv2gM253W7t2bNHI0eOVNOmTc2OAwCwIWZIARtzu90aPny4PvnkE8ooAMA0FFLAxlauXKk2bdrogQceMDsKAMDGWLIHbMjtdispKUljxoxReHi42XEAADbHDClgM263W0OHDlWjRo0oowCAgMAMKWAjJSUlKigo0H333af4+Hiz4wAAIIkZUsA2SkpKNHjwYK1fv54yCgAIKBRSwCYmTZqk22+/XbfddpvZUQAAOANL9oDFlZSU6KOPPtLTTz+tiIgIs+MAAHAOZkgBCysuLtaDDz4oh8NBGQUABCxmSAEL27Fjh+6880716NHD7CgAAJSLGVLAgoqLizVw4EBddNFFlFEAQMCjkAIWYxiGBg4cqDvuuEP169c3Ow4AABfEkj1gIS6XS3v27NFzzz2nxo0bmx0HAIAKYYYUsAiXy6V+/frpm2++oYwCAIIKhRSwiKVLl+pvf/ubunfvbnYUAAA8wpI9EOSKioo0depUTZw4UaGh/I4JAAg+/PQCglhRUZH69u2r1q1bU0YBAEGLGVIgSBUVFamwsFAjRozQLbfcYnYcAAAqjSkVIAgVFhaqT58+2rZtG2UUABD0KKRAEBo/frweeOAB3XTTTWZHAQCgyliyB4JIQUGBMjIy9MILL6haNb59AQDWwAwpECQKCgrUu3dvRUdHU0YBAJbCTzUgSPz4448aOnSo4uPjzY4CAIBXMUMKBLiTJ0+qZ8+euvzyyymjAABLopACAcztdqtPnz4aOHCgatWqZXYcAAB8giV7IEA5nU7l5uZq9uzZql+/vtlxAADwGWZIgQDkdDrVq1cv/frrr5RRAIDlUUiBALRkyRKNGjVKt912m9lRAADwOZbsgQDicDj0/PPP67nnnlNISIjZcQAA8AtmSIEA4XA4lJCQoK5du1JGAQC2wgwpEACcTqdKSkr07LPPqm3btmbHAQDAr5ghBUx24sQJ/e1vf9PevXspowAAW6KQAiYbPXq0xo8frxYtWpgdBQAAU7BkD5jk+PHjWrNmjZKTkxUayu+GAAD74qcgYIL8/Hz16NFDDRs2pIwCAGyPGVLAzwzD0LZt2zRx4kT9v//3/8yOAwCA6ZiaAfzo2LFjuvfee9WyZUvKKAAA/0UhBfykuLhYPXv21Lhx4xQdHW12HAAAAgZL9oAfHD16VIcPH9a7776r2rVrmx0HAICAwgwp4GNHjhxRjx49dPjwYcooAABlYIYU8LHU1FQlJSWpTZs2ZkcBACAgUUgBHzl8+LBmzJihqVOnmh0FAICAxpI94AOHDx9Wz549dd9995kdBQCAgMcMKeBl+fn5CgsL06xZs3TttdeaHQcAgIDHDCngRYcOHdK9996rI0eOUEYBAKggCingRWPGjNHMmTPVpEkTs6MAABA0WLIHvODgwYP67LPPtGDBAoWEhJgdBwCAoMIMKVBFBw4cUM+ePdWsWTPKKAAAlcAMKVAFhmHoxx9/1KuvvqrrrrvO7DgAAAQlZkiBSsrLy9M999yj9u3bU0YBAKgCZkiBSigoKFCfPn302muvKTw83Ow4AAAENQop4KH9+/ersLBQy5YtU61atcyOAwBA0GPJHvDA/v371adPHxUWFlJGAQDwEgop4IH09HS98cYbatasmdlRAACwDJbsgQrYu3ev3njjDT333HNmRwEAwHKYIQUuYN++ferXr58eeOABs6MAAGBJzJAC5/Hbb7+pevXqmj9/vpo2bWp2HAAALIkZUqAcu3fv1t/+9jcVFRVRRgEA8CEKKVAGwzA0fvx4vfnmm6pXr57ZcQAAsDSW7IGz/Prrr9q4caPeeecd3pseAAA/YIYUOM0vv/yiAQMG6MYbb6SMAgDgJxRS4L9KSkr0yy+/KCUlRU2aNDE7DgAAtkEhBST9/PPPuvfee/WnP/2JMgoAgJ9xDilsLz8/XwMHDtTChQsVGsrvaAAA+BuFFLa2Y8cORUREaOXKlapRo4bZcQAAsCWmg2Bb27dv15AhQxQaGkoZBQDARBRS2NYHH3ygd955R40aNTI7CgAAtsaSPWznp59+0qJFizRp0iSzowAAAFFIYTPbt2/XQw89pHfffdfsKAAA4L8opLCN3NxcXXLJJVq0aJEaNGhgdhwAAPBfnEMKW9i2bZt69+6t0NBQyigAAAGGQgrLMwxDU6ZM0ZIlS1SrVi2z4wAAgLOwZA9L+/7777Vjxw4tXrzY7CgAAKAczJDCsr777juNHDlS7du3NzsKAAA4DwopLKm4uFh5eXlasmSJ6tata3YcAABwHhRSWM6WLVvUs2dP3XbbbZRRAACCgG3PITUMQ06ns/S2w+EwMQ285eDBg0pMTFRqaqpCQkLMjgMAACrAljOkhmGoY8eOqlGjRulHvXr1zI6FKtqyZYtcLpdWrlyp2rVrmx0HAABUkC0LqdPpVHZ2dpl/FxcXp+joaD8nQlVt3rxZjz/+uCIjI1W9enWz4wAAAA/Ydsn+lLy8PMXExJTejo6OZqk3CGVmZiotLU2XXHKJ2VEAAICHbF9IY2JiziikCC4bN25URkaGnn76abOjAACASrJ9IUXw+uabbzRu3DilpaWZHQUAAFSBLc8hRfDbvXu3GjZsqLS0NF188cVmxwEAAFVAIUXQ+eqrrzRo0CDFxMRQRgEAsAAKKYJKcXGxXnnlFS1dupTdEAAAsIhKFdLk5GQ1adJEUVFRat++vdavX1/ufefPn69bbrlFF198sS6++GJ17tz5vPcHyvPll18qKytLixYt0kUXXWR2HAAA4CUeF9L09HQlJiZq4sSJ2rhxo1q1aqX4+HgdOHCgzPuvXbtWvXr10qeffqqcnBw1btxYXbt21d69e6scHvbx5Zdf6tlnn1WHDh3MjgIAALzM46vsZ86cqcGDB2vAgAGSpDlz5uijjz5SSkqKxo4de879Fy9efMbtN998U3//+9+VlZWlfv36lfkahYWFKiwsLL2dn58vSXK5XHK5XKXHT/359GMVcfZzePp4+M+p8Tl27JgWLVqk6tWrM14WVNnvZQQXxtn6GGN7KG+cqzLuHhXSoqIibdiwQePGjSs9Fhoaqs6dOysnJ6dCz+F0OuVyuc67gXlSUpImTZp0zvE1a9aUed5gZmZmhV77lIKCgtI/r169WlFRUR49Hv6zbds2ZWRkKDExUevWrTM7DnzM0+9lBCfG2foYY3s4e5ydTmeln8ujQnro0CGVlJSc877v9erV07Zt2yr0HE8++aQaNmyozp07l3ufcePGKTExsfR2fn5+6VJ/bGxs6XGXy6XMzEx16dJF4eHhFf48HA5H6Z/j4+PZGD9A7dq1S2+88YYefvhhj8cYwaWy38sILoyz9THG9lDeOJ9a0a4Mv26MP23aNKWlpWnt2rXnnZWMjIxUZGTkOcfDw8PL/AIv73h5Tr+vp4+Ff3zxxRdq2rSpli1bpqysLMbJJhhne2CcrY8xtoezx7kqY+7RRU21a9dWWFiY8vLyzjiel5en+vXrn/exL730kqZNm6Y1a9boj3/8o+dJYRufffaZpk6dqpiYmDJ/MQEAANbiUSGNiIhQmzZtlJWVVXrM7XYrKyvrvFc/v/jii5oyZYpWrVqltm3bVj4tbGH9+vVKS0vjVAoAAGzC4yX7xMRE9e/fX23btlW7du00a9YsORyO0qvu+/Xrp0aNGikpKUmS9MILL2jChAlasmSJmjRpotzcXElSjRo1VKNGDS9+KuUzDOOME21PP4cUgWPt2rX66quvNHr0aLOjAAAAP/K4kCYkJOjgwYOaMGGCcnNzdcMNN2jVqlWlFzrt2rVLoaH/N/H6xhtvqKioSPfdd98ZzzNx4kQ9++yzVUtfAYZhqGPHjsrOzvb5a6Hy1q1bp5kzZyotLc3sKAAAwM8qdVHTiBEjNGLEiDL/bu3atWfc/uWXXyrzEl7jdDrLLaNxcXG8/WQA2LFjh5o1a6a0tDTGAwAAG/LrVfZmy8vLO+O8xOjoaIWEhJiYCB9//LFee+01LVu2jCsyAQCwKVsV0piYGC6UCSAFBQVasmSJ0tLSKKMAANiYrQopAseaNWsUGRmplJQUs6MAAACTebTtE+ANq1ev1pw5c9S+fXuzowAAgABAIYVfFRQUKCIiQkuWLDnvu3UBAAD7YMkefpORkaEVK1Zo3rx5ZkcBAAABhEIKv9i2bZveeustLVq0yOwoAAAgwLBkD5/LyspSnTp1lJqaynvTAwCAc1BI4VMrV67U3LlzVbNmTVWrxoQ8AAA4F4UUPmMYhrZv365FixYpIiLC7DgAACBAMWUFn1ixYoV2796txMREs6MAAIAARyGF12VkZCg9PV3vvPOO2VEAAEAQoJDCq7Zu3aqbbrpJXbp04e1AAQBAhXAOKbxm2bJleu6553TppZdSRgEAQIVRSOEV+fn5+uSTT/T2228rNJQvKwAAUHGWW7I3DENOp7P0tsPhMDGNPaSnp+vKK6/U7NmzzY4CAACCkKWmsgzDUMeOHVWjRo3Sj3r16pkdy9LS0tL00UcfqXXr1mZHAQAAQcpShdTpdCo7O7vMv4uLi1N0dLSfE1nbiRMn1LBhQ6WkpLDpPQAAqDTLtoi8vDzFxMSU3o6OjlZISIiJiaxl0aJF2rhxo2bOnGl2FAAAEOQsW0hjYmLOKKTwnq+//lqffPKJ5s+fb3YUAABgAZZasofvffDBB7r66qs1f/58hYWFmR0HAABYAIUUFbZw4UJ9+OGHqlmzJmUUAAB4DYUUFeJ2u5Wfn6+5c+eyzygAAPAqy55DCu9JSUmRJI0cOdLkJAAAwIqY6sJ5paamav369XrggQfMjgIAACyKGVKU65tvvlGXLl2UkJDAMj0AAPAZWgbKNHfuXM2bN0+XXnopZRQAAPgUTQPnOHjwoHbs2KHXX3+dNxMAAAA+RyHFGebMmaPc3Fy9+OKLlFEAAOAXFFKUSk5O1tatW9WyZUuzowAAABvhoiZIko4dO6bWrVtr2LBhzIwCAAC/opBCr7zyio4ePaqJEyeaHQUAANgQhdTmPv30U+3atUsvvfSS2VEAAIBNUUhtbPHixerevbs6derEMj0AADANFzXZ1IwZM/TNN98oOjqaMgoAAEzFDKkNuVwuxcbGKjExkTIKAABMRyG1mRdffFFXXnmlBg8ebHYUAAAASSzZ28obb7yhY8eO6b777jM7CgAAQClmSG3iq6++Us+ePVWrVi2W6QEAQEBhhtQGpk6dqpUrV+riiy+mjAIAgIBDIbW4Xbt2SZImT55schIAAICyUUgtLCkpScXFxXrqqaeYGQUAAAGLc0gtatKkSQoJCVHTpk3NjgIAAHBeFFKLMQxDhw8f1l133aU2bdqYHQcAAOCCKKQWYhiGJkyYoDp16mjkyJFmxwEAAKgQziG1kJUrVyo6OpoyCgAAggozpBZgGIbmzZunAQMG6J577jE7DgAAgEeYIQ1yhmFo3Lhxys/PV0REhNlxAAAAPMYMaRAzDEMFBQW6/vrr1adPH7PjAAAAVAozpEHKMAw9+eST+uyzzyijAAAgqFFIg1RSUpIaNGig+Ph4s6MAAABUCUv2QcYwDP373//WiBEjFBsba3YcAACAKmOGNIgYhqHExERt3LiRMgoAACyDGdIg8uOPP+rqq6/WsGHDzI4CAADgNcyQBgHDMDRmzBjFxsZSRgEAgOVQSAOcYRgaNWqUrrzySjVo0MDsOAAAAF7Hkn0Ac7vdOnTokIYMGaKWLVuaHQcAAMAnmCENUG63WyNGjNDq1aspowAAwNIopAFqyZIluvHGG9W3b1+zowAAAPgUS/YBxu1269VXX9XIkSMVGsrvCwAAwPpoPAHE7XbroYceUmxsLGUUAADYBjOkAcLtdsvhcOjOO+/UPffcY3YcAAAAv2EaLgCUlJRoyJAh+vbbbymjAADAdiikAWD8+PG69dZb1aFDB7OjAAAA+B1L9iYqKSnRZ599pokTJyo6OtrsOAAAAKZghtQkJSUlGjRokPbt20cZBQAAtsYMqUm2bNmirl27qlevXmZHAQAAMFVQz5AahqGCggI5HI7Sj0BXXFyshx9+WFdccQVlFAAAQEE8Q2oYhjp16qScnByzo1SYYRgaMGCA7rrrLl188cVmxwEAAAgIQVtInU5nuWU0Li4u4M7LLC4u1qFDh/T000+rWbNmZscBAAAIGEG9ZH/Knj17dOLEidKPzz//XCEhIWbHKuVyudS/f3999dVXlFEAAICzBO0M6eliYmIUExNjdoxypaSk6N5771W3bt3MjgIAABBwLFFIA5XL5dLLL7+s0aNHB9SMLQAAQCCxxJJ9ICoqKlLfvn11zTXXUEYBAADOgxlSH3C5XHI6nRo0aJA6d+5sdhwAAICAxgyplxUVFalPnz7avXs3ZRQAAKACKKRe9thjj6lfv366/vrrzY4CAAAQFFiy95LCwkJ99tlnmjFjhqKiosyOAwAAEDSYIfWCwsJC9enTR8XFxZRRAAAADzFD6gUbNmzQoEGDdMcdd5gdBQAAIOgwQ1oFBQUFeuCBB9SqVSvKKAAAQCVRSCupuLhYvXr1Uu/evQP6XaIAAAACHUv2lXDy5EkdO3ZMM2fO1JVXXml2HAAAgKDGDKmHnE6nevbsqR9++IEyCgAA4AUUUg/NmzdPI0eO1K233mp2FAAAAEtgyb6CHA6HXn31VY0bN87sKAAAAJbCDGkFOBwO9ezZUx06dDA7CgAAgOUwQ3oBhYWFKigo0Pjx4ymkAAAAPsAM6XmcOHFCf/3rX3Xs2DHKKAAAgI9QSM9jxIgRGjt2rJo2bWp2FAAAAMtiyb4Mx48fV05OjubPn6/w8HCz4wAAAFgaM6RnOX78uBISElSjRg3KKAAAgB8wQ3qWr776Ss888wznjAIAAPgJhfS/8vPz9dBDD2nhwoWKiIgwOw4AAIBtsGQvqaCgQD169NCjjz5KGQUAAPAz28+QHj16VIWFhVqwYIEaNWpkdhwAAADbsfUM6dGjR5WQkKC9e/dSRgEAAExi60I6d+5cTZ06Va1btzY7CgAAgG3Zcsn+yJEjmjNnjsaNG2d2FAAAANuz3Qzp4cOHlZCQoPj4eLOjAAAAQDabIXU6nSouLtb06dPVqlUrs+MAAABANpoh/e2333TPPfeopKSEMgoAABBAbFNIhw8frpdeekkNGjQwOwoAAABOY/kl+0OHDmnjxo1atGiRqlWz/KcLAAAQdCw9Q3rw4EH17NlTDRs2pIwCAAAEKMsWUsMwtGHDBs2aNUstW7Y0Ow4AAADKYclCeuDAAfXs2VNdunShjAIAAAQ4y61jHz9+XL1799arr76qsLAws+MAAADgAixVSHNzcxUWFqbFixerXr16ZscBAABABVRqyT45OVlNmjRRVFSU2rdvr/Xr15/3/u+9956aN2+uqKgoXX/99crIyKhU2PPZv3+/+vTpoyNHjlBGAQAAgojHhTQ9PV2JiYmaOHGiNm7cqFatWik+Pl4HDhwo8/7Z2dnq1auXBg4cqE2bNql79+7q3r27vv322yqHP92CBQs0e/ZsXXPNNV59XgAAAPiWx4V05syZGjx4sAYMGKBrr71Wc+bMUXR0tFJSUsq8/yuvvKI77rhDo0ePVosWLTRlyhS1bt1ar7/+epXDn/Lyyy/r6aefVrNmzbz2nAAAAPAPj84hLSoq0oYNGzRu3LjSY6GhoercubNycnLKfExOTo4SExPPOBYfH68VK1aU+zqFhYUqLCwsvZ2fny9JcrlccrlcpX8+5S9/+csZt2EdZY03rIdxtgfG2foYY3sob5yrMu4eFdJDhw6ppKTknHM069Wrp23btpX5mNzc3DLvn5ubW+7rJCUladKkSeccX7NmjaKjoyVJBQUFpcd/+eWX8z4fgl9mZqbZEeAHjLM9MM7Wxxjbw9nj7HQ6K/1cAXmV/bhx486YVc3Pz1fjxo3VtWtXxcbGSvp94/sDBw7ok08+0V133aWIiAiz4sKHXC6XMjMz1aVLF4WHh5sdBz7CONsD42x9jLE9lDfOp1a0K8OjQlq7dm2FhYUpLy/vjON5eXmqX79+mY+pX7++R/eXpMjISEVGRp5zPDw8/IxPvFatWoqKilJERARf+BZ39tjDmhhne2CcrY8xtoezx7kqY+7RRU0RERFq06aNsrKySo+53W5lZWWpQ4cOZT6mQ4cOZ9xf+n2Kt7z7AwAAwF48XrJPTExU//791bZtW7Vr106zZs2Sw+HQgAEDJEn9+vVTo0aNlJSUJEkaNWqUbr31Vs2YMUN33nmn0tLS9PXXX2vevHne/UwAAAAQlDwupAkJCTp48KAmTJig3Nxc3XDDDVq1alXphUu7du1SaOj/TbzefPPNWrJkiZ5++mmNHz9eV199tVasWOHRe8wbhiHp3HMTXC6XnE6n8vPzWRqwKMbYHhhne2CcrY8xtofyxvlUTzvV2zwRYlTmUX62Z88eNW7c2OwYAAAAuIDdu3frsssu8+gxQVFI3W639u3bp5o1ayokJKT0+Kmr73fv3l169T2shTG2B8bZHhhn62OM7aG8cTYMQ8ePH1fDhg3PWC2viIDc9ulsoaGh523asbGxfOFbHGNsD4yzPTDO1scY20NZ43zRRRdV6rk8futQAAAAwJsopAAAADBVUBfSyMhITZw4scxN9GENjLE9MM72wDhbH2NsD74Y56C4qAkAAADWFdQzpAAAAAh+FFIAAACYikIKAAAAU1FIAQAAYCoKKQAAAEwV8IU0OTlZTZo0UVRUlNq3b6/169ef9/7vvfeemjdvrqioKF1//fXKyMjwU1JUlidjPH/+fN1yyy26+OKLdfHFF6tz584X/JpAYPD0e/mUtLQ0hYSEqHv37r4NiCrzdIyPHj2q4cOHq0GDBoqMjNQ111zD/9lBwNNxnjVrlpo1a6bq1aurcePGeuyxx1RQUOCntPDUZ599pm7duqlhw4YKCQnRihUrLviYtWvXqnXr1oqMjNQf/vAHLVy40PMXNgJYWlqaERERYaSkpBjfffedMXjwYKNWrVpGXl5emff/97//bYSFhRkvvvii8f333xtPP/20ER4ebmzZssXPyVFRno5x7969jeTkZGPTpk3G1q1bjQceeMC46KKLjD179vg5OTzh6Tif8vPPPxuNGjUybrnlFuOee+7xT1hUiqdjXFhYaLRt29b4y1/+Yqxbt874+eefjbVr1xqbN2/2c3J4wtNxXrx4sREZGWksXrzY+Pnnn43Vq1cbDRo0MB577DE/J0dFZWRkGE899ZSxfPlyQ5Lx/vvvn/f+O3fuNKKjo43ExETj+++/N1577TUjLCzMWLVqlUevG9CFtF27dsbw4cNLb5eUlBgNGzY0kpKSyrx/jx49jDvvvPOMY+3btzeGDh3q05yoPE/H+GzFxcVGzZo1jbfffttXEeEFlRnn4uJi4+abbzbefPNNo3///hTSAOfpGL/xxhtG06ZNjaKiIn9FhBd4Os7Dhw83br/99jOOJSYmGnFxcT7NCe+oSCEdM2aMcd11151xLCEhwYiPj/fotQJ2yb6oqEgbNmxQ586dS4+Fhoaqc+fOysnJKfMxOTk5Z9xfkuLj48u9P8xVmTE+m9PplMvl0iWXXOKrmKiiyo7z5MmTVbduXQ0cONAfMVEFlRnjlStXqkOHDho+fLjq1aunli1b6vnnn1dJSYm/YsNDlRnnm2++WRs2bChd1t+5c6cyMjL0l7/8xS+Z4Xve6l7VvBnKmw4dOqSSkhLVq1fvjOP16tXTtm3bynxMbm5umffPzc31WU5UXmXG+GxPPvmkGjZseM43AwJHZcZ53bp1WrBggTZv3uyHhKiqyozxzp079cknn6hPnz7KyMjQ9u3bNWzYMLlcLk2cONEfseGhyoxz7969dejQIXXs2FGGYai4uFgPPfSQxo8f74/I8IPyuld+fr5Onjyp6tWrV+h5AnaGFLiQadOmKS0tTe+//76ioqLMjgMvOX78uPr27av58+erdu3aZseBj7jdbtWtW1fz5s1TmzZtlJCQoKeeekpz5swxOxq8aO3atXr++ec1e/Zsbdy4UcuXL9dHH32kKVOmmB0NASZgZ0hr166tsLAw5eXlnXE8Ly9P9evXL/Mx9evX9+j+MFdlxviUl156SdOmTdPHH3+sP/7xj76MiSrydJx37NihX375Rd26dSs95na7JUnVqlXTDz/8oKuuusq3oeGRynwvN2jQQOHh4QoLCys91qJFC+Xm5qqoqEgRERE+zQzPVWacn3nmGfXt21eDBg2SJF1//fVyOBwaMmSInnrqKYWGMi8W7MrrXrGxsRWeHZUCeIY0IiJCbdq0UVZWVukxt9utrKwsdejQoczHdOjQ4Yz7S1JmZma594e5KjPGkvTiiy9qypQpWrVqldq2beuPqKgCT8e5efPm2rJlizZv3lz6cffdd+u2227T5s2b1bhxY3/GRwVU5ns5Li5O27dvL/1lQ5J+/PFHNWjQgDIaoCozzk6n85zSeeqXkN+vmUGw81r38ux6K/9KS0szIiMjjYULFxrff/+9MWTIEKNWrVpGbm6uYRiG0bdvX2Ps2LGl9//3v/9tVKtWzXjppZeMrVu3GhMnTmTbpwDn6RhPmzbNiIiIMJYtW2bs37+/9OP48eNmfQqoAE/H+WxcZR/4PB3jXbt2GTVr1jRGjBhh/PDDD8aHH35o1K1b13juuefM+hRQAZ6O88SJE42aNWsaqampxs6dO401a9YYV111ldGjRw+zPgVcwPHjx41NmzYZmzZtMiQZM2fONDZt2mT8+uuvhmEYxtixY42+ffuW3v/Utk+jR482tm7daiQnJ1tv2yfDMIzXXnvNuPzyy42IiAijXbt2xhdffFH6d7feeqvRv3//M+6/dOlS45prrjEiIiKM6667zvjoo4/8nBie8mSMr7jiCkPSOR8TJ070f3B4xNPv5dNRSIODp2OcnZ1ttG/f3oiMjDSaNm1qTJ061SguLvZzanjKk3F2uVzGs88+a1x11VVGVFSU0bhxY2PYsGHGkSNH/B8cFfLpp5+W+XP21Lj279/fuPXWW895zA033GBEREQYTZs2Nd566y2PXzfEMJgzBwAAgHkC9hxSAAAA2AOFFAAAAKaikAIAAMBUFFIAAACYikIKAAAAU1FIAQAAYCoKKQAAAExFIQUAAICpKKQAAAAwFYUUAAAApqKQAgAAwFT/H4EOWybWaD5sAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "invalid-nevada",
      "metadata": {
        "id": "invalid-nevada"
      },
      "source": [
        " Plot the training loss and the validation loss over the different epochs and see how it looks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "hidden-physics",
      "metadata": {
        "id": "hidden-physics",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1ca0b31f-989b-4a03-f308-42524a23666e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "run_hist_1.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "banned-spider",
      "metadata": {
        "id": "banned-spider",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "outputId": "82557264-90cd-4b6b-e222-782a64274008"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7b655dfb2a10>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "superb-circus",
      "metadata": {
        "id": "superb-circus"
      },
      "source": [
        "What is your interpretation about the result of the train and validation loss?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "german-cherry",
      "metadata": {
        "id": "german-cherry"
      },
      "source": [
        "#type your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What I can infer from the given graph is that after around 50 epoch, the validation loss remained constant while the train loss is still slowly decreasing. This I can say that with the perfect epoch for this training of model is around 50-100 epochs only or it will result to overfitting."
      ],
      "metadata": {
        "id": "3PiQY08kG7pg"
      },
      "id": "3PiQY08kG7pg"
    },
    {
      "cell_type": "markdown",
      "id": "involved-slovak",
      "metadata": {
        "id": "involved-slovak"
      },
      "source": [
        "#### Supplementary Activity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pending-publisher",
      "metadata": {
        "id": "pending-publisher"
      },
      "source": [
        "* Build a model with two hidden layers, each with 6 nodes\n",
        "* Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
        "* Use a learning rate of .003 and train for 1500 epochs\n",
        "* Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "* Plot the roc curve for the predictions\n",
        "* Use different learning rates, numbers of epochs, and network structures.\n",
        "* Plot the results of training and validation loss using different learning rates, number of epocgs and network structures\n",
        "* Interpret your result"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a different dataset\n",
        "supDataset = pd.read_csv('/content/drive/MyDrive/datas/citrus.csv')"
      ],
      "metadata": {
        "id": "6gupjYI4-MF2"
      },
      "id": "6gupjYI4-MF2",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "supDataset.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "I1jQEmA8-TI8",
        "outputId": "26c84843-4405-4dd8-a81c-667ec0d3be02"
      },
      "id": "I1jQEmA8-TI8",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "name         object\n",
              "diameter    float64\n",
              "weight      float64\n",
              "red           int64\n",
              "green         int64\n",
              "blue          int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "supDataset.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "w_CwClX3_FSM",
        "outputId": "b09bdf30-5e88-4fee-e5ca-419b89a4750c"
      },
      "id": "w_CwClX3_FSM",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            name  diameter  weight  red  green  blue\n",
              "9995  grapefruit     15.35  253.89  149     77    20\n",
              "9996  grapefruit     15.41  254.67  148     68     7\n",
              "9997  grapefruit     15.59  256.50  168     82    20\n",
              "9998  grapefruit     15.92  260.14  142     72    11\n",
              "9999  grapefruit     16.45  261.51  152     74     2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1ef80c14-3a77-4046-84ca-dd8c3139e4ec\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>diameter</th>\n",
              "      <th>weight</th>\n",
              "      <th>red</th>\n",
              "      <th>green</th>\n",
              "      <th>blue</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>grapefruit</td>\n",
              "      <td>15.35</td>\n",
              "      <td>253.89</td>\n",
              "      <td>149</td>\n",
              "      <td>77</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>grapefruit</td>\n",
              "      <td>15.41</td>\n",
              "      <td>254.67</td>\n",
              "      <td>148</td>\n",
              "      <td>68</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>grapefruit</td>\n",
              "      <td>15.59</td>\n",
              "      <td>256.50</td>\n",
              "      <td>168</td>\n",
              "      <td>82</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>grapefruit</td>\n",
              "      <td>15.92</td>\n",
              "      <td>260.14</td>\n",
              "      <td>142</td>\n",
              "      <td>72</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>grapefruit</td>\n",
              "      <td>16.45</td>\n",
              "      <td>261.51</td>\n",
              "      <td>152</td>\n",
              "      <td>74</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ef80c14-3a77-4046-84ca-dd8c3139e4ec')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1ef80c14-3a77-4046-84ca-dd8c3139e4ec button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1ef80c14-3a77-4046-84ca-dd8c3139e4ec');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-96c3bcad-d81a-4b21-9624-3e31eb0e5ea4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-96c3bcad-d81a-4b21-9624-3e31eb0e5ea4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-96c3bcad-d81a-4b21-9624-3e31eb0e5ea4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# label encode the y values, orange = 1 and 0 is grapefruit\n",
        "le = LabelEncoder()\n",
        "supDataset['name'] = le.fit_transform(supDataset['name'])"
      ],
      "metadata": {
        "id": "2r8r3SYa-fU9"
      },
      "id": "2r8r3SYa-fU9",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# declare the x and y values\n",
        "X = supDataset.drop('name', axis = 1)\n",
        "y = supDataset['name']"
      ],
      "metadata": {
        "id": "22O9QW0b_Uxd"
      },
      "id": "22O9QW0b_Uxd",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state = 100)"
      ],
      "metadata": {
        "id": "embICZttABxF"
      },
      "id": "embICZttABxF",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ],
      "metadata": {
        "id": "mZRMwfozAa60"
      },
      "id": "mZRMwfozAa60",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a model with two hidden layers, each with 6 nodes\n",
        "model_sup = Sequential([\n",
        "    Dense(6, activation = 'relu', input_shape = (5,)),\n",
        "    Dense(6, activation = 'relu'),\n",
        "    Dense(1, activation = 'sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "HDyox1E78b8-"
      },
      "id": "HDyox1E78b8-",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
        "model_sup.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Iv68HBxe8_Yu",
        "outputId": "99c338fe-61f9-4e05-96d4-1fbb4e6defb7"
      },
      "id": "Iv68HBxe8_Yu",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 6)                 36        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 6)                 42        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 7         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85 (340.00 Byte)\n",
            "Trainable params: 85 (340.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_sup.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_1 = model_sup.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "poNlTLNjAjt1",
        "outputId": "3f5cef81-38a4-452f-c070-aaba5d32e91d"
      },
      "id": "poNlTLNjAjt1",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "235/235 [==============================] - 2s 4ms/step - loss: 0.6512 - accuracy: 0.6200 - val_loss: 0.4951 - val_accuracy: 0.8308\n",
            "Epoch 2/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.4100 - accuracy: 0.8808 - val_loss: 0.3473 - val_accuracy: 0.8928\n",
            "Epoch 3/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.2906 - accuracy: 0.9128 - val_loss: 0.2686 - val_accuracy: 0.9052\n",
            "Epoch 4/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.2334 - accuracy: 0.9204 - val_loss: 0.2349 - val_accuracy: 0.9116\n",
            "Epoch 5/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.2082 - accuracy: 0.9239 - val_loss: 0.2204 - val_accuracy: 0.9144\n",
            "Epoch 6/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1965 - accuracy: 0.9260 - val_loss: 0.2139 - val_accuracy: 0.9184\n",
            "Epoch 7/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1904 - accuracy: 0.9280 - val_loss: 0.2111 - val_accuracy: 0.9184\n",
            "Epoch 8/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1870 - accuracy: 0.9291 - val_loss: 0.2084 - val_accuracy: 0.9184\n",
            "Epoch 9/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 0.9301 - val_loss: 0.2068 - val_accuracy: 0.9176\n",
            "Epoch 10/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1829 - accuracy: 0.9304 - val_loss: 0.2055 - val_accuracy: 0.9176\n",
            "Epoch 11/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1815 - accuracy: 0.9309 - val_loss: 0.2043 - val_accuracy: 0.9172\n",
            "Epoch 12/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1803 - accuracy: 0.9309 - val_loss: 0.2030 - val_accuracy: 0.9176\n",
            "Epoch 13/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1793 - accuracy: 0.9312 - val_loss: 0.2024 - val_accuracy: 0.9172\n",
            "Epoch 14/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1783 - accuracy: 0.9311 - val_loss: 0.2021 - val_accuracy: 0.9172\n",
            "Epoch 15/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1775 - accuracy: 0.9311 - val_loss: 0.2012 - val_accuracy: 0.9176\n",
            "Epoch 16/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1767 - accuracy: 0.9319 - val_loss: 0.2003 - val_accuracy: 0.9176\n",
            "Epoch 17/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.9305 - val_loss: 0.1999 - val_accuracy: 0.9180\n",
            "Epoch 18/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1753 - accuracy: 0.9316 - val_loss: 0.1993 - val_accuracy: 0.9176\n",
            "Epoch 19/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1747 - accuracy: 0.9316 - val_loss: 0.1981 - val_accuracy: 0.9164\n",
            "Epoch 20/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1743 - accuracy: 0.9315 - val_loss: 0.1979 - val_accuracy: 0.9160\n",
            "Epoch 21/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1738 - accuracy: 0.9319 - val_loss: 0.1979 - val_accuracy: 0.9168\n",
            "Epoch 22/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1733 - accuracy: 0.9315 - val_loss: 0.1975 - val_accuracy: 0.9164\n",
            "Epoch 23/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1729 - accuracy: 0.9319 - val_loss: 0.1974 - val_accuracy: 0.9168\n",
            "Epoch 24/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1726 - accuracy: 0.9313 - val_loss: 0.1965 - val_accuracy: 0.9168\n",
            "Epoch 25/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1722 - accuracy: 0.9323 - val_loss: 0.1962 - val_accuracy: 0.9172\n",
            "Epoch 26/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1718 - accuracy: 0.9323 - val_loss: 0.1959 - val_accuracy: 0.9168\n",
            "Epoch 27/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1714 - accuracy: 0.9325 - val_loss: 0.1953 - val_accuracy: 0.9176\n",
            "Epoch 28/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1711 - accuracy: 0.9328 - val_loss: 0.1955 - val_accuracy: 0.9180\n",
            "Epoch 29/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1708 - accuracy: 0.9328 - val_loss: 0.1950 - val_accuracy: 0.9176\n",
            "Epoch 30/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1705 - accuracy: 0.9329 - val_loss: 0.1952 - val_accuracy: 0.9172\n",
            "Epoch 31/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1702 - accuracy: 0.9325 - val_loss: 0.1949 - val_accuracy: 0.9180\n",
            "Epoch 32/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1700 - accuracy: 0.9336 - val_loss: 0.1942 - val_accuracy: 0.9172\n",
            "Epoch 33/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1697 - accuracy: 0.9325 - val_loss: 0.1943 - val_accuracy: 0.9176\n",
            "Epoch 34/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1695 - accuracy: 0.9329 - val_loss: 0.1938 - val_accuracy: 0.9176\n",
            "Epoch 35/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1692 - accuracy: 0.9328 - val_loss: 0.1937 - val_accuracy: 0.9180\n",
            "Epoch 36/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1689 - accuracy: 0.9327 - val_loss: 0.1936 - val_accuracy: 0.9176\n",
            "Epoch 37/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1687 - accuracy: 0.9332 - val_loss: 0.1933 - val_accuracy: 0.9184\n",
            "Epoch 38/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1684 - accuracy: 0.9331 - val_loss: 0.1928 - val_accuracy: 0.9180\n",
            "Epoch 39/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1682 - accuracy: 0.9336 - val_loss: 0.1929 - val_accuracy: 0.9184\n",
            "Epoch 40/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1679 - accuracy: 0.9333 - val_loss: 0.1926 - val_accuracy: 0.9176\n",
            "Epoch 41/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1677 - accuracy: 0.9333 - val_loss: 0.1924 - val_accuracy: 0.9184\n",
            "Epoch 42/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1674 - accuracy: 0.9333 - val_loss: 0.1919 - val_accuracy: 0.9184\n",
            "Epoch 43/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1673 - accuracy: 0.9333 - val_loss: 0.1921 - val_accuracy: 0.9184\n",
            "Epoch 44/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1671 - accuracy: 0.9331 - val_loss: 0.1917 - val_accuracy: 0.9184\n",
            "Epoch 45/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1669 - accuracy: 0.9337 - val_loss: 0.1913 - val_accuracy: 0.9184\n",
            "Epoch 46/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1666 - accuracy: 0.9339 - val_loss: 0.1908 - val_accuracy: 0.9188\n",
            "Epoch 47/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1664 - accuracy: 0.9332 - val_loss: 0.1910 - val_accuracy: 0.9184\n",
            "Epoch 48/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1662 - accuracy: 0.9344 - val_loss: 0.1910 - val_accuracy: 0.9180\n",
            "Epoch 49/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1660 - accuracy: 0.9331 - val_loss: 0.1906 - val_accuracy: 0.9180\n",
            "Epoch 50/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1659 - accuracy: 0.9333 - val_loss: 0.1905 - val_accuracy: 0.9184\n",
            "Epoch 51/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1657 - accuracy: 0.9337 - val_loss: 0.1901 - val_accuracy: 0.9188\n",
            "Epoch 52/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1654 - accuracy: 0.9337 - val_loss: 0.1893 - val_accuracy: 0.9200\n",
            "Epoch 53/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1653 - accuracy: 0.9343 - val_loss: 0.1898 - val_accuracy: 0.9188\n",
            "Epoch 54/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1651 - accuracy: 0.9345 - val_loss: 0.1894 - val_accuracy: 0.9196\n",
            "Epoch 55/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1648 - accuracy: 0.9343 - val_loss: 0.1899 - val_accuracy: 0.9180\n",
            "Epoch 56/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1647 - accuracy: 0.9347 - val_loss: 0.1892 - val_accuracy: 0.9196\n",
            "Epoch 57/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1643 - accuracy: 0.9355 - val_loss: 0.1883 - val_accuracy: 0.9204\n",
            "Epoch 58/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1642 - accuracy: 0.9343 - val_loss: 0.1880 - val_accuracy: 0.9200\n",
            "Epoch 59/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1640 - accuracy: 0.9348 - val_loss: 0.1886 - val_accuracy: 0.9180\n",
            "Epoch 60/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1638 - accuracy: 0.9352 - val_loss: 0.1883 - val_accuracy: 0.9188\n",
            "Epoch 61/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1636 - accuracy: 0.9343 - val_loss: 0.1871 - val_accuracy: 0.9208\n",
            "Epoch 62/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1634 - accuracy: 0.9345 - val_loss: 0.1877 - val_accuracy: 0.9188\n",
            "Epoch 63/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1632 - accuracy: 0.9344 - val_loss: 0.1871 - val_accuracy: 0.9200\n",
            "Epoch 64/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1629 - accuracy: 0.9349 - val_loss: 0.1867 - val_accuracy: 0.9196\n",
            "Epoch 65/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1628 - accuracy: 0.9351 - val_loss: 0.1868 - val_accuracy: 0.9192\n",
            "Epoch 66/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1625 - accuracy: 0.9353 - val_loss: 0.1861 - val_accuracy: 0.9204\n",
            "Epoch 67/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.9347 - val_loss: 0.1865 - val_accuracy: 0.9188\n",
            "Epoch 68/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1620 - accuracy: 0.9361 - val_loss: 0.1854 - val_accuracy: 0.9204\n",
            "Epoch 69/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1618 - accuracy: 0.9344 - val_loss: 0.1851 - val_accuracy: 0.9204\n",
            "Epoch 70/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1615 - accuracy: 0.9365 - val_loss: 0.1853 - val_accuracy: 0.9196\n",
            "Epoch 71/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1613 - accuracy: 0.9357 - val_loss: 0.1848 - val_accuracy: 0.9204\n",
            "Epoch 72/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1610 - accuracy: 0.9356 - val_loss: 0.1852 - val_accuracy: 0.9192\n",
            "Epoch 73/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1608 - accuracy: 0.9361 - val_loss: 0.1847 - val_accuracy: 0.9200\n",
            "Epoch 74/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1605 - accuracy: 0.9356 - val_loss: 0.1847 - val_accuracy: 0.9196\n",
            "Epoch 75/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1603 - accuracy: 0.9367 - val_loss: 0.1841 - val_accuracy: 0.9208\n",
            "Epoch 76/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1600 - accuracy: 0.9375 - val_loss: 0.1837 - val_accuracy: 0.9204\n",
            "Epoch 77/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1597 - accuracy: 0.9369 - val_loss: 0.1826 - val_accuracy: 0.9208\n",
            "Epoch 78/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1595 - accuracy: 0.9368 - val_loss: 0.1829 - val_accuracy: 0.9204\n",
            "Epoch 79/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1591 - accuracy: 0.9371 - val_loss: 0.1829 - val_accuracy: 0.9216\n",
            "Epoch 80/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1588 - accuracy: 0.9371 - val_loss: 0.1823 - val_accuracy: 0.9212\n",
            "Epoch 81/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1587 - accuracy: 0.9369 - val_loss: 0.1825 - val_accuracy: 0.9208\n",
            "Epoch 82/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1583 - accuracy: 0.9375 - val_loss: 0.1822 - val_accuracy: 0.9204\n",
            "Epoch 83/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1581 - accuracy: 0.9379 - val_loss: 0.1814 - val_accuracy: 0.9212\n",
            "Epoch 84/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1579 - accuracy: 0.9375 - val_loss: 0.1811 - val_accuracy: 0.9220\n",
            "Epoch 85/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1575 - accuracy: 0.9381 - val_loss: 0.1802 - val_accuracy: 0.9212\n",
            "Epoch 86/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1572 - accuracy: 0.9384 - val_loss: 0.1802 - val_accuracy: 0.9220\n",
            "Epoch 87/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1569 - accuracy: 0.9385 - val_loss: 0.1801 - val_accuracy: 0.9216\n",
            "Epoch 88/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1565 - accuracy: 0.9381 - val_loss: 0.1788 - val_accuracy: 0.9232\n",
            "Epoch 89/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1562 - accuracy: 0.9393 - val_loss: 0.1789 - val_accuracy: 0.9220\n",
            "Epoch 90/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1560 - accuracy: 0.9388 - val_loss: 0.1786 - val_accuracy: 0.9232\n",
            "Epoch 91/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1556 - accuracy: 0.9396 - val_loss: 0.1778 - val_accuracy: 0.9228\n",
            "Epoch 92/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1552 - accuracy: 0.9389 - val_loss: 0.1775 - val_accuracy: 0.9224\n",
            "Epoch 93/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1550 - accuracy: 0.9396 - val_loss: 0.1782 - val_accuracy: 0.9220\n",
            "Epoch 94/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1546 - accuracy: 0.9392 - val_loss: 0.1769 - val_accuracy: 0.9236\n",
            "Epoch 95/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1543 - accuracy: 0.9400 - val_loss: 0.1775 - val_accuracy: 0.9228\n",
            "Epoch 96/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1539 - accuracy: 0.9395 - val_loss: 0.1766 - val_accuracy: 0.9240\n",
            "Epoch 97/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1533 - accuracy: 0.9399 - val_loss: 0.1752 - val_accuracy: 0.9256\n",
            "Epoch 98/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1532 - accuracy: 0.9404 - val_loss: 0.1763 - val_accuracy: 0.9228\n",
            "Epoch 99/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1526 - accuracy: 0.9407 - val_loss: 0.1756 - val_accuracy: 0.9240\n",
            "Epoch 100/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1522 - accuracy: 0.9404 - val_loss: 0.1743 - val_accuracy: 0.9244\n",
            "Epoch 101/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1519 - accuracy: 0.9412 - val_loss: 0.1743 - val_accuracy: 0.9252\n",
            "Epoch 102/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1513 - accuracy: 0.9396 - val_loss: 0.1724 - val_accuracy: 0.9276\n",
            "Epoch 103/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1511 - accuracy: 0.9411 - val_loss: 0.1720 - val_accuracy: 0.9268\n",
            "Epoch 104/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1506 - accuracy: 0.9421 - val_loss: 0.1738 - val_accuracy: 0.9244\n",
            "Epoch 105/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1502 - accuracy: 0.9413 - val_loss: 0.1719 - val_accuracy: 0.9264\n",
            "Epoch 106/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1497 - accuracy: 0.9416 - val_loss: 0.1717 - val_accuracy: 0.9268\n",
            "Epoch 107/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1492 - accuracy: 0.9427 - val_loss: 0.1715 - val_accuracy: 0.9268\n",
            "Epoch 108/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1487 - accuracy: 0.9412 - val_loss: 0.1706 - val_accuracy: 0.9264\n",
            "Epoch 109/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1483 - accuracy: 0.9421 - val_loss: 0.1698 - val_accuracy: 0.9272\n",
            "Epoch 110/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1476 - accuracy: 0.9417 - val_loss: 0.1689 - val_accuracy: 0.9288\n",
            "Epoch 111/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1472 - accuracy: 0.9428 - val_loss: 0.1682 - val_accuracy: 0.9284\n",
            "Epoch 112/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1468 - accuracy: 0.9427 - val_loss: 0.1679 - val_accuracy: 0.9276\n",
            "Epoch 113/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1463 - accuracy: 0.9427 - val_loss: 0.1672 - val_accuracy: 0.9288\n",
            "Epoch 114/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1456 - accuracy: 0.9429 - val_loss: 0.1682 - val_accuracy: 0.9284\n",
            "Epoch 115/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1453 - accuracy: 0.9429 - val_loss: 0.1662 - val_accuracy: 0.9300\n",
            "Epoch 116/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1447 - accuracy: 0.9431 - val_loss: 0.1650 - val_accuracy: 0.9292\n",
            "Epoch 117/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1441 - accuracy: 0.9428 - val_loss: 0.1638 - val_accuracy: 0.9316\n",
            "Epoch 118/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1433 - accuracy: 0.9443 - val_loss: 0.1634 - val_accuracy: 0.9320\n",
            "Epoch 119/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1429 - accuracy: 0.9441 - val_loss: 0.1649 - val_accuracy: 0.9304\n",
            "Epoch 120/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1421 - accuracy: 0.9447 - val_loss: 0.1620 - val_accuracy: 0.9320\n",
            "Epoch 121/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1415 - accuracy: 0.9452 - val_loss: 0.1632 - val_accuracy: 0.9316\n",
            "Epoch 122/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1412 - accuracy: 0.9449 - val_loss: 0.1616 - val_accuracy: 0.9328\n",
            "Epoch 123/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1404 - accuracy: 0.9456 - val_loss: 0.1623 - val_accuracy: 0.9308\n",
            "Epoch 124/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1400 - accuracy: 0.9448 - val_loss: 0.1601 - val_accuracy: 0.9312\n",
            "Epoch 125/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1393 - accuracy: 0.9460 - val_loss: 0.1584 - val_accuracy: 0.9336\n",
            "Epoch 126/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1383 - accuracy: 0.9465 - val_loss: 0.1594 - val_accuracy: 0.9320\n",
            "Epoch 127/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1379 - accuracy: 0.9455 - val_loss: 0.1565 - val_accuracy: 0.9364\n",
            "Epoch 128/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1373 - accuracy: 0.9475 - val_loss: 0.1550 - val_accuracy: 0.9344\n",
            "Epoch 129/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1366 - accuracy: 0.9475 - val_loss: 0.1554 - val_accuracy: 0.9352\n",
            "Epoch 130/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1359 - accuracy: 0.9480 - val_loss: 0.1552 - val_accuracy: 0.9360\n",
            "Epoch 131/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1354 - accuracy: 0.9477 - val_loss: 0.1547 - val_accuracy: 0.9356\n",
            "Epoch 132/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1344 - accuracy: 0.9481 - val_loss: 0.1519 - val_accuracy: 0.9372\n",
            "Epoch 133/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1337 - accuracy: 0.9493 - val_loss: 0.1535 - val_accuracy: 0.9368\n",
            "Epoch 134/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1331 - accuracy: 0.9495 - val_loss: 0.1503 - val_accuracy: 0.9400\n",
            "Epoch 135/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1324 - accuracy: 0.9501 - val_loss: 0.1524 - val_accuracy: 0.9364\n",
            "Epoch 136/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1316 - accuracy: 0.9509 - val_loss: 0.1509 - val_accuracy: 0.9376\n",
            "Epoch 137/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1308 - accuracy: 0.9509 - val_loss: 0.1493 - val_accuracy: 0.9400\n",
            "Epoch 138/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1301 - accuracy: 0.9503 - val_loss: 0.1462 - val_accuracy: 0.9436\n",
            "Epoch 139/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1295 - accuracy: 0.9515 - val_loss: 0.1464 - val_accuracy: 0.9440\n",
            "Epoch 140/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1287 - accuracy: 0.9519 - val_loss: 0.1455 - val_accuracy: 0.9432\n",
            "Epoch 141/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1279 - accuracy: 0.9520 - val_loss: 0.1443 - val_accuracy: 0.9440\n",
            "Epoch 142/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1271 - accuracy: 0.9536 - val_loss: 0.1438 - val_accuracy: 0.9448\n",
            "Epoch 143/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1262 - accuracy: 0.9523 - val_loss: 0.1460 - val_accuracy: 0.9384\n",
            "Epoch 144/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1257 - accuracy: 0.9533 - val_loss: 0.1435 - val_accuracy: 0.9436\n",
            "Epoch 145/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1248 - accuracy: 0.9539 - val_loss: 0.1472 - val_accuracy: 0.9392\n",
            "Epoch 146/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1244 - accuracy: 0.9537 - val_loss: 0.1408 - val_accuracy: 0.9448\n",
            "Epoch 147/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1236 - accuracy: 0.9545 - val_loss: 0.1413 - val_accuracy: 0.9432\n",
            "Epoch 148/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1229 - accuracy: 0.9548 - val_loss: 0.1397 - val_accuracy: 0.9460\n",
            "Epoch 149/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1223 - accuracy: 0.9545 - val_loss: 0.1394 - val_accuracy: 0.9460\n",
            "Epoch 150/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1214 - accuracy: 0.9563 - val_loss: 0.1378 - val_accuracy: 0.9460\n",
            "Epoch 151/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1205 - accuracy: 0.9565 - val_loss: 0.1372 - val_accuracy: 0.9464\n",
            "Epoch 152/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1194 - accuracy: 0.9557 - val_loss: 0.1358 - val_accuracy: 0.9488\n",
            "Epoch 153/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1195 - accuracy: 0.9555 - val_loss: 0.1351 - val_accuracy: 0.9464\n",
            "Epoch 154/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1186 - accuracy: 0.9571 - val_loss: 0.1359 - val_accuracy: 0.9444\n",
            "Epoch 155/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1175 - accuracy: 0.9573 - val_loss: 0.1345 - val_accuracy: 0.9472\n",
            "Epoch 156/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1172 - accuracy: 0.9571 - val_loss: 0.1341 - val_accuracy: 0.9480\n",
            "Epoch 157/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1165 - accuracy: 0.9579 - val_loss: 0.1326 - val_accuracy: 0.9472\n",
            "Epoch 158/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1155 - accuracy: 0.9572 - val_loss: 0.1301 - val_accuracy: 0.9536\n",
            "Epoch 159/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1149 - accuracy: 0.9568 - val_loss: 0.1306 - val_accuracy: 0.9524\n",
            "Epoch 160/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1147 - accuracy: 0.9588 - val_loss: 0.1291 - val_accuracy: 0.9524\n",
            "Epoch 161/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1139 - accuracy: 0.9587 - val_loss: 0.1285 - val_accuracy: 0.9536\n",
            "Epoch 162/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1132 - accuracy: 0.9593 - val_loss: 0.1292 - val_accuracy: 0.9504\n",
            "Epoch 163/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1125 - accuracy: 0.9609 - val_loss: 0.1258 - val_accuracy: 0.9556\n",
            "Epoch 164/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1116 - accuracy: 0.9605 - val_loss: 0.1290 - val_accuracy: 0.9488\n",
            "Epoch 165/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1114 - accuracy: 0.9601 - val_loss: 0.1253 - val_accuracy: 0.9540\n",
            "Epoch 166/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1106 - accuracy: 0.9613 - val_loss: 0.1274 - val_accuracy: 0.9500\n",
            "Epoch 167/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1102 - accuracy: 0.9612 - val_loss: 0.1244 - val_accuracy: 0.9548\n",
            "Epoch 168/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1092 - accuracy: 0.9625 - val_loss: 0.1284 - val_accuracy: 0.9516\n",
            "Epoch 169/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1090 - accuracy: 0.9633 - val_loss: 0.1231 - val_accuracy: 0.9556\n",
            "Epoch 170/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1086 - accuracy: 0.9628 - val_loss: 0.1226 - val_accuracy: 0.9552\n",
            "Epoch 171/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1081 - accuracy: 0.9631 - val_loss: 0.1232 - val_accuracy: 0.9548\n",
            "Epoch 172/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1075 - accuracy: 0.9635 - val_loss: 0.1217 - val_accuracy: 0.9564\n",
            "Epoch 173/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1068 - accuracy: 0.9636 - val_loss: 0.1203 - val_accuracy: 0.9596\n",
            "Epoch 174/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1060 - accuracy: 0.9649 - val_loss: 0.1215 - val_accuracy: 0.9556\n",
            "Epoch 175/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1060 - accuracy: 0.9645 - val_loss: 0.1199 - val_accuracy: 0.9568\n",
            "Epoch 176/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1052 - accuracy: 0.9651 - val_loss: 0.1196 - val_accuracy: 0.9568\n",
            "Epoch 177/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1049 - accuracy: 0.9657 - val_loss: 0.1197 - val_accuracy: 0.9572\n",
            "Epoch 178/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1044 - accuracy: 0.9656 - val_loss: 0.1176 - val_accuracy: 0.9584\n",
            "Epoch 179/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1039 - accuracy: 0.9659 - val_loss: 0.1164 - val_accuracy: 0.9600\n",
            "Epoch 180/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1036 - accuracy: 0.9655 - val_loss: 0.1173 - val_accuracy: 0.9588\n",
            "Epoch 181/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1030 - accuracy: 0.9667 - val_loss: 0.1157 - val_accuracy: 0.9616\n",
            "Epoch 182/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1023 - accuracy: 0.9669 - val_loss: 0.1147 - val_accuracy: 0.9604\n",
            "Epoch 183/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1022 - accuracy: 0.9663 - val_loss: 0.1169 - val_accuracy: 0.9580\n",
            "Epoch 184/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1018 - accuracy: 0.9657 - val_loss: 0.1136 - val_accuracy: 0.9620\n",
            "Epoch 185/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1015 - accuracy: 0.9664 - val_loss: 0.1136 - val_accuracy: 0.9608\n",
            "Epoch 186/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1009 - accuracy: 0.9663 - val_loss: 0.1126 - val_accuracy: 0.9616\n",
            "Epoch 187/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.1003 - accuracy: 0.9669 - val_loss: 0.1149 - val_accuracy: 0.9584\n",
            "Epoch 188/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.1004 - accuracy: 0.9665 - val_loss: 0.1147 - val_accuracy: 0.9572\n",
            "Epoch 189/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0998 - accuracy: 0.9671 - val_loss: 0.1124 - val_accuracy: 0.9612\n",
            "Epoch 190/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0993 - accuracy: 0.9673 - val_loss: 0.1111 - val_accuracy: 0.9648\n",
            "Epoch 191/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0992 - accuracy: 0.9683 - val_loss: 0.1105 - val_accuracy: 0.9640\n",
            "Epoch 192/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0986 - accuracy: 0.9687 - val_loss: 0.1107 - val_accuracy: 0.9624\n",
            "Epoch 193/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0983 - accuracy: 0.9679 - val_loss: 0.1108 - val_accuracy: 0.9628\n",
            "Epoch 194/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0981 - accuracy: 0.9680 - val_loss: 0.1093 - val_accuracy: 0.9656\n",
            "Epoch 195/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9693 - val_loss: 0.1098 - val_accuracy: 0.9616\n",
            "Epoch 196/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0972 - accuracy: 0.9689 - val_loss: 0.1104 - val_accuracy: 0.9612\n",
            "Epoch 197/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0967 - accuracy: 0.9689 - val_loss: 0.1099 - val_accuracy: 0.9604\n",
            "Epoch 198/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0964 - accuracy: 0.9685 - val_loss: 0.1102 - val_accuracy: 0.9596\n",
            "Epoch 199/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0961 - accuracy: 0.9692 - val_loss: 0.1100 - val_accuracy: 0.9608\n",
            "Epoch 200/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0959 - accuracy: 0.9695 - val_loss: 0.1099 - val_accuracy: 0.9596\n",
            "Epoch 201/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0955 - accuracy: 0.9684 - val_loss: 0.1079 - val_accuracy: 0.9636\n",
            "Epoch 202/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0954 - accuracy: 0.9701 - val_loss: 0.1089 - val_accuracy: 0.9600\n",
            "Epoch 203/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0950 - accuracy: 0.9697 - val_loss: 0.1067 - val_accuracy: 0.9636\n",
            "Epoch 204/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0949 - accuracy: 0.9683 - val_loss: 0.1057 - val_accuracy: 0.9624\n",
            "Epoch 205/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0943 - accuracy: 0.9693 - val_loss: 0.1050 - val_accuracy: 0.9656\n",
            "Epoch 206/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0942 - accuracy: 0.9693 - val_loss: 0.1056 - val_accuracy: 0.9660\n",
            "Epoch 207/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0940 - accuracy: 0.9697 - val_loss: 0.1054 - val_accuracy: 0.9628\n",
            "Epoch 208/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0934 - accuracy: 0.9699 - val_loss: 0.1052 - val_accuracy: 0.9656\n",
            "Epoch 209/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0932 - accuracy: 0.9703 - val_loss: 0.1069 - val_accuracy: 0.9600\n",
            "Epoch 210/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0931 - accuracy: 0.9700 - val_loss: 0.1095 - val_accuracy: 0.9580\n",
            "Epoch 211/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0930 - accuracy: 0.9697 - val_loss: 0.1046 - val_accuracy: 0.9608\n",
            "Epoch 212/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0925 - accuracy: 0.9704 - val_loss: 0.1057 - val_accuracy: 0.9612\n",
            "Epoch 213/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0921 - accuracy: 0.9705 - val_loss: 0.1025 - val_accuracy: 0.9692\n",
            "Epoch 214/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0922 - accuracy: 0.9703 - val_loss: 0.1059 - val_accuracy: 0.9632\n",
            "Epoch 215/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0917 - accuracy: 0.9703 - val_loss: 0.1045 - val_accuracy: 0.9624\n",
            "Epoch 216/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0918 - accuracy: 0.9700 - val_loss: 0.1019 - val_accuracy: 0.9660\n",
            "Epoch 217/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0914 - accuracy: 0.9705 - val_loss: 0.1037 - val_accuracy: 0.9604\n",
            "Epoch 218/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0909 - accuracy: 0.9705 - val_loss: 0.1023 - val_accuracy: 0.9676\n",
            "Epoch 219/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0909 - accuracy: 0.9705 - val_loss: 0.1011 - val_accuracy: 0.9656\n",
            "Epoch 220/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0904 - accuracy: 0.9708 - val_loss: 0.1011 - val_accuracy: 0.9668\n",
            "Epoch 221/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0904 - accuracy: 0.9699 - val_loss: 0.1027 - val_accuracy: 0.9620\n",
            "Epoch 222/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0899 - accuracy: 0.9715 - val_loss: 0.1008 - val_accuracy: 0.9656\n",
            "Epoch 223/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 0.9703 - val_loss: 0.1033 - val_accuracy: 0.9672\n",
            "Epoch 224/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0901 - accuracy: 0.9705 - val_loss: 0.0999 - val_accuracy: 0.9684\n",
            "Epoch 225/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0894 - accuracy: 0.9707 - val_loss: 0.0993 - val_accuracy: 0.9684\n",
            "Epoch 226/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0890 - accuracy: 0.9704 - val_loss: 0.1038 - val_accuracy: 0.9616\n",
            "Epoch 227/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0890 - accuracy: 0.9707 - val_loss: 0.0998 - val_accuracy: 0.9680\n",
            "Epoch 228/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0886 - accuracy: 0.9716 - val_loss: 0.0992 - val_accuracy: 0.9668\n",
            "Epoch 229/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0887 - accuracy: 0.9709 - val_loss: 0.1006 - val_accuracy: 0.9652\n",
            "Epoch 230/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0885 - accuracy: 0.9711 - val_loss: 0.0987 - val_accuracy: 0.9696\n",
            "Epoch 231/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0882 - accuracy: 0.9712 - val_loss: 0.0988 - val_accuracy: 0.9688\n",
            "Epoch 232/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0881 - accuracy: 0.9715 - val_loss: 0.0980 - val_accuracy: 0.9676\n",
            "Epoch 233/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0874 - accuracy: 0.9716 - val_loss: 0.0991 - val_accuracy: 0.9664\n",
            "Epoch 234/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0876 - accuracy: 0.9716 - val_loss: 0.0991 - val_accuracy: 0.9660\n",
            "Epoch 235/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0875 - accuracy: 0.9716 - val_loss: 0.0978 - val_accuracy: 0.9692\n",
            "Epoch 236/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0869 - accuracy: 0.9728 - val_loss: 0.0980 - val_accuracy: 0.9692\n",
            "Epoch 237/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0868 - accuracy: 0.9711 - val_loss: 0.0962 - val_accuracy: 0.9680\n",
            "Epoch 238/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0867 - accuracy: 0.9716 - val_loss: 0.0965 - val_accuracy: 0.9688\n",
            "Epoch 239/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0864 - accuracy: 0.9713 - val_loss: 0.1004 - val_accuracy: 0.9628\n",
            "Epoch 240/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0863 - accuracy: 0.9720 - val_loss: 0.0976 - val_accuracy: 0.9668\n",
            "Epoch 241/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0861 - accuracy: 0.9724 - val_loss: 0.0962 - val_accuracy: 0.9688\n",
            "Epoch 242/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0860 - accuracy: 0.9725 - val_loss: 0.0968 - val_accuracy: 0.9676\n",
            "Epoch 243/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0859 - accuracy: 0.9727 - val_loss: 0.0954 - val_accuracy: 0.9688\n",
            "Epoch 244/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0858 - accuracy: 0.9720 - val_loss: 0.0952 - val_accuracy: 0.9688\n",
            "Epoch 245/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0855 - accuracy: 0.9717 - val_loss: 0.0953 - val_accuracy: 0.9688\n",
            "Epoch 246/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0852 - accuracy: 0.9725 - val_loss: 0.0954 - val_accuracy: 0.9676\n",
            "Epoch 247/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0851 - accuracy: 0.9719 - val_loss: 0.0941 - val_accuracy: 0.9692\n",
            "Epoch 248/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0849 - accuracy: 0.9720 - val_loss: 0.0943 - val_accuracy: 0.9680\n",
            "Epoch 249/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0848 - accuracy: 0.9721 - val_loss: 0.0948 - val_accuracy: 0.9688\n",
            "Epoch 250/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0843 - accuracy: 0.9721 - val_loss: 0.0949 - val_accuracy: 0.9688\n",
            "Epoch 251/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0842 - accuracy: 0.9723 - val_loss: 0.1208 - val_accuracy: 0.9536\n",
            "Epoch 252/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0846 - accuracy: 0.9727 - val_loss: 0.0944 - val_accuracy: 0.9688\n",
            "Epoch 253/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0839 - accuracy: 0.9723 - val_loss: 0.0941 - val_accuracy: 0.9692\n",
            "Epoch 254/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0840 - accuracy: 0.9727 - val_loss: 0.0943 - val_accuracy: 0.9692\n",
            "Epoch 255/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0836 - accuracy: 0.9719 - val_loss: 0.0934 - val_accuracy: 0.9700\n",
            "Epoch 256/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0836 - accuracy: 0.9725 - val_loss: 0.0934 - val_accuracy: 0.9692\n",
            "Epoch 257/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0834 - accuracy: 0.9727 - val_loss: 0.0937 - val_accuracy: 0.9688\n",
            "Epoch 258/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0830 - accuracy: 0.9719 - val_loss: 0.0926 - val_accuracy: 0.9708\n",
            "Epoch 259/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0829 - accuracy: 0.9727 - val_loss: 0.0935 - val_accuracy: 0.9696\n",
            "Epoch 260/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0825 - accuracy: 0.9729 - val_loss: 0.0928 - val_accuracy: 0.9680\n",
            "Epoch 261/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0826 - accuracy: 0.9733 - val_loss: 0.0943 - val_accuracy: 0.9700\n",
            "Epoch 262/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0825 - accuracy: 0.9728 - val_loss: 0.0943 - val_accuracy: 0.9648\n",
            "Epoch 263/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0822 - accuracy: 0.9724 - val_loss: 0.0961 - val_accuracy: 0.9624\n",
            "Epoch 264/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0826 - accuracy: 0.9725 - val_loss: 0.0921 - val_accuracy: 0.9696\n",
            "Epoch 265/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0821 - accuracy: 0.9732 - val_loss: 0.0909 - val_accuracy: 0.9692\n",
            "Epoch 266/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0821 - accuracy: 0.9728 - val_loss: 0.0913 - val_accuracy: 0.9704\n",
            "Epoch 267/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0817 - accuracy: 0.9736 - val_loss: 0.0927 - val_accuracy: 0.9692\n",
            "Epoch 268/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0816 - accuracy: 0.9720 - val_loss: 0.0915 - val_accuracy: 0.9696\n",
            "Epoch 269/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0813 - accuracy: 0.9729 - val_loss: 0.0914 - val_accuracy: 0.9688\n",
            "Epoch 270/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0812 - accuracy: 0.9737 - val_loss: 0.0930 - val_accuracy: 0.9664\n",
            "Epoch 271/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0809 - accuracy: 0.9733 - val_loss: 0.0909 - val_accuracy: 0.9704\n",
            "Epoch 272/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0811 - accuracy: 0.9735 - val_loss: 0.0945 - val_accuracy: 0.9672\n",
            "Epoch 273/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0808 - accuracy: 0.9732 - val_loss: 0.0901 - val_accuracy: 0.9696\n",
            "Epoch 274/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0806 - accuracy: 0.9739 - val_loss: 0.0911 - val_accuracy: 0.9680\n",
            "Epoch 275/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0806 - accuracy: 0.9735 - val_loss: 0.0900 - val_accuracy: 0.9704\n",
            "Epoch 276/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0805 - accuracy: 0.9744 - val_loss: 0.0899 - val_accuracy: 0.9700\n",
            "Epoch 277/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0801 - accuracy: 0.9743 - val_loss: 0.0895 - val_accuracy: 0.9700\n",
            "Epoch 278/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0799 - accuracy: 0.9737 - val_loss: 0.0902 - val_accuracy: 0.9704\n",
            "Epoch 279/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0800 - accuracy: 0.9739 - val_loss: 0.0901 - val_accuracy: 0.9700\n",
            "Epoch 280/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0797 - accuracy: 0.9737 - val_loss: 0.0893 - val_accuracy: 0.9696\n",
            "Epoch 281/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0796 - accuracy: 0.9740 - val_loss: 0.0899 - val_accuracy: 0.9700\n",
            "Epoch 282/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0793 - accuracy: 0.9740 - val_loss: 0.0886 - val_accuracy: 0.9696\n",
            "Epoch 283/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0793 - accuracy: 0.9741 - val_loss: 0.0897 - val_accuracy: 0.9696\n",
            "Epoch 284/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0790 - accuracy: 0.9741 - val_loss: 0.0902 - val_accuracy: 0.9688\n",
            "Epoch 285/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0790 - accuracy: 0.9732 - val_loss: 0.0884 - val_accuracy: 0.9700\n",
            "Epoch 286/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0784 - accuracy: 0.9749 - val_loss: 0.0880 - val_accuracy: 0.9712\n",
            "Epoch 287/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0785 - accuracy: 0.9745 - val_loss: 0.0886 - val_accuracy: 0.9700\n",
            "Epoch 288/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0782 - accuracy: 0.9739 - val_loss: 0.0888 - val_accuracy: 0.9688\n",
            "Epoch 289/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0782 - accuracy: 0.9741 - val_loss: 0.0874 - val_accuracy: 0.9696\n",
            "Epoch 290/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0779 - accuracy: 0.9749 - val_loss: 0.0879 - val_accuracy: 0.9704\n",
            "Epoch 291/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0779 - accuracy: 0.9744 - val_loss: 0.0875 - val_accuracy: 0.9688\n",
            "Epoch 292/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0779 - accuracy: 0.9743 - val_loss: 0.0871 - val_accuracy: 0.9704\n",
            "Epoch 293/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0775 - accuracy: 0.9745 - val_loss: 0.0871 - val_accuracy: 0.9700\n",
            "Epoch 294/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0777 - accuracy: 0.9732 - val_loss: 0.0876 - val_accuracy: 0.9704\n",
            "Epoch 295/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0774 - accuracy: 0.9745 - val_loss: 0.0885 - val_accuracy: 0.9692\n",
            "Epoch 296/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0772 - accuracy: 0.9748 - val_loss: 0.0887 - val_accuracy: 0.9692\n",
            "Epoch 297/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0772 - accuracy: 0.9744 - val_loss: 0.0861 - val_accuracy: 0.9700\n",
            "Epoch 298/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0766 - accuracy: 0.9756 - val_loss: 0.0864 - val_accuracy: 0.9692\n",
            "Epoch 299/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0769 - accuracy: 0.9747 - val_loss: 0.0863 - val_accuracy: 0.9704\n",
            "Epoch 300/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0765 - accuracy: 0.9747 - val_loss: 0.0864 - val_accuracy: 0.9700\n",
            "Epoch 301/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0761 - accuracy: 0.9747 - val_loss: 0.0868 - val_accuracy: 0.9704\n",
            "Epoch 302/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0765 - accuracy: 0.9753 - val_loss: 0.0867 - val_accuracy: 0.9708\n",
            "Epoch 303/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0761 - accuracy: 0.9756 - val_loss: 0.0869 - val_accuracy: 0.9696\n",
            "Epoch 304/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0761 - accuracy: 0.9748 - val_loss: 0.0854 - val_accuracy: 0.9724\n",
            "Epoch 305/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0756 - accuracy: 0.9751 - val_loss: 0.0849 - val_accuracy: 0.9708\n",
            "Epoch 306/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0756 - accuracy: 0.9756 - val_loss: 0.0848 - val_accuracy: 0.9712\n",
            "Epoch 307/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0754 - accuracy: 0.9759 - val_loss: 0.0848 - val_accuracy: 0.9704\n",
            "Epoch 308/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0752 - accuracy: 0.9757 - val_loss: 0.0846 - val_accuracy: 0.9712\n",
            "Epoch 309/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0750 - accuracy: 0.9752 - val_loss: 0.0844 - val_accuracy: 0.9712\n",
            "Epoch 310/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0749 - accuracy: 0.9759 - val_loss: 0.0851 - val_accuracy: 0.9704\n",
            "Epoch 311/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0745 - accuracy: 0.9753 - val_loss: 0.0841 - val_accuracy: 0.9708\n",
            "Epoch 312/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0745 - accuracy: 0.9760 - val_loss: 0.0834 - val_accuracy: 0.9696\n",
            "Epoch 313/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0748 - accuracy: 0.9760 - val_loss: 0.0831 - val_accuracy: 0.9708\n",
            "Epoch 314/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0741 - accuracy: 0.9753 - val_loss: 0.0833 - val_accuracy: 0.9704\n",
            "Epoch 315/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0738 - accuracy: 0.9764 - val_loss: 0.0848 - val_accuracy: 0.9712\n",
            "Epoch 316/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0739 - accuracy: 0.9765 - val_loss: 0.0832 - val_accuracy: 0.9708\n",
            "Epoch 317/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0734 - accuracy: 0.9763 - val_loss: 0.0885 - val_accuracy: 0.9684\n",
            "Epoch 318/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0737 - accuracy: 0.9761 - val_loss: 0.0831 - val_accuracy: 0.9720\n",
            "Epoch 319/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0732 - accuracy: 0.9763 - val_loss: 0.0852 - val_accuracy: 0.9712\n",
            "Epoch 320/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0733 - accuracy: 0.9765 - val_loss: 0.0834 - val_accuracy: 0.9704\n",
            "Epoch 321/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0729 - accuracy: 0.9763 - val_loss: 0.0854 - val_accuracy: 0.9696\n",
            "Epoch 322/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0731 - accuracy: 0.9769 - val_loss: 0.0819 - val_accuracy: 0.9708\n",
            "Epoch 323/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0730 - accuracy: 0.9763 - val_loss: 0.0826 - val_accuracy: 0.9716\n",
            "Epoch 324/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0727 - accuracy: 0.9772 - val_loss: 0.0816 - val_accuracy: 0.9716\n",
            "Epoch 325/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0724 - accuracy: 0.9759 - val_loss: 0.0835 - val_accuracy: 0.9708\n",
            "Epoch 326/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0722 - accuracy: 0.9765 - val_loss: 0.0824 - val_accuracy: 0.9712\n",
            "Epoch 327/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0722 - accuracy: 0.9773 - val_loss: 0.0827 - val_accuracy: 0.9716\n",
            "Epoch 328/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0717 - accuracy: 0.9771 - val_loss: 0.0815 - val_accuracy: 0.9728\n",
            "Epoch 329/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0719 - accuracy: 0.9772 - val_loss: 0.0815 - val_accuracy: 0.9724\n",
            "Epoch 330/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0716 - accuracy: 0.9776 - val_loss: 0.0811 - val_accuracy: 0.9716\n",
            "Epoch 331/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0718 - accuracy: 0.9768 - val_loss: 0.0812 - val_accuracy: 0.9712\n",
            "Epoch 332/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0712 - accuracy: 0.9775 - val_loss: 0.0811 - val_accuracy: 0.9712\n",
            "Epoch 333/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0715 - accuracy: 0.9773 - val_loss: 0.0802 - val_accuracy: 0.9712\n",
            "Epoch 334/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0712 - accuracy: 0.9780 - val_loss: 0.0796 - val_accuracy: 0.9724\n",
            "Epoch 335/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0710 - accuracy: 0.9777 - val_loss: 0.0815 - val_accuracy: 0.9732\n",
            "Epoch 336/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0710 - accuracy: 0.9776 - val_loss: 0.0795 - val_accuracy: 0.9728\n",
            "Epoch 337/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0704 - accuracy: 0.9777 - val_loss: 0.0806 - val_accuracy: 0.9728\n",
            "Epoch 338/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0705 - accuracy: 0.9781 - val_loss: 0.0817 - val_accuracy: 0.9700\n",
            "Epoch 339/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0701 - accuracy: 0.9783 - val_loss: 0.0788 - val_accuracy: 0.9732\n",
            "Epoch 340/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0701 - accuracy: 0.9783 - val_loss: 0.0793 - val_accuracy: 0.9720\n",
            "Epoch 341/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0702 - accuracy: 0.9776 - val_loss: 0.0817 - val_accuracy: 0.9728\n",
            "Epoch 342/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0700 - accuracy: 0.9783 - val_loss: 0.0789 - val_accuracy: 0.9736\n",
            "Epoch 343/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0698 - accuracy: 0.9780 - val_loss: 0.0820 - val_accuracy: 0.9740\n",
            "Epoch 344/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0697 - accuracy: 0.9785 - val_loss: 0.0794 - val_accuracy: 0.9720\n",
            "Epoch 345/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0696 - accuracy: 0.9779 - val_loss: 0.0785 - val_accuracy: 0.9716\n",
            "Epoch 346/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0693 - accuracy: 0.9780 - val_loss: 0.0774 - val_accuracy: 0.9740\n",
            "Epoch 347/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0693 - accuracy: 0.9783 - val_loss: 0.0785 - val_accuracy: 0.9720\n",
            "Epoch 348/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0691 - accuracy: 0.9792 - val_loss: 0.0772 - val_accuracy: 0.9732\n",
            "Epoch 349/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0689 - accuracy: 0.9791 - val_loss: 0.0787 - val_accuracy: 0.9724\n",
            "Epoch 350/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0689 - accuracy: 0.9781 - val_loss: 0.0779 - val_accuracy: 0.9724\n",
            "Epoch 351/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0686 - accuracy: 0.9784 - val_loss: 0.0808 - val_accuracy: 0.9708\n",
            "Epoch 352/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0686 - accuracy: 0.9781 - val_loss: 0.0783 - val_accuracy: 0.9716\n",
            "Epoch 353/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0684 - accuracy: 0.9792 - val_loss: 0.0774 - val_accuracy: 0.9724\n",
            "Epoch 354/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0682 - accuracy: 0.9789 - val_loss: 0.0767 - val_accuracy: 0.9740\n",
            "Epoch 355/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0680 - accuracy: 0.9789 - val_loss: 0.0769 - val_accuracy: 0.9728\n",
            "Epoch 356/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0680 - accuracy: 0.9788 - val_loss: 0.0767 - val_accuracy: 0.9728\n",
            "Epoch 357/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0676 - accuracy: 0.9792 - val_loss: 0.0805 - val_accuracy: 0.9732\n",
            "Epoch 358/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0676 - accuracy: 0.9793 - val_loss: 0.0788 - val_accuracy: 0.9720\n",
            "Epoch 359/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0675 - accuracy: 0.9791 - val_loss: 0.0767 - val_accuracy: 0.9744\n",
            "Epoch 360/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.9787 - val_loss: 0.0765 - val_accuracy: 0.9720\n",
            "Epoch 361/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0674 - accuracy: 0.9792 - val_loss: 0.0762 - val_accuracy: 0.9736\n",
            "Epoch 362/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0670 - accuracy: 0.9785 - val_loss: 0.0768 - val_accuracy: 0.9724\n",
            "Epoch 363/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0670 - accuracy: 0.9791 - val_loss: 0.0751 - val_accuracy: 0.9748\n",
            "Epoch 364/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0667 - accuracy: 0.9797 - val_loss: 0.0764 - val_accuracy: 0.9728\n",
            "Epoch 365/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0665 - accuracy: 0.9789 - val_loss: 0.0758 - val_accuracy: 0.9736\n",
            "Epoch 366/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0665 - accuracy: 0.9799 - val_loss: 0.0747 - val_accuracy: 0.9732\n",
            "Epoch 367/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0665 - accuracy: 0.9791 - val_loss: 0.0760 - val_accuracy: 0.9760\n",
            "Epoch 368/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0662 - accuracy: 0.9795 - val_loss: 0.0762 - val_accuracy: 0.9720\n",
            "Epoch 369/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0660 - accuracy: 0.9797 - val_loss: 0.0740 - val_accuracy: 0.9740\n",
            "Epoch 370/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0661 - accuracy: 0.9799 - val_loss: 0.0749 - val_accuracy: 0.9744\n",
            "Epoch 371/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0660 - accuracy: 0.9796 - val_loss: 0.0742 - val_accuracy: 0.9748\n",
            "Epoch 372/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0659 - accuracy: 0.9799 - val_loss: 0.0738 - val_accuracy: 0.9756\n",
            "Epoch 373/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0657 - accuracy: 0.9796 - val_loss: 0.0745 - val_accuracy: 0.9736\n",
            "Epoch 374/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0654 - accuracy: 0.9797 - val_loss: 0.0748 - val_accuracy: 0.9724\n",
            "Epoch 375/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0654 - accuracy: 0.9799 - val_loss: 0.0737 - val_accuracy: 0.9744\n",
            "Epoch 376/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0653 - accuracy: 0.9789 - val_loss: 0.0741 - val_accuracy: 0.9752\n",
            "Epoch 377/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0654 - accuracy: 0.9795 - val_loss: 0.0730 - val_accuracy: 0.9740\n",
            "Epoch 378/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0652 - accuracy: 0.9799 - val_loss: 0.0733 - val_accuracy: 0.9748\n",
            "Epoch 379/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0650 - accuracy: 0.9797 - val_loss: 0.0739 - val_accuracy: 0.9736\n",
            "Epoch 380/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0645 - accuracy: 0.9795 - val_loss: 0.0741 - val_accuracy: 0.9744\n",
            "Epoch 381/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0648 - accuracy: 0.9796 - val_loss: 0.0733 - val_accuracy: 0.9740\n",
            "Epoch 382/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0644 - accuracy: 0.9792 - val_loss: 0.0763 - val_accuracy: 0.9720\n",
            "Epoch 383/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0644 - accuracy: 0.9799 - val_loss: 0.0763 - val_accuracy: 0.9716\n",
            "Epoch 384/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0644 - accuracy: 0.9793 - val_loss: 0.0722 - val_accuracy: 0.9764\n",
            "Epoch 385/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0643 - accuracy: 0.9799 - val_loss: 0.0730 - val_accuracy: 0.9748\n",
            "Epoch 386/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0641 - accuracy: 0.9804 - val_loss: 0.0726 - val_accuracy: 0.9740\n",
            "Epoch 387/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0639 - accuracy: 0.9799 - val_loss: 0.0729 - val_accuracy: 0.9732\n",
            "Epoch 388/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0639 - accuracy: 0.9800 - val_loss: 0.0727 - val_accuracy: 0.9740\n",
            "Epoch 389/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0638 - accuracy: 0.9799 - val_loss: 0.0733 - val_accuracy: 0.9736\n",
            "Epoch 390/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0635 - accuracy: 0.9799 - val_loss: 0.0725 - val_accuracy: 0.9736\n",
            "Epoch 391/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0634 - accuracy: 0.9797 - val_loss: 0.0755 - val_accuracy: 0.9756\n",
            "Epoch 392/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0634 - accuracy: 0.9792 - val_loss: 0.0749 - val_accuracy: 0.9728\n",
            "Epoch 393/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0634 - accuracy: 0.9801 - val_loss: 0.0726 - val_accuracy: 0.9736\n",
            "Epoch 394/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0633 - accuracy: 0.9799 - val_loss: 0.0718 - val_accuracy: 0.9752\n",
            "Epoch 395/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0631 - accuracy: 0.9799 - val_loss: 0.0725 - val_accuracy: 0.9724\n",
            "Epoch 396/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0628 - accuracy: 0.9803 - val_loss: 0.0708 - val_accuracy: 0.9748\n",
            "Epoch 397/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0628 - accuracy: 0.9808 - val_loss: 0.0731 - val_accuracy: 0.9740\n",
            "Epoch 398/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0628 - accuracy: 0.9803 - val_loss: 0.0714 - val_accuracy: 0.9740\n",
            "Epoch 399/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0624 - accuracy: 0.9801 - val_loss: 0.0726 - val_accuracy: 0.9760\n",
            "Epoch 400/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0626 - accuracy: 0.9796 - val_loss: 0.0724 - val_accuracy: 0.9752\n",
            "Epoch 401/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0622 - accuracy: 0.9803 - val_loss: 0.0714 - val_accuracy: 0.9748\n",
            "Epoch 402/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0619 - accuracy: 0.9805 - val_loss: 0.0718 - val_accuracy: 0.9740\n",
            "Epoch 403/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0622 - accuracy: 0.9804 - val_loss: 0.0702 - val_accuracy: 0.9756\n",
            "Epoch 404/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0619 - accuracy: 0.9799 - val_loss: 0.0709 - val_accuracy: 0.9732\n",
            "Epoch 405/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0618 - accuracy: 0.9804 - val_loss: 0.0706 - val_accuracy: 0.9744\n",
            "Epoch 406/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0617 - accuracy: 0.9801 - val_loss: 0.0706 - val_accuracy: 0.9744\n",
            "Epoch 407/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0618 - accuracy: 0.9796 - val_loss: 0.0701 - val_accuracy: 0.9752\n",
            "Epoch 408/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0612 - accuracy: 0.9807 - val_loss: 0.0695 - val_accuracy: 0.9756\n",
            "Epoch 409/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0616 - accuracy: 0.9796 - val_loss: 0.0709 - val_accuracy: 0.9760\n",
            "Epoch 410/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0611 - accuracy: 0.9801 - val_loss: 0.0699 - val_accuracy: 0.9756\n",
            "Epoch 411/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0612 - accuracy: 0.9799 - val_loss: 0.0698 - val_accuracy: 0.9760\n",
            "Epoch 412/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0610 - accuracy: 0.9788 - val_loss: 0.0700 - val_accuracy: 0.9756\n",
            "Epoch 413/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0610 - accuracy: 0.9796 - val_loss: 0.0812 - val_accuracy: 0.9744\n",
            "Epoch 414/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0609 - accuracy: 0.9805 - val_loss: 0.0723 - val_accuracy: 0.9740\n",
            "Epoch 415/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0605 - accuracy: 0.9803 - val_loss: 0.0708 - val_accuracy: 0.9744\n",
            "Epoch 416/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0604 - accuracy: 0.9800 - val_loss: 0.0691 - val_accuracy: 0.9752\n",
            "Epoch 417/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0606 - accuracy: 0.9791 - val_loss: 0.0690 - val_accuracy: 0.9756\n",
            "Epoch 418/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0605 - accuracy: 0.9795 - val_loss: 0.0697 - val_accuracy: 0.9748\n",
            "Epoch 419/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0599 - accuracy: 0.9796 - val_loss: 0.0707 - val_accuracy: 0.9748\n",
            "Epoch 420/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0597 - accuracy: 0.9801 - val_loss: 0.0692 - val_accuracy: 0.9752\n",
            "Epoch 421/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0598 - accuracy: 0.9803 - val_loss: 0.0691 - val_accuracy: 0.9756\n",
            "Epoch 422/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0598 - accuracy: 0.9803 - val_loss: 0.0693 - val_accuracy: 0.9748\n",
            "Epoch 423/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0598 - accuracy: 0.9804 - val_loss: 0.0712 - val_accuracy: 0.9760\n",
            "Epoch 424/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0595 - accuracy: 0.9804 - val_loss: 0.0688 - val_accuracy: 0.9748\n",
            "Epoch 425/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0597 - accuracy: 0.9799 - val_loss: 0.0689 - val_accuracy: 0.9748\n",
            "Epoch 426/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0594 - accuracy: 0.9804 - val_loss: 0.0705 - val_accuracy: 0.9764\n",
            "Epoch 427/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0595 - accuracy: 0.9801 - val_loss: 0.0686 - val_accuracy: 0.9752\n",
            "Epoch 428/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0595 - accuracy: 0.9803 - val_loss: 0.0696 - val_accuracy: 0.9756\n",
            "Epoch 429/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0592 - accuracy: 0.9795 - val_loss: 0.0685 - val_accuracy: 0.9756\n",
            "Epoch 430/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0593 - accuracy: 0.9796 - val_loss: 0.0685 - val_accuracy: 0.9764\n",
            "Epoch 431/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0589 - accuracy: 0.9804 - val_loss: 0.0685 - val_accuracy: 0.9756\n",
            "Epoch 432/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0588 - accuracy: 0.9797 - val_loss: 0.0677 - val_accuracy: 0.9760\n",
            "Epoch 433/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0590 - accuracy: 0.9804 - val_loss: 0.0683 - val_accuracy: 0.9760\n",
            "Epoch 434/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0586 - accuracy: 0.9804 - val_loss: 0.0685 - val_accuracy: 0.9752\n",
            "Epoch 435/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0585 - accuracy: 0.9805 - val_loss: 0.0683 - val_accuracy: 0.9756\n",
            "Epoch 436/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0584 - accuracy: 0.9803 - val_loss: 0.0689 - val_accuracy: 0.9752\n",
            "Epoch 437/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0583 - accuracy: 0.9803 - val_loss: 0.0688 - val_accuracy: 0.9756\n",
            "Epoch 438/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0585 - accuracy: 0.9804 - val_loss: 0.0676 - val_accuracy: 0.9756\n",
            "Epoch 439/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0583 - accuracy: 0.9807 - val_loss: 0.0682 - val_accuracy: 0.9752\n",
            "Epoch 440/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0583 - accuracy: 0.9804 - val_loss: 0.0674 - val_accuracy: 0.9756\n",
            "Epoch 441/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0581 - accuracy: 0.9804 - val_loss: 0.0684 - val_accuracy: 0.9748\n",
            "Epoch 442/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0578 - accuracy: 0.9808 - val_loss: 0.0713 - val_accuracy: 0.9744\n",
            "Epoch 443/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0579 - accuracy: 0.9811 - val_loss: 0.0674 - val_accuracy: 0.9764\n",
            "Epoch 444/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0574 - accuracy: 0.9807 - val_loss: 0.0678 - val_accuracy: 0.9756\n",
            "Epoch 445/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0576 - accuracy: 0.9809 - val_loss: 0.0681 - val_accuracy: 0.9760\n",
            "Epoch 446/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0575 - accuracy: 0.9809 - val_loss: 0.0672 - val_accuracy: 0.9760\n",
            "Epoch 447/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0577 - accuracy: 0.9807 - val_loss: 0.0670 - val_accuracy: 0.9756\n",
            "Epoch 448/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0574 - accuracy: 0.9805 - val_loss: 0.0681 - val_accuracy: 0.9756\n",
            "Epoch 449/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0572 - accuracy: 0.9813 - val_loss: 0.0664 - val_accuracy: 0.9756\n",
            "Epoch 450/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0572 - accuracy: 0.9812 - val_loss: 0.0667 - val_accuracy: 0.9760\n",
            "Epoch 451/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0569 - accuracy: 0.9813 - val_loss: 0.0687 - val_accuracy: 0.9752\n",
            "Epoch 452/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0570 - accuracy: 0.9803 - val_loss: 0.0669 - val_accuracy: 0.9768\n",
            "Epoch 453/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0572 - accuracy: 0.9817 - val_loss: 0.0668 - val_accuracy: 0.9756\n",
            "Epoch 454/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0570 - accuracy: 0.9811 - val_loss: 0.0666 - val_accuracy: 0.9764\n",
            "Epoch 455/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0569 - accuracy: 0.9801 - val_loss: 0.0672 - val_accuracy: 0.9768\n",
            "Epoch 456/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0567 - accuracy: 0.9812 - val_loss: 0.0666 - val_accuracy: 0.9756\n",
            "Epoch 457/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0565 - accuracy: 0.9811 - val_loss: 0.0662 - val_accuracy: 0.9764\n",
            "Epoch 458/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0560 - accuracy: 0.9813 - val_loss: 0.0671 - val_accuracy: 0.9752\n",
            "Epoch 459/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0563 - accuracy: 0.9812 - val_loss: 0.0863 - val_accuracy: 0.9684\n",
            "Epoch 460/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0568 - accuracy: 0.9812 - val_loss: 0.0666 - val_accuracy: 0.9764\n",
            "Epoch 461/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0563 - accuracy: 0.9812 - val_loss: 0.0679 - val_accuracy: 0.9760\n",
            "Epoch 462/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0561 - accuracy: 0.9807 - val_loss: 0.0680 - val_accuracy: 0.9768\n",
            "Epoch 463/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0560 - accuracy: 0.9813 - val_loss: 0.0665 - val_accuracy: 0.9772\n",
            "Epoch 464/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0557 - accuracy: 0.9813 - val_loss: 0.0661 - val_accuracy: 0.9772\n",
            "Epoch 465/1500\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 0.0557 - accuracy: 0.9809 - val_loss: 0.0673 - val_accuracy: 0.9756\n",
            "Epoch 466/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0559 - accuracy: 0.9815 - val_loss: 0.0658 - val_accuracy: 0.9784\n",
            "Epoch 467/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0555 - accuracy: 0.9811 - val_loss: 0.0723 - val_accuracy: 0.9740\n",
            "Epoch 468/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0555 - accuracy: 0.9812 - val_loss: 0.0650 - val_accuracy: 0.9772\n",
            "Epoch 469/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0553 - accuracy: 0.9813 - val_loss: 0.0672 - val_accuracy: 0.9772\n",
            "Epoch 470/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0550 - accuracy: 0.9813 - val_loss: 0.0669 - val_accuracy: 0.9768\n",
            "Epoch 471/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0552 - accuracy: 0.9809 - val_loss: 0.0735 - val_accuracy: 0.9732\n",
            "Epoch 472/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0549 - accuracy: 0.9815 - val_loss: 0.0664 - val_accuracy: 0.9768\n",
            "Epoch 473/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0547 - accuracy: 0.9807 - val_loss: 0.0649 - val_accuracy: 0.9776\n",
            "Epoch 474/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0548 - accuracy: 0.9815 - val_loss: 0.0657 - val_accuracy: 0.9784\n",
            "Epoch 475/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0547 - accuracy: 0.9812 - val_loss: 0.0669 - val_accuracy: 0.9768\n",
            "Epoch 476/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0547 - accuracy: 0.9809 - val_loss: 0.0668 - val_accuracy: 0.9772\n",
            "Epoch 477/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0543 - accuracy: 0.9808 - val_loss: 0.0643 - val_accuracy: 0.9772\n",
            "Epoch 478/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0546 - accuracy: 0.9811 - val_loss: 0.0647 - val_accuracy: 0.9776\n",
            "Epoch 479/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0542 - accuracy: 0.9813 - val_loss: 0.0642 - val_accuracy: 0.9772\n",
            "Epoch 480/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0543 - accuracy: 0.9811 - val_loss: 0.0660 - val_accuracy: 0.9764\n",
            "Epoch 481/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0542 - accuracy: 0.9820 - val_loss: 0.0646 - val_accuracy: 0.9784\n",
            "Epoch 482/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0541 - accuracy: 0.9812 - val_loss: 0.0652 - val_accuracy: 0.9780\n",
            "Epoch 483/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0540 - accuracy: 0.9815 - val_loss: 0.0644 - val_accuracy: 0.9768\n",
            "Epoch 484/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0539 - accuracy: 0.9816 - val_loss: 0.0635 - val_accuracy: 0.9780\n",
            "Epoch 485/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0538 - accuracy: 0.9815 - val_loss: 0.0645 - val_accuracy: 0.9768\n",
            "Epoch 486/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0535 - accuracy: 0.9813 - val_loss: 0.0640 - val_accuracy: 0.9772\n",
            "Epoch 487/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0538 - accuracy: 0.9819 - val_loss: 0.0661 - val_accuracy: 0.9776\n",
            "Epoch 488/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0536 - accuracy: 0.9812 - val_loss: 0.0632 - val_accuracy: 0.9776\n",
            "Epoch 489/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0535 - accuracy: 0.9820 - val_loss: 0.0630 - val_accuracy: 0.9784\n",
            "Epoch 490/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0531 - accuracy: 0.9825 - val_loss: 0.0639 - val_accuracy: 0.9780\n",
            "Epoch 491/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0533 - accuracy: 0.9812 - val_loss: 0.0631 - val_accuracy: 0.9780\n",
            "Epoch 492/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0530 - accuracy: 0.9827 - val_loss: 0.0634 - val_accuracy: 0.9776\n",
            "Epoch 493/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0530 - accuracy: 0.9823 - val_loss: 0.0640 - val_accuracy: 0.9784\n",
            "Epoch 494/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0530 - accuracy: 0.9831 - val_loss: 0.0638 - val_accuracy: 0.9776\n",
            "Epoch 495/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0530 - accuracy: 0.9819 - val_loss: 0.0626 - val_accuracy: 0.9788\n",
            "Epoch 496/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0529 - accuracy: 0.9823 - val_loss: 0.0652 - val_accuracy: 0.9784\n",
            "Epoch 497/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0526 - accuracy: 0.9827 - val_loss: 0.0649 - val_accuracy: 0.9772\n",
            "Epoch 498/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0525 - accuracy: 0.9827 - val_loss: 0.0659 - val_accuracy: 0.9772\n",
            "Epoch 499/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0526 - accuracy: 0.9824 - val_loss: 0.0623 - val_accuracy: 0.9788\n",
            "Epoch 500/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0524 - accuracy: 0.9831 - val_loss: 0.0626 - val_accuracy: 0.9780\n",
            "Epoch 501/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0526 - accuracy: 0.9831 - val_loss: 0.0628 - val_accuracy: 0.9784\n",
            "Epoch 502/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0522 - accuracy: 0.9832 - val_loss: 0.0629 - val_accuracy: 0.9784\n",
            "Epoch 503/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0522 - accuracy: 0.9827 - val_loss: 0.0627 - val_accuracy: 0.9784\n",
            "Epoch 504/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0523 - accuracy: 0.9829 - val_loss: 0.0622 - val_accuracy: 0.9784\n",
            "Epoch 505/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0521 - accuracy: 0.9831 - val_loss: 0.0616 - val_accuracy: 0.9780\n",
            "Epoch 506/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0517 - accuracy: 0.9839 - val_loss: 0.0619 - val_accuracy: 0.9780\n",
            "Epoch 507/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0517 - accuracy: 0.9833 - val_loss: 0.0632 - val_accuracy: 0.9780\n",
            "Epoch 508/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0518 - accuracy: 0.9836 - val_loss: 0.0659 - val_accuracy: 0.9780\n",
            "Epoch 509/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0515 - accuracy: 0.9828 - val_loss: 0.0773 - val_accuracy: 0.9756\n",
            "Epoch 510/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0518 - accuracy: 0.9844 - val_loss: 0.0624 - val_accuracy: 0.9792\n",
            "Epoch 511/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0518 - accuracy: 0.9837 - val_loss: 0.0615 - val_accuracy: 0.9784\n",
            "Epoch 512/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0512 - accuracy: 0.9840 - val_loss: 0.0611 - val_accuracy: 0.9792\n",
            "Epoch 513/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0514 - accuracy: 0.9835 - val_loss: 0.0624 - val_accuracy: 0.9788\n",
            "Epoch 514/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0510 - accuracy: 0.9832 - val_loss: 0.0609 - val_accuracy: 0.9792\n",
            "Epoch 515/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0512 - accuracy: 0.9839 - val_loss: 0.0609 - val_accuracy: 0.9808\n",
            "Epoch 516/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0509 - accuracy: 0.9839 - val_loss: 0.0640 - val_accuracy: 0.9776\n",
            "Epoch 517/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0512 - accuracy: 0.9836 - val_loss: 0.0612 - val_accuracy: 0.9804\n",
            "Epoch 518/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0512 - accuracy: 0.9839 - val_loss: 0.0607 - val_accuracy: 0.9784\n",
            "Epoch 519/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0509 - accuracy: 0.9835 - val_loss: 0.0606 - val_accuracy: 0.9792\n",
            "Epoch 520/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0512 - accuracy: 0.9835 - val_loss: 0.0603 - val_accuracy: 0.9792\n",
            "Epoch 521/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0509 - accuracy: 0.9837 - val_loss: 0.0617 - val_accuracy: 0.9780\n",
            "Epoch 522/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0506 - accuracy: 0.9843 - val_loss: 0.0647 - val_accuracy: 0.9768\n",
            "Epoch 523/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0506 - accuracy: 0.9843 - val_loss: 0.0616 - val_accuracy: 0.9796\n",
            "Epoch 524/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0506 - accuracy: 0.9840 - val_loss: 0.0612 - val_accuracy: 0.9796\n",
            "Epoch 525/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0503 - accuracy: 0.9848 - val_loss: 0.0608 - val_accuracy: 0.9800\n",
            "Epoch 526/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0506 - accuracy: 0.9835 - val_loss: 0.0606 - val_accuracy: 0.9792\n",
            "Epoch 527/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0502 - accuracy: 0.9840 - val_loss: 0.0612 - val_accuracy: 0.9792\n",
            "Epoch 528/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0503 - accuracy: 0.9841 - val_loss: 0.0596 - val_accuracy: 0.9804\n",
            "Epoch 529/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0499 - accuracy: 0.9844 - val_loss: 0.0603 - val_accuracy: 0.9808\n",
            "Epoch 530/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0502 - accuracy: 0.9837 - val_loss: 0.0593 - val_accuracy: 0.9812\n",
            "Epoch 531/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0497 - accuracy: 0.9855 - val_loss: 0.0606 - val_accuracy: 0.9780\n",
            "Epoch 532/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0502 - accuracy: 0.9839 - val_loss: 0.0596 - val_accuracy: 0.9800\n",
            "Epoch 533/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0500 - accuracy: 0.9845 - val_loss: 0.0592 - val_accuracy: 0.9816\n",
            "Epoch 534/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0498 - accuracy: 0.9844 - val_loss: 0.0590 - val_accuracy: 0.9808\n",
            "Epoch 535/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0494 - accuracy: 0.9845 - val_loss: 0.0602 - val_accuracy: 0.9820\n",
            "Epoch 536/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0495 - accuracy: 0.9837 - val_loss: 0.0595 - val_accuracy: 0.9804\n",
            "Epoch 537/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0496 - accuracy: 0.9839 - val_loss: 0.0604 - val_accuracy: 0.9804\n",
            "Epoch 538/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0496 - accuracy: 0.9839 - val_loss: 0.0584 - val_accuracy: 0.9816\n",
            "Epoch 539/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0491 - accuracy: 0.9840 - val_loss: 0.0597 - val_accuracy: 0.9812\n",
            "Epoch 540/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0495 - accuracy: 0.9839 - val_loss: 0.0589 - val_accuracy: 0.9800\n",
            "Epoch 541/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0491 - accuracy: 0.9840 - val_loss: 0.0589 - val_accuracy: 0.9796\n",
            "Epoch 542/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0490 - accuracy: 0.9843 - val_loss: 0.0579 - val_accuracy: 0.9816\n",
            "Epoch 543/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0492 - accuracy: 0.9840 - val_loss: 0.0583 - val_accuracy: 0.9804\n",
            "Epoch 544/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0486 - accuracy: 0.9840 - val_loss: 0.0591 - val_accuracy: 0.9796\n",
            "Epoch 545/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0484 - accuracy: 0.9840 - val_loss: 0.0589 - val_accuracy: 0.9816\n",
            "Epoch 546/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0489 - accuracy: 0.9845 - val_loss: 0.0581 - val_accuracy: 0.9808\n",
            "Epoch 547/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0485 - accuracy: 0.9845 - val_loss: 0.0574 - val_accuracy: 0.9816\n",
            "Epoch 548/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0486 - accuracy: 0.9848 - val_loss: 0.0579 - val_accuracy: 0.9808\n",
            "Epoch 549/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0484 - accuracy: 0.9841 - val_loss: 0.0586 - val_accuracy: 0.9800\n",
            "Epoch 550/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0479 - accuracy: 0.9837 - val_loss: 0.0582 - val_accuracy: 0.9804\n",
            "Epoch 551/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0478 - accuracy: 0.9843 - val_loss: 0.0585 - val_accuracy: 0.9808\n",
            "Epoch 552/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0479 - accuracy: 0.9848 - val_loss: 0.0578 - val_accuracy: 0.9800\n",
            "Epoch 553/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0479 - accuracy: 0.9849 - val_loss: 0.0575 - val_accuracy: 0.9812\n",
            "Epoch 554/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0480 - accuracy: 0.9836 - val_loss: 0.0573 - val_accuracy: 0.9820\n",
            "Epoch 555/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0481 - accuracy: 0.9829 - val_loss: 0.0580 - val_accuracy: 0.9812\n",
            "Epoch 556/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0479 - accuracy: 0.9845 - val_loss: 0.0579 - val_accuracy: 0.9808\n",
            "Epoch 557/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0477 - accuracy: 0.9856 - val_loss: 0.0571 - val_accuracy: 0.9816\n",
            "Epoch 558/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0478 - accuracy: 0.9843 - val_loss: 0.0568 - val_accuracy: 0.9808\n",
            "Epoch 559/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0476 - accuracy: 0.9843 - val_loss: 0.0571 - val_accuracy: 0.9812\n",
            "Epoch 560/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0473 - accuracy: 0.9851 - val_loss: 0.0560 - val_accuracy: 0.9808\n",
            "Epoch 561/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0474 - accuracy: 0.9845 - val_loss: 0.0571 - val_accuracy: 0.9808\n",
            "Epoch 562/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0470 - accuracy: 0.9844 - val_loss: 0.0564 - val_accuracy: 0.9808\n",
            "Epoch 563/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0472 - accuracy: 0.9847 - val_loss: 0.0564 - val_accuracy: 0.9808\n",
            "Epoch 564/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0470 - accuracy: 0.9852 - val_loss: 0.0564 - val_accuracy: 0.9816\n",
            "Epoch 565/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0467 - accuracy: 0.9840 - val_loss: 0.0560 - val_accuracy: 0.9820\n",
            "Epoch 566/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0472 - accuracy: 0.9840 - val_loss: 0.0584 - val_accuracy: 0.9812\n",
            "Epoch 567/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0470 - accuracy: 0.9852 - val_loss: 0.0551 - val_accuracy: 0.9816\n",
            "Epoch 568/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0468 - accuracy: 0.9849 - val_loss: 0.0556 - val_accuracy: 0.9816\n",
            "Epoch 569/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0465 - accuracy: 0.9851 - val_loss: 0.0567 - val_accuracy: 0.9812\n",
            "Epoch 570/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0462 - accuracy: 0.9844 - val_loss: 0.0561 - val_accuracy: 0.9808\n",
            "Epoch 571/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0464 - accuracy: 0.9848 - val_loss: 0.0551 - val_accuracy: 0.9816\n",
            "Epoch 572/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0461 - accuracy: 0.9863 - val_loss: 0.0553 - val_accuracy: 0.9816\n",
            "Epoch 573/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0464 - accuracy: 0.9847 - val_loss: 0.0562 - val_accuracy: 0.9808\n",
            "Epoch 574/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0460 - accuracy: 0.9851 - val_loss: 0.0568 - val_accuracy: 0.9812\n",
            "Epoch 575/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0461 - accuracy: 0.9851 - val_loss: 0.0556 - val_accuracy: 0.9812\n",
            "Epoch 576/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0462 - accuracy: 0.9841 - val_loss: 0.0546 - val_accuracy: 0.9824\n",
            "Epoch 577/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0460 - accuracy: 0.9841 - val_loss: 0.0559 - val_accuracy: 0.9808\n",
            "Epoch 578/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0458 - accuracy: 0.9849 - val_loss: 0.0550 - val_accuracy: 0.9816\n",
            "Epoch 579/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0454 - accuracy: 0.9855 - val_loss: 0.0553 - val_accuracy: 0.9812\n",
            "Epoch 580/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0456 - accuracy: 0.9849 - val_loss: 0.0543 - val_accuracy: 0.9824\n",
            "Epoch 581/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0458 - accuracy: 0.9845 - val_loss: 0.0535 - val_accuracy: 0.9816\n",
            "Epoch 582/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0457 - accuracy: 0.9841 - val_loss: 0.0535 - val_accuracy: 0.9828\n",
            "Epoch 583/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0451 - accuracy: 0.9852 - val_loss: 0.0555 - val_accuracy: 0.9800\n",
            "Epoch 584/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0453 - accuracy: 0.9844 - val_loss: 0.0566 - val_accuracy: 0.9820\n",
            "Epoch 585/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0452 - accuracy: 0.9853 - val_loss: 0.0642 - val_accuracy: 0.9772\n",
            "Epoch 586/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0454 - accuracy: 0.9849 - val_loss: 0.0531 - val_accuracy: 0.9828\n",
            "Epoch 587/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0451 - accuracy: 0.9848 - val_loss: 0.0536 - val_accuracy: 0.9832\n",
            "Epoch 588/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0450 - accuracy: 0.9849 - val_loss: 0.0558 - val_accuracy: 0.9812\n",
            "Epoch 589/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0449 - accuracy: 0.9848 - val_loss: 0.0525 - val_accuracy: 0.9832\n",
            "Epoch 590/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0448 - accuracy: 0.9845 - val_loss: 0.0558 - val_accuracy: 0.9820\n",
            "Epoch 591/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0447 - accuracy: 0.9847 - val_loss: 0.0531 - val_accuracy: 0.9828\n",
            "Epoch 592/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0445 - accuracy: 0.9851 - val_loss: 0.0528 - val_accuracy: 0.9824\n",
            "Epoch 593/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0444 - accuracy: 0.9856 - val_loss: 0.0527 - val_accuracy: 0.9832\n",
            "Epoch 594/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0446 - accuracy: 0.9851 - val_loss: 0.0546 - val_accuracy: 0.9812\n",
            "Epoch 595/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0443 - accuracy: 0.9857 - val_loss: 0.0523 - val_accuracy: 0.9832\n",
            "Epoch 596/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0443 - accuracy: 0.9860 - val_loss: 0.0527 - val_accuracy: 0.9824\n",
            "Epoch 597/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0439 - accuracy: 0.9851 - val_loss: 0.0548 - val_accuracy: 0.9832\n",
            "Epoch 598/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0442 - accuracy: 0.9859 - val_loss: 0.0601 - val_accuracy: 0.9804\n",
            "Epoch 599/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0440 - accuracy: 0.9849 - val_loss: 0.0520 - val_accuracy: 0.9832\n",
            "Epoch 600/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0438 - accuracy: 0.9848 - val_loss: 0.0536 - val_accuracy: 0.9840\n",
            "Epoch 601/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0441 - accuracy: 0.9852 - val_loss: 0.0517 - val_accuracy: 0.9840\n",
            "Epoch 602/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0435 - accuracy: 0.9857 - val_loss: 0.0538 - val_accuracy: 0.9832\n",
            "Epoch 603/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0437 - accuracy: 0.9849 - val_loss: 0.0505 - val_accuracy: 0.9852\n",
            "Epoch 604/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0432 - accuracy: 0.9853 - val_loss: 0.0514 - val_accuracy: 0.9828\n",
            "Epoch 605/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0437 - accuracy: 0.9851 - val_loss: 0.0520 - val_accuracy: 0.9840\n",
            "Epoch 606/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0434 - accuracy: 0.9853 - val_loss: 0.0501 - val_accuracy: 0.9856\n",
            "Epoch 607/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0428 - accuracy: 0.9856 - val_loss: 0.0526 - val_accuracy: 0.9804\n",
            "Epoch 608/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0430 - accuracy: 0.9853 - val_loss: 0.0539 - val_accuracy: 0.9824\n",
            "Epoch 609/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0432 - accuracy: 0.9851 - val_loss: 0.0505 - val_accuracy: 0.9848\n",
            "Epoch 610/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0430 - accuracy: 0.9855 - val_loss: 0.0510 - val_accuracy: 0.9844\n",
            "Epoch 611/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0427 - accuracy: 0.9859 - val_loss: 0.0505 - val_accuracy: 0.9856\n",
            "Epoch 612/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0429 - accuracy: 0.9856 - val_loss: 0.0578 - val_accuracy: 0.9820\n",
            "Epoch 613/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0431 - accuracy: 0.9860 - val_loss: 0.0506 - val_accuracy: 0.9852\n",
            "Epoch 614/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0427 - accuracy: 0.9859 - val_loss: 0.0492 - val_accuracy: 0.9852\n",
            "Epoch 615/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0427 - accuracy: 0.9855 - val_loss: 0.0526 - val_accuracy: 0.9836\n",
            "Epoch 616/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0425 - accuracy: 0.9863 - val_loss: 0.0495 - val_accuracy: 0.9848\n",
            "Epoch 617/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0419 - accuracy: 0.9865 - val_loss: 0.0547 - val_accuracy: 0.9820\n",
            "Epoch 618/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0423 - accuracy: 0.9852 - val_loss: 0.0491 - val_accuracy: 0.9860\n",
            "Epoch 619/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0420 - accuracy: 0.9872 - val_loss: 0.0515 - val_accuracy: 0.9840\n",
            "Epoch 620/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0422 - accuracy: 0.9859 - val_loss: 0.0534 - val_accuracy: 0.9844\n",
            "Epoch 621/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0422 - accuracy: 0.9859 - val_loss: 0.0484 - val_accuracy: 0.9852\n",
            "Epoch 622/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0420 - accuracy: 0.9856 - val_loss: 0.0482 - val_accuracy: 0.9864\n",
            "Epoch 623/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0415 - accuracy: 0.9864 - val_loss: 0.0485 - val_accuracy: 0.9860\n",
            "Epoch 624/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0415 - accuracy: 0.9855 - val_loss: 0.0509 - val_accuracy: 0.9852\n",
            "Epoch 625/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0418 - accuracy: 0.9861 - val_loss: 0.0498 - val_accuracy: 0.9844\n",
            "Epoch 626/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0416 - accuracy: 0.9857 - val_loss: 0.0477 - val_accuracy: 0.9864\n",
            "Epoch 627/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0413 - accuracy: 0.9873 - val_loss: 0.0485 - val_accuracy: 0.9864\n",
            "Epoch 628/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0416 - accuracy: 0.9865 - val_loss: 0.0492 - val_accuracy: 0.9852\n",
            "Epoch 629/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0413 - accuracy: 0.9860 - val_loss: 0.0476 - val_accuracy: 0.9860\n",
            "Epoch 630/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0410 - accuracy: 0.9857 - val_loss: 0.0505 - val_accuracy: 0.9852\n",
            "Epoch 631/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0413 - accuracy: 0.9865 - val_loss: 0.0482 - val_accuracy: 0.9864\n",
            "Epoch 632/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0409 - accuracy: 0.9869 - val_loss: 0.0488 - val_accuracy: 0.9852\n",
            "Epoch 633/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0409 - accuracy: 0.9864 - val_loss: 0.0506 - val_accuracy: 0.9848\n",
            "Epoch 634/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0412 - accuracy: 0.9860 - val_loss: 0.0474 - val_accuracy: 0.9864\n",
            "Epoch 635/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0408 - accuracy: 0.9868 - val_loss: 0.0480 - val_accuracy: 0.9848\n",
            "Epoch 636/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0409 - accuracy: 0.9861 - val_loss: 0.0469 - val_accuracy: 0.9868\n",
            "Epoch 637/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0406 - accuracy: 0.9868 - val_loss: 0.0470 - val_accuracy: 0.9868\n",
            "Epoch 638/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0406 - accuracy: 0.9861 - val_loss: 0.0465 - val_accuracy: 0.9864\n",
            "Epoch 639/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0405 - accuracy: 0.9868 - val_loss: 0.0467 - val_accuracy: 0.9868\n",
            "Epoch 640/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0406 - accuracy: 0.9860 - val_loss: 0.0454 - val_accuracy: 0.9868\n",
            "Epoch 641/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0401 - accuracy: 0.9868 - val_loss: 0.0467 - val_accuracy: 0.9868\n",
            "Epoch 642/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0401 - accuracy: 0.9865 - val_loss: 0.0474 - val_accuracy: 0.9852\n",
            "Epoch 643/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0400 - accuracy: 0.9863 - val_loss: 0.0469 - val_accuracy: 0.9852\n",
            "Epoch 644/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0400 - accuracy: 0.9867 - val_loss: 0.0475 - val_accuracy: 0.9852\n",
            "Epoch 645/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0401 - accuracy: 0.9871 - val_loss: 0.0461 - val_accuracy: 0.9872\n",
            "Epoch 646/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0401 - accuracy: 0.9871 - val_loss: 0.0461 - val_accuracy: 0.9864\n",
            "Epoch 647/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0397 - accuracy: 0.9864 - val_loss: 0.0474 - val_accuracy: 0.9860\n",
            "Epoch 648/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0398 - accuracy: 0.9869 - val_loss: 0.0462 - val_accuracy: 0.9856\n",
            "Epoch 649/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0394 - accuracy: 0.9867 - val_loss: 0.0481 - val_accuracy: 0.9852\n",
            "Epoch 650/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0396 - accuracy: 0.9865 - val_loss: 0.0476 - val_accuracy: 0.9848\n",
            "Epoch 651/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0395 - accuracy: 0.9868 - val_loss: 0.0449 - val_accuracy: 0.9856\n",
            "Epoch 652/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0404 - accuracy: 0.9867 - val_loss: 0.0454 - val_accuracy: 0.9860\n",
            "Epoch 653/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0397 - accuracy: 0.9871 - val_loss: 0.0458 - val_accuracy: 0.9844\n",
            "Epoch 654/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0393 - accuracy: 0.9865 - val_loss: 0.0447 - val_accuracy: 0.9872\n",
            "Epoch 655/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0390 - accuracy: 0.9871 - val_loss: 0.0456 - val_accuracy: 0.9848\n",
            "Epoch 656/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0391 - accuracy: 0.9872 - val_loss: 0.0447 - val_accuracy: 0.9868\n",
            "Epoch 657/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0383 - accuracy: 0.9879 - val_loss: 0.0501 - val_accuracy: 0.9844\n",
            "Epoch 658/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0389 - accuracy: 0.9876 - val_loss: 0.0455 - val_accuracy: 0.9868\n",
            "Epoch 659/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0391 - accuracy: 0.9875 - val_loss: 0.0442 - val_accuracy: 0.9868\n",
            "Epoch 660/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0389 - accuracy: 0.9869 - val_loss: 0.0452 - val_accuracy: 0.9868\n",
            "Epoch 661/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0388 - accuracy: 0.9871 - val_loss: 0.0439 - val_accuracy: 0.9876\n",
            "Epoch 662/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0390 - accuracy: 0.9869 - val_loss: 0.0448 - val_accuracy: 0.9860\n",
            "Epoch 663/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0388 - accuracy: 0.9872 - val_loss: 0.0457 - val_accuracy: 0.9848\n",
            "Epoch 664/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0385 - accuracy: 0.9867 - val_loss: 0.0446 - val_accuracy: 0.9868\n",
            "Epoch 665/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0384 - accuracy: 0.9868 - val_loss: 0.0446 - val_accuracy: 0.9872\n",
            "Epoch 666/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0380 - accuracy: 0.9876 - val_loss: 0.0444 - val_accuracy: 0.9856\n",
            "Epoch 667/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0382 - accuracy: 0.9875 - val_loss: 0.0435 - val_accuracy: 0.9868\n",
            "Epoch 668/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0379 - accuracy: 0.9883 - val_loss: 0.0444 - val_accuracy: 0.9876\n",
            "Epoch 669/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0375 - accuracy: 0.9880 - val_loss: 0.0461 - val_accuracy: 0.9864\n",
            "Epoch 670/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0375 - accuracy: 0.9877 - val_loss: 0.0459 - val_accuracy: 0.9864\n",
            "Epoch 671/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0380 - accuracy: 0.9869 - val_loss: 0.0437 - val_accuracy: 0.9876\n",
            "Epoch 672/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0376 - accuracy: 0.9873 - val_loss: 0.0446 - val_accuracy: 0.9860\n",
            "Epoch 673/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0377 - accuracy: 0.9876 - val_loss: 0.0430 - val_accuracy: 0.9872\n",
            "Epoch 674/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0375 - accuracy: 0.9875 - val_loss: 0.0439 - val_accuracy: 0.9876\n",
            "Epoch 675/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0377 - accuracy: 0.9872 - val_loss: 0.0433 - val_accuracy: 0.9888\n",
            "Epoch 676/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0377 - accuracy: 0.9872 - val_loss: 0.0427 - val_accuracy: 0.9876\n",
            "Epoch 677/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0377 - accuracy: 0.9869 - val_loss: 0.0429 - val_accuracy: 0.9868\n",
            "Epoch 678/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0370 - accuracy: 0.9879 - val_loss: 0.0426 - val_accuracy: 0.9876\n",
            "Epoch 679/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0374 - accuracy: 0.9876 - val_loss: 0.0443 - val_accuracy: 0.9880\n",
            "Epoch 680/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0372 - accuracy: 0.9877 - val_loss: 0.0453 - val_accuracy: 0.9872\n",
            "Epoch 681/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0372 - accuracy: 0.9871 - val_loss: 0.0431 - val_accuracy: 0.9872\n",
            "Epoch 682/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0373 - accuracy: 0.9879 - val_loss: 0.0429 - val_accuracy: 0.9864\n",
            "Epoch 683/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0376 - accuracy: 0.9869 - val_loss: 0.0421 - val_accuracy: 0.9880\n",
            "Epoch 684/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0369 - accuracy: 0.9877 - val_loss: 0.0427 - val_accuracy: 0.9884\n",
            "Epoch 685/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0368 - accuracy: 0.9875 - val_loss: 0.0416 - val_accuracy: 0.9884\n",
            "Epoch 686/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0370 - accuracy: 0.9872 - val_loss: 0.0428 - val_accuracy: 0.9868\n",
            "Epoch 687/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0366 - accuracy: 0.9880 - val_loss: 0.0443 - val_accuracy: 0.9876\n",
            "Epoch 688/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0368 - accuracy: 0.9873 - val_loss: 0.0430 - val_accuracy: 0.9888\n",
            "Epoch 689/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0366 - accuracy: 0.9881 - val_loss: 0.0424 - val_accuracy: 0.9872\n",
            "Epoch 690/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0365 - accuracy: 0.9881 - val_loss: 0.0435 - val_accuracy: 0.9868\n",
            "Epoch 691/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0366 - accuracy: 0.9879 - val_loss: 0.0426 - val_accuracy: 0.9880\n",
            "Epoch 692/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0364 - accuracy: 0.9880 - val_loss: 0.0410 - val_accuracy: 0.9884\n",
            "Epoch 693/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0365 - accuracy: 0.9869 - val_loss: 0.0438 - val_accuracy: 0.9864\n",
            "Epoch 694/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0362 - accuracy: 0.9880 - val_loss: 0.0433 - val_accuracy: 0.9872\n",
            "Epoch 695/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0360 - accuracy: 0.9872 - val_loss: 0.0451 - val_accuracy: 0.9872\n",
            "Epoch 696/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0362 - accuracy: 0.9876 - val_loss: 0.0417 - val_accuracy: 0.9876\n",
            "Epoch 697/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0357 - accuracy: 0.9880 - val_loss: 0.0403 - val_accuracy: 0.9892\n",
            "Epoch 698/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0363 - accuracy: 0.9875 - val_loss: 0.0412 - val_accuracy: 0.9876\n",
            "Epoch 699/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0357 - accuracy: 0.9876 - val_loss: 0.0420 - val_accuracy: 0.9876\n",
            "Epoch 700/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0355 - accuracy: 0.9885 - val_loss: 0.0437 - val_accuracy: 0.9880\n",
            "Epoch 701/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0356 - accuracy: 0.9887 - val_loss: 0.0421 - val_accuracy: 0.9880\n",
            "Epoch 702/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0360 - accuracy: 0.9881 - val_loss: 0.0405 - val_accuracy: 0.9876\n",
            "Epoch 703/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0357 - accuracy: 0.9880 - val_loss: 0.0409 - val_accuracy: 0.9880\n",
            "Epoch 704/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0355 - accuracy: 0.9891 - val_loss: 0.0436 - val_accuracy: 0.9852\n",
            "Epoch 705/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0356 - accuracy: 0.9877 - val_loss: 0.0417 - val_accuracy: 0.9888\n",
            "Epoch 706/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0352 - accuracy: 0.9880 - val_loss: 0.0410 - val_accuracy: 0.9884\n",
            "Epoch 707/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0355 - accuracy: 0.9885 - val_loss: 0.0415 - val_accuracy: 0.9864\n",
            "Epoch 708/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0353 - accuracy: 0.9888 - val_loss: 0.0408 - val_accuracy: 0.9880\n",
            "Epoch 709/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0354 - accuracy: 0.9875 - val_loss: 0.0413 - val_accuracy: 0.9884\n",
            "Epoch 710/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0356 - accuracy: 0.9880 - val_loss: 0.0407 - val_accuracy: 0.9884\n",
            "Epoch 711/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0352 - accuracy: 0.9885 - val_loss: 0.0420 - val_accuracy: 0.9868\n",
            "Epoch 712/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0350 - accuracy: 0.9888 - val_loss: 0.0420 - val_accuracy: 0.9884\n",
            "Epoch 713/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0351 - accuracy: 0.9880 - val_loss: 0.0407 - val_accuracy: 0.9888\n",
            "Epoch 714/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0349 - accuracy: 0.9891 - val_loss: 0.0410 - val_accuracy: 0.9876\n",
            "Epoch 715/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0351 - accuracy: 0.9880 - val_loss: 0.0399 - val_accuracy: 0.9880\n",
            "Epoch 716/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0347 - accuracy: 0.9889 - val_loss: 0.0399 - val_accuracy: 0.9892\n",
            "Epoch 717/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0348 - accuracy: 0.9883 - val_loss: 0.0400 - val_accuracy: 0.9900\n",
            "Epoch 718/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0344 - accuracy: 0.9887 - val_loss: 0.0398 - val_accuracy: 0.9884\n",
            "Epoch 719/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0347 - accuracy: 0.9869 - val_loss: 0.0393 - val_accuracy: 0.9884\n",
            "Epoch 720/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0344 - accuracy: 0.9892 - val_loss: 0.0432 - val_accuracy: 0.9876\n",
            "Epoch 721/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0348 - accuracy: 0.9883 - val_loss: 0.0396 - val_accuracy: 0.9884\n",
            "Epoch 722/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0339 - accuracy: 0.9889 - val_loss: 0.0401 - val_accuracy: 0.9888\n",
            "Epoch 723/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0342 - accuracy: 0.9883 - val_loss: 0.0468 - val_accuracy: 0.9852\n",
            "Epoch 724/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0339 - accuracy: 0.9881 - val_loss: 0.0396 - val_accuracy: 0.9888\n",
            "Epoch 725/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0345 - accuracy: 0.9881 - val_loss: 0.0406 - val_accuracy: 0.9868\n",
            "Epoch 726/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0340 - accuracy: 0.9883 - val_loss: 0.0403 - val_accuracy: 0.9876\n",
            "Epoch 727/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0341 - accuracy: 0.9892 - val_loss: 0.0424 - val_accuracy: 0.9868\n",
            "Epoch 728/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0340 - accuracy: 0.9885 - val_loss: 0.0419 - val_accuracy: 0.9864\n",
            "Epoch 729/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0342 - accuracy: 0.9879 - val_loss: 0.0395 - val_accuracy: 0.9880\n",
            "Epoch 730/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0339 - accuracy: 0.9889 - val_loss: 0.0967 - val_accuracy: 0.9596\n",
            "Epoch 731/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0343 - accuracy: 0.9877 - val_loss: 0.0420 - val_accuracy: 0.9880\n",
            "Epoch 732/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0339 - accuracy: 0.9889 - val_loss: 0.0387 - val_accuracy: 0.9896\n",
            "Epoch 733/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0332 - accuracy: 0.9893 - val_loss: 0.0546 - val_accuracy: 0.9796\n",
            "Epoch 734/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0342 - accuracy: 0.9889 - val_loss: 0.0381 - val_accuracy: 0.9896\n",
            "Epoch 735/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0336 - accuracy: 0.9887 - val_loss: 0.0377 - val_accuracy: 0.9900\n",
            "Epoch 736/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0338 - accuracy: 0.9883 - val_loss: 0.0394 - val_accuracy: 0.9900\n",
            "Epoch 737/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0333 - accuracy: 0.9889 - val_loss: 0.0391 - val_accuracy: 0.9896\n",
            "Epoch 738/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0328 - accuracy: 0.9889 - val_loss: 0.0400 - val_accuracy: 0.9892\n",
            "Epoch 739/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0339 - accuracy: 0.9889 - val_loss: 0.0394 - val_accuracy: 0.9892\n",
            "Epoch 740/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0336 - accuracy: 0.9881 - val_loss: 0.0419 - val_accuracy: 0.9880\n",
            "Epoch 741/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0336 - accuracy: 0.9891 - val_loss: 0.0392 - val_accuracy: 0.9888\n",
            "Epoch 742/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0330 - accuracy: 0.9887 - val_loss: 0.0382 - val_accuracy: 0.9904\n",
            "Epoch 743/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0334 - accuracy: 0.9885 - val_loss: 0.0389 - val_accuracy: 0.9892\n",
            "Epoch 744/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0328 - accuracy: 0.9896 - val_loss: 0.0398 - val_accuracy: 0.9884\n",
            "Epoch 745/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0333 - accuracy: 0.9891 - val_loss: 0.0379 - val_accuracy: 0.9892\n",
            "Epoch 746/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0332 - accuracy: 0.9892 - val_loss: 0.0382 - val_accuracy: 0.9884\n",
            "Epoch 747/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0330 - accuracy: 0.9889 - val_loss: 0.0399 - val_accuracy: 0.9864\n",
            "Epoch 748/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0330 - accuracy: 0.9889 - val_loss: 0.0392 - val_accuracy: 0.9912\n",
            "Epoch 749/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0330 - accuracy: 0.9891 - val_loss: 0.0378 - val_accuracy: 0.9900\n",
            "Epoch 750/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0327 - accuracy: 0.9885 - val_loss: 0.0375 - val_accuracy: 0.9900\n",
            "Epoch 751/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0329 - accuracy: 0.9887 - val_loss: 0.0712 - val_accuracy: 0.9756\n",
            "Epoch 752/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0334 - accuracy: 0.9889 - val_loss: 0.0422 - val_accuracy: 0.9868\n",
            "Epoch 753/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0327 - accuracy: 0.9900 - val_loss: 0.0400 - val_accuracy: 0.9888\n",
            "Epoch 754/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0324 - accuracy: 0.9897 - val_loss: 0.0384 - val_accuracy: 0.9888\n",
            "Epoch 755/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0322 - accuracy: 0.9891 - val_loss: 0.0370 - val_accuracy: 0.9896\n",
            "Epoch 756/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0328 - accuracy: 0.9896 - val_loss: 0.0372 - val_accuracy: 0.9896\n",
            "Epoch 757/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0325 - accuracy: 0.9889 - val_loss: 0.0423 - val_accuracy: 0.9876\n",
            "Epoch 758/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0323 - accuracy: 0.9884 - val_loss: 0.0376 - val_accuracy: 0.9888\n",
            "Epoch 759/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0323 - accuracy: 0.9891 - val_loss: 0.0423 - val_accuracy: 0.9856\n",
            "Epoch 760/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0325 - accuracy: 0.9891 - val_loss: 0.0379 - val_accuracy: 0.9888\n",
            "Epoch 761/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0322 - accuracy: 0.9888 - val_loss: 0.0368 - val_accuracy: 0.9904\n",
            "Epoch 762/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0324 - accuracy: 0.9896 - val_loss: 0.0376 - val_accuracy: 0.9896\n",
            "Epoch 763/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0325 - accuracy: 0.9885 - val_loss: 0.0370 - val_accuracy: 0.9892\n",
            "Epoch 764/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0322 - accuracy: 0.9889 - val_loss: 0.0370 - val_accuracy: 0.9908\n",
            "Epoch 765/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0324 - accuracy: 0.9899 - val_loss: 0.0380 - val_accuracy: 0.9892\n",
            "Epoch 766/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0324 - accuracy: 0.9891 - val_loss: 0.0362 - val_accuracy: 0.9912\n",
            "Epoch 767/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0319 - accuracy: 0.9892 - val_loss: 0.0370 - val_accuracy: 0.9896\n",
            "Epoch 768/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0320 - accuracy: 0.9900 - val_loss: 0.0366 - val_accuracy: 0.9896\n",
            "Epoch 769/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0316 - accuracy: 0.9900 - val_loss: 0.0367 - val_accuracy: 0.9888\n",
            "Epoch 770/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0318 - accuracy: 0.9899 - val_loss: 0.0395 - val_accuracy: 0.9876\n",
            "Epoch 771/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0319 - accuracy: 0.9899 - val_loss: 0.0366 - val_accuracy: 0.9900\n",
            "Epoch 772/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0321 - accuracy: 0.9893 - val_loss: 0.0376 - val_accuracy: 0.9904\n",
            "Epoch 773/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0318 - accuracy: 0.9899 - val_loss: 0.0393 - val_accuracy: 0.9884\n",
            "Epoch 774/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0316 - accuracy: 0.9892 - val_loss: 0.0359 - val_accuracy: 0.9912\n",
            "Epoch 775/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0318 - accuracy: 0.9900 - val_loss: 0.0354 - val_accuracy: 0.9908\n",
            "Epoch 776/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0319 - accuracy: 0.9891 - val_loss: 0.0388 - val_accuracy: 0.9888\n",
            "Epoch 777/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0314 - accuracy: 0.9897 - val_loss: 0.0556 - val_accuracy: 0.9792\n",
            "Epoch 778/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0315 - accuracy: 0.9895 - val_loss: 0.0359 - val_accuracy: 0.9900\n",
            "Epoch 779/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0315 - accuracy: 0.9892 - val_loss: 0.0386 - val_accuracy: 0.9880\n",
            "Epoch 780/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0312 - accuracy: 0.9900 - val_loss: 0.0357 - val_accuracy: 0.9904\n",
            "Epoch 781/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0315 - accuracy: 0.9891 - val_loss: 0.0354 - val_accuracy: 0.9904\n",
            "Epoch 782/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0311 - accuracy: 0.9897 - val_loss: 0.0360 - val_accuracy: 0.9896\n",
            "Epoch 783/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0317 - accuracy: 0.9895 - val_loss: 0.0373 - val_accuracy: 0.9884\n",
            "Epoch 784/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0308 - accuracy: 0.9897 - val_loss: 0.0361 - val_accuracy: 0.9912\n",
            "Epoch 785/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0313 - accuracy: 0.9903 - val_loss: 0.0353 - val_accuracy: 0.9904\n",
            "Epoch 786/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0315 - accuracy: 0.9897 - val_loss: 0.0361 - val_accuracy: 0.9900\n",
            "Epoch 787/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0313 - accuracy: 0.9895 - val_loss: 0.0371 - val_accuracy: 0.9896\n",
            "Epoch 788/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0307 - accuracy: 0.9901 - val_loss: 0.0361 - val_accuracy: 0.9900\n",
            "Epoch 789/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0312 - accuracy: 0.9893 - val_loss: 0.0358 - val_accuracy: 0.9900\n",
            "Epoch 790/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0308 - accuracy: 0.9899 - val_loss: 0.0353 - val_accuracy: 0.9904\n",
            "Epoch 791/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0309 - accuracy: 0.9904 - val_loss: 0.0352 - val_accuracy: 0.9904\n",
            "Epoch 792/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0307 - accuracy: 0.9901 - val_loss: 0.0390 - val_accuracy: 0.9880\n",
            "Epoch 793/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0311 - accuracy: 0.9891 - val_loss: 0.0358 - val_accuracy: 0.9900\n",
            "Epoch 794/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0310 - accuracy: 0.9896 - val_loss: 0.0364 - val_accuracy: 0.9892\n",
            "Epoch 795/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0309 - accuracy: 0.9899 - val_loss: 0.0382 - val_accuracy: 0.9904\n",
            "Epoch 796/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0309 - accuracy: 0.9901 - val_loss: 0.0357 - val_accuracy: 0.9900\n",
            "Epoch 797/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0306 - accuracy: 0.9899 - val_loss: 0.0369 - val_accuracy: 0.9896\n",
            "Epoch 798/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0309 - accuracy: 0.9896 - val_loss: 0.0390 - val_accuracy: 0.9892\n",
            "Epoch 799/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0306 - accuracy: 0.9899 - val_loss: 0.0354 - val_accuracy: 0.9904\n",
            "Epoch 800/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0306 - accuracy: 0.9897 - val_loss: 0.0352 - val_accuracy: 0.9900\n",
            "Epoch 801/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0304 - accuracy: 0.9897 - val_loss: 0.0363 - val_accuracy: 0.9896\n",
            "Epoch 802/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0308 - accuracy: 0.9892 - val_loss: 0.0354 - val_accuracy: 0.9908\n",
            "Epoch 803/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0307 - accuracy: 0.9897 - val_loss: 0.0350 - val_accuracy: 0.9900\n",
            "Epoch 804/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0302 - accuracy: 0.9905 - val_loss: 0.0345 - val_accuracy: 0.9904\n",
            "Epoch 805/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0303 - accuracy: 0.9899 - val_loss: 0.0344 - val_accuracy: 0.9904\n",
            "Epoch 806/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0305 - accuracy: 0.9904 - val_loss: 0.0346 - val_accuracy: 0.9908\n",
            "Epoch 807/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0304 - accuracy: 0.9901 - val_loss: 0.0359 - val_accuracy: 0.9904\n",
            "Epoch 808/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0299 - accuracy: 0.9899 - val_loss: 0.0353 - val_accuracy: 0.9904\n",
            "Epoch 809/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0304 - accuracy: 0.9903 - val_loss: 0.0342 - val_accuracy: 0.9908\n",
            "Epoch 810/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0301 - accuracy: 0.9903 - val_loss: 0.0354 - val_accuracy: 0.9896\n",
            "Epoch 811/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0305 - accuracy: 0.9897 - val_loss: 0.0346 - val_accuracy: 0.9908\n",
            "Epoch 812/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0295 - accuracy: 0.9909 - val_loss: 0.0341 - val_accuracy: 0.9904\n",
            "Epoch 813/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0299 - accuracy: 0.9893 - val_loss: 0.0357 - val_accuracy: 0.9896\n",
            "Epoch 814/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0297 - accuracy: 0.9904 - val_loss: 0.0361 - val_accuracy: 0.9892\n",
            "Epoch 815/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0300 - accuracy: 0.9904 - val_loss: 0.0344 - val_accuracy: 0.9900\n",
            "Epoch 816/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0305 - accuracy: 0.9896 - val_loss: 0.0352 - val_accuracy: 0.9908\n",
            "Epoch 817/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0302 - accuracy: 0.9892 - val_loss: 0.0340 - val_accuracy: 0.9900\n",
            "Epoch 818/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0295 - accuracy: 0.9897 - val_loss: 0.0344 - val_accuracy: 0.9900\n",
            "Epoch 819/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0297 - accuracy: 0.9904 - val_loss: 0.0348 - val_accuracy: 0.9892\n",
            "Epoch 820/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0297 - accuracy: 0.9903 - val_loss: 0.0382 - val_accuracy: 0.9884\n",
            "Epoch 821/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0300 - accuracy: 0.9899 - val_loss: 0.0357 - val_accuracy: 0.9896\n",
            "Epoch 822/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0296 - accuracy: 0.9899 - val_loss: 0.0338 - val_accuracy: 0.9904\n",
            "Epoch 823/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0295 - accuracy: 0.9893 - val_loss: 0.0338 - val_accuracy: 0.9908\n",
            "Epoch 824/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0297 - accuracy: 0.9901 - val_loss: 0.0354 - val_accuracy: 0.9900\n",
            "Epoch 825/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0298 - accuracy: 0.9905 - val_loss: 0.0341 - val_accuracy: 0.9908\n",
            "Epoch 826/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0295 - accuracy: 0.9903 - val_loss: 0.0338 - val_accuracy: 0.9908\n",
            "Epoch 827/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0297 - accuracy: 0.9904 - val_loss: 0.0349 - val_accuracy: 0.9904\n",
            "Epoch 828/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0300 - accuracy: 0.9903 - val_loss: 0.0368 - val_accuracy: 0.9888\n",
            "Epoch 829/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0295 - accuracy: 0.9905 - val_loss: 0.0351 - val_accuracy: 0.9912\n",
            "Epoch 830/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0296 - accuracy: 0.9896 - val_loss: 0.0357 - val_accuracy: 0.9896\n",
            "Epoch 831/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0292 - accuracy: 0.9909 - val_loss: 0.0333 - val_accuracy: 0.9896\n",
            "Epoch 832/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0292 - accuracy: 0.9908 - val_loss: 0.0357 - val_accuracy: 0.9896\n",
            "Epoch 833/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0296 - accuracy: 0.9899 - val_loss: 0.0352 - val_accuracy: 0.9916\n",
            "Epoch 834/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0292 - accuracy: 0.9908 - val_loss: 0.0352 - val_accuracy: 0.9904\n",
            "Epoch 835/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0292 - accuracy: 0.9905 - val_loss: 0.0339 - val_accuracy: 0.9908\n",
            "Epoch 836/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0290 - accuracy: 0.9899 - val_loss: 0.0336 - val_accuracy: 0.9916\n",
            "Epoch 837/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0294 - accuracy: 0.9896 - val_loss: 0.0337 - val_accuracy: 0.9904\n",
            "Epoch 838/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0288 - accuracy: 0.9911 - val_loss: 0.0362 - val_accuracy: 0.9892\n",
            "Epoch 839/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0294 - accuracy: 0.9897 - val_loss: 0.0332 - val_accuracy: 0.9912\n",
            "Epoch 840/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0292 - accuracy: 0.9897 - val_loss: 0.0337 - val_accuracy: 0.9908\n",
            "Epoch 841/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0290 - accuracy: 0.9907 - val_loss: 0.0357 - val_accuracy: 0.9904\n",
            "Epoch 842/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0288 - accuracy: 0.9909 - val_loss: 0.0346 - val_accuracy: 0.9896\n",
            "Epoch 843/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0287 - accuracy: 0.9899 - val_loss: 0.0365 - val_accuracy: 0.9892\n",
            "Epoch 844/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0289 - accuracy: 0.9911 - val_loss: 0.0354 - val_accuracy: 0.9904\n",
            "Epoch 845/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0288 - accuracy: 0.9908 - val_loss: 0.0343 - val_accuracy: 0.9900\n",
            "Epoch 846/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0292 - accuracy: 0.9904 - val_loss: 0.0340 - val_accuracy: 0.9908\n",
            "Epoch 847/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0292 - accuracy: 0.9908 - val_loss: 0.0340 - val_accuracy: 0.9912\n",
            "Epoch 848/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0289 - accuracy: 0.9900 - val_loss: 0.0352 - val_accuracy: 0.9908\n",
            "Epoch 849/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0290 - accuracy: 0.9907 - val_loss: 0.0334 - val_accuracy: 0.9908\n",
            "Epoch 850/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0291 - accuracy: 0.9907 - val_loss: 0.0346 - val_accuracy: 0.9900\n",
            "Epoch 851/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0285 - accuracy: 0.9917 - val_loss: 0.0331 - val_accuracy: 0.9908\n",
            "Epoch 852/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0290 - accuracy: 0.9907 - val_loss: 0.0336 - val_accuracy: 0.9908\n",
            "Epoch 853/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0282 - accuracy: 0.9915 - val_loss: 0.0332 - val_accuracy: 0.9900\n",
            "Epoch 854/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0283 - accuracy: 0.9911 - val_loss: 0.0343 - val_accuracy: 0.9908\n",
            "Epoch 855/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0288 - accuracy: 0.9909 - val_loss: 0.0325 - val_accuracy: 0.9912\n",
            "Epoch 856/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0288 - accuracy: 0.9908 - val_loss: 0.0393 - val_accuracy: 0.9888\n",
            "Epoch 857/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0290 - accuracy: 0.9901 - val_loss: 0.0325 - val_accuracy: 0.9908\n",
            "Epoch 858/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0285 - accuracy: 0.9899 - val_loss: 0.0388 - val_accuracy: 0.9864\n",
            "Epoch 859/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0282 - accuracy: 0.9913 - val_loss: 0.0327 - val_accuracy: 0.9904\n",
            "Epoch 860/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0286 - accuracy: 0.9899 - val_loss: 0.0358 - val_accuracy: 0.9908\n",
            "Epoch 861/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0287 - accuracy: 0.9905 - val_loss: 0.0330 - val_accuracy: 0.9912\n",
            "Epoch 862/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0278 - accuracy: 0.9907 - val_loss: 0.0330 - val_accuracy: 0.9904\n",
            "Epoch 863/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0280 - accuracy: 0.9904 - val_loss: 0.0362 - val_accuracy: 0.9904\n",
            "Epoch 864/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0287 - accuracy: 0.9904 - val_loss: 0.0352 - val_accuracy: 0.9904\n",
            "Epoch 865/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0282 - accuracy: 0.9900 - val_loss: 0.0335 - val_accuracy: 0.9916\n",
            "Epoch 866/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0286 - accuracy: 0.9907 - val_loss: 0.0325 - val_accuracy: 0.9904\n",
            "Epoch 867/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0282 - accuracy: 0.9912 - val_loss: 0.0328 - val_accuracy: 0.9904\n",
            "Epoch 868/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0285 - accuracy: 0.9905 - val_loss: 0.0329 - val_accuracy: 0.9904\n",
            "Epoch 869/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0284 - accuracy: 0.9901 - val_loss: 0.0342 - val_accuracy: 0.9908\n",
            "Epoch 870/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0280 - accuracy: 0.9911 - val_loss: 0.0324 - val_accuracy: 0.9908\n",
            "Epoch 871/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0280 - accuracy: 0.9908 - val_loss: 0.0325 - val_accuracy: 0.9908\n",
            "Epoch 872/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0280 - accuracy: 0.9908 - val_loss: 0.0330 - val_accuracy: 0.9928\n",
            "Epoch 873/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0280 - accuracy: 0.9911 - val_loss: 0.0317 - val_accuracy: 0.9920\n",
            "Epoch 874/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0280 - accuracy: 0.9909 - val_loss: 0.0322 - val_accuracy: 0.9912\n",
            "Epoch 875/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0279 - accuracy: 0.9903 - val_loss: 0.0349 - val_accuracy: 0.9892\n",
            "Epoch 876/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0283 - accuracy: 0.9908 - val_loss: 0.0333 - val_accuracy: 0.9924\n",
            "Epoch 877/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0278 - accuracy: 0.9907 - val_loss: 0.0342 - val_accuracy: 0.9904\n",
            "Epoch 878/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0276 - accuracy: 0.9903 - val_loss: 0.0355 - val_accuracy: 0.9896\n",
            "Epoch 879/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0276 - accuracy: 0.9907 - val_loss: 0.0350 - val_accuracy: 0.9896\n",
            "Epoch 880/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0279 - accuracy: 0.9904 - val_loss: 0.0335 - val_accuracy: 0.9904\n",
            "Epoch 881/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0283 - accuracy: 0.9901 - val_loss: 0.0338 - val_accuracy: 0.9920\n",
            "Epoch 882/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0276 - accuracy: 0.9916 - val_loss: 0.0322 - val_accuracy: 0.9908\n",
            "Epoch 883/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0284 - accuracy: 0.9905 - val_loss: 0.0319 - val_accuracy: 0.9908\n",
            "Epoch 884/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0274 - accuracy: 0.9909 - val_loss: 0.0323 - val_accuracy: 0.9904\n",
            "Epoch 885/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0280 - accuracy: 0.9908 - val_loss: 0.0321 - val_accuracy: 0.9904\n",
            "Epoch 886/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0277 - accuracy: 0.9911 - val_loss: 0.0363 - val_accuracy: 0.9892\n",
            "Epoch 887/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0277 - accuracy: 0.9915 - val_loss: 0.0350 - val_accuracy: 0.9896\n",
            "Epoch 888/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0274 - accuracy: 0.9905 - val_loss: 0.0410 - val_accuracy: 0.9848\n",
            "Epoch 889/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0279 - accuracy: 0.9908 - val_loss: 0.0335 - val_accuracy: 0.9920\n",
            "Epoch 890/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0273 - accuracy: 0.9915 - val_loss: 0.0346 - val_accuracy: 0.9896\n",
            "Epoch 891/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0278 - accuracy: 0.9909 - val_loss: 0.0315 - val_accuracy: 0.9908\n",
            "Epoch 892/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0267 - accuracy: 0.9911 - val_loss: 0.0352 - val_accuracy: 0.9916\n",
            "Epoch 893/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0272 - accuracy: 0.9911 - val_loss: 0.0318 - val_accuracy: 0.9916\n",
            "Epoch 894/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0272 - accuracy: 0.9908 - val_loss: 0.0342 - val_accuracy: 0.9912\n",
            "Epoch 895/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0276 - accuracy: 0.9912 - val_loss: 0.0328 - val_accuracy: 0.9912\n",
            "Epoch 896/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0272 - accuracy: 0.9912 - val_loss: 0.0322 - val_accuracy: 0.9912\n",
            "Epoch 897/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0274 - accuracy: 0.9909 - val_loss: 0.0321 - val_accuracy: 0.9912\n",
            "Epoch 898/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0273 - accuracy: 0.9905 - val_loss: 0.0330 - val_accuracy: 0.9928\n",
            "Epoch 899/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0271 - accuracy: 0.9915 - val_loss: 0.0364 - val_accuracy: 0.9876\n",
            "Epoch 900/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0270 - accuracy: 0.9920 - val_loss: 0.0316 - val_accuracy: 0.9912\n",
            "Epoch 901/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0271 - accuracy: 0.9908 - val_loss: 0.0330 - val_accuracy: 0.9900\n",
            "Epoch 902/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0278 - accuracy: 0.9904 - val_loss: 0.0322 - val_accuracy: 0.9908\n",
            "Epoch 903/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0267 - accuracy: 0.9913 - val_loss: 0.0319 - val_accuracy: 0.9912\n",
            "Epoch 904/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0274 - accuracy: 0.9907 - val_loss: 0.0316 - val_accuracy: 0.9912\n",
            "Epoch 905/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0271 - accuracy: 0.9909 - val_loss: 0.0318 - val_accuracy: 0.9916\n",
            "Epoch 906/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0273 - accuracy: 0.9908 - val_loss: 0.0386 - val_accuracy: 0.9876\n",
            "Epoch 907/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0280 - accuracy: 0.9908 - val_loss: 0.0329 - val_accuracy: 0.9908\n",
            "Epoch 908/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0268 - accuracy: 0.9916 - val_loss: 0.0318 - val_accuracy: 0.9912\n",
            "Epoch 909/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0273 - accuracy: 0.9907 - val_loss: 0.0316 - val_accuracy: 0.9916\n",
            "Epoch 910/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0273 - accuracy: 0.9913 - val_loss: 0.0322 - val_accuracy: 0.9920\n",
            "Epoch 911/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0274 - accuracy: 0.9907 - val_loss: 0.0311 - val_accuracy: 0.9924\n",
            "Epoch 912/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0272 - accuracy: 0.9908 - val_loss: 0.0324 - val_accuracy: 0.9924\n",
            "Epoch 913/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0268 - accuracy: 0.9913 - val_loss: 0.0329 - val_accuracy: 0.9908\n",
            "Epoch 914/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0271 - accuracy: 0.9913 - val_loss: 0.0304 - val_accuracy: 0.9912\n",
            "Epoch 915/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0267 - accuracy: 0.9909 - val_loss: 0.0344 - val_accuracy: 0.9920\n",
            "Epoch 916/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0264 - accuracy: 0.9913 - val_loss: 0.0326 - val_accuracy: 0.9916\n",
            "Epoch 917/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0264 - accuracy: 0.9907 - val_loss: 0.0308 - val_accuracy: 0.9924\n",
            "Epoch 918/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0266 - accuracy: 0.9904 - val_loss: 0.0320 - val_accuracy: 0.9920\n",
            "Epoch 919/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0267 - accuracy: 0.9908 - val_loss: 0.0410 - val_accuracy: 0.9876\n",
            "Epoch 920/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0272 - accuracy: 0.9912 - val_loss: 0.0309 - val_accuracy: 0.9916\n",
            "Epoch 921/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0264 - accuracy: 0.9913 - val_loss: 0.0327 - val_accuracy: 0.9904\n",
            "Epoch 922/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0267 - accuracy: 0.9916 - val_loss: 0.0321 - val_accuracy: 0.9908\n",
            "Epoch 923/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0270 - accuracy: 0.9907 - val_loss: 0.0311 - val_accuracy: 0.9912\n",
            "Epoch 924/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0266 - accuracy: 0.9915 - val_loss: 0.0312 - val_accuracy: 0.9912\n",
            "Epoch 925/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0264 - accuracy: 0.9919 - val_loss: 0.0308 - val_accuracy: 0.9920\n",
            "Epoch 926/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0262 - accuracy: 0.9916 - val_loss: 0.0328 - val_accuracy: 0.9916\n",
            "Epoch 927/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0264 - accuracy: 0.9920 - val_loss: 0.0323 - val_accuracy: 0.9916\n",
            "Epoch 928/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0264 - accuracy: 0.9908 - val_loss: 0.0321 - val_accuracy: 0.9912\n",
            "Epoch 929/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0264 - accuracy: 0.9916 - val_loss: 0.0310 - val_accuracy: 0.9912\n",
            "Epoch 930/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0261 - accuracy: 0.9921 - val_loss: 0.0336 - val_accuracy: 0.9900\n",
            "Epoch 931/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0263 - accuracy: 0.9909 - val_loss: 0.0313 - val_accuracy: 0.9912\n",
            "Epoch 932/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0264 - accuracy: 0.9913 - val_loss: 0.0318 - val_accuracy: 0.9920\n",
            "Epoch 933/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0258 - accuracy: 0.9920 - val_loss: 0.0393 - val_accuracy: 0.9876\n",
            "Epoch 934/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0267 - accuracy: 0.9908 - val_loss: 0.0303 - val_accuracy: 0.9920\n",
            "Epoch 935/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0262 - accuracy: 0.9915 - val_loss: 0.0307 - val_accuracy: 0.9916\n",
            "Epoch 936/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0262 - accuracy: 0.9911 - val_loss: 0.0443 - val_accuracy: 0.9852\n",
            "Epoch 937/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0267 - accuracy: 0.9915 - val_loss: 0.0312 - val_accuracy: 0.9912\n",
            "Epoch 938/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0257 - accuracy: 0.9919 - val_loss: 0.0348 - val_accuracy: 0.9912\n",
            "Epoch 939/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0263 - accuracy: 0.9908 - val_loss: 0.0300 - val_accuracy: 0.9928\n",
            "Epoch 940/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0266 - accuracy: 0.9901 - val_loss: 0.0337 - val_accuracy: 0.9924\n",
            "Epoch 941/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0262 - accuracy: 0.9915 - val_loss: 0.0298 - val_accuracy: 0.9928\n",
            "Epoch 942/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0263 - accuracy: 0.9913 - val_loss: 0.0321 - val_accuracy: 0.9920\n",
            "Epoch 943/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0262 - accuracy: 0.9912 - val_loss: 0.0305 - val_accuracy: 0.9916\n",
            "Epoch 944/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0261 - accuracy: 0.9916 - val_loss: 0.0322 - val_accuracy: 0.9920\n",
            "Epoch 945/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0255 - accuracy: 0.9923 - val_loss: 0.0307 - val_accuracy: 0.9912\n",
            "Epoch 946/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0263 - accuracy: 0.9907 - val_loss: 0.0301 - val_accuracy: 0.9924\n",
            "Epoch 947/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0256 - accuracy: 0.9919 - val_loss: 0.0386 - val_accuracy: 0.9884\n",
            "Epoch 948/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0260 - accuracy: 0.9916 - val_loss: 0.0310 - val_accuracy: 0.9920\n",
            "Epoch 949/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0262 - accuracy: 0.9911 - val_loss: 0.0348 - val_accuracy: 0.9896\n",
            "Epoch 950/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0261 - accuracy: 0.9912 - val_loss: 0.0309 - val_accuracy: 0.9912\n",
            "Epoch 951/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0259 - accuracy: 0.9920 - val_loss: 0.0322 - val_accuracy: 0.9904\n",
            "Epoch 952/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0256 - accuracy: 0.9912 - val_loss: 0.0307 - val_accuracy: 0.9908\n",
            "Epoch 953/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0254 - accuracy: 0.9917 - val_loss: 0.0325 - val_accuracy: 0.9912\n",
            "Epoch 954/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0255 - accuracy: 0.9911 - val_loss: 0.0311 - val_accuracy: 0.9912\n",
            "Epoch 955/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0260 - accuracy: 0.9915 - val_loss: 0.0355 - val_accuracy: 0.9880\n",
            "Epoch 956/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0264 - accuracy: 0.9912 - val_loss: 0.0364 - val_accuracy: 0.9892\n",
            "Epoch 957/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0259 - accuracy: 0.9913 - val_loss: 0.0319 - val_accuracy: 0.9920\n",
            "Epoch 958/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0257 - accuracy: 0.9915 - val_loss: 0.0304 - val_accuracy: 0.9916\n",
            "Epoch 959/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0259 - accuracy: 0.9916 - val_loss: 0.0319 - val_accuracy: 0.9912\n",
            "Epoch 960/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0262 - accuracy: 0.9911 - val_loss: 0.0311 - val_accuracy: 0.9916\n",
            "Epoch 961/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0257 - accuracy: 0.9915 - val_loss: 0.0353 - val_accuracy: 0.9880\n",
            "Epoch 962/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0256 - accuracy: 0.9915 - val_loss: 0.0322 - val_accuracy: 0.9916\n",
            "Epoch 963/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0252 - accuracy: 0.9920 - val_loss: 0.0332 - val_accuracy: 0.9916\n",
            "Epoch 964/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0258 - accuracy: 0.9916 - val_loss: 0.0315 - val_accuracy: 0.9924\n",
            "Epoch 965/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0255 - accuracy: 0.9919 - val_loss: 0.0302 - val_accuracy: 0.9912\n",
            "Epoch 966/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0251 - accuracy: 0.9924 - val_loss: 0.0327 - val_accuracy: 0.9916\n",
            "Epoch 967/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0258 - accuracy: 0.9917 - val_loss: 0.0307 - val_accuracy: 0.9916\n",
            "Epoch 968/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0254 - accuracy: 0.9907 - val_loss: 0.0348 - val_accuracy: 0.9888\n",
            "Epoch 969/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0251 - accuracy: 0.9921 - val_loss: 0.0311 - val_accuracy: 0.9920\n",
            "Epoch 970/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0255 - accuracy: 0.9916 - val_loss: 0.0323 - val_accuracy: 0.9896\n",
            "Epoch 971/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0255 - accuracy: 0.9921 - val_loss: 0.0301 - val_accuracy: 0.9928\n",
            "Epoch 972/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0256 - accuracy: 0.9913 - val_loss: 0.0302 - val_accuracy: 0.9924\n",
            "Epoch 973/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0255 - accuracy: 0.9908 - val_loss: 0.0304 - val_accuracy: 0.9920\n",
            "Epoch 974/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0250 - accuracy: 0.9921 - val_loss: 0.0297 - val_accuracy: 0.9920\n",
            "Epoch 975/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0251 - accuracy: 0.9919 - val_loss: 0.0304 - val_accuracy: 0.9928\n",
            "Epoch 976/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0253 - accuracy: 0.9917 - val_loss: 0.0331 - val_accuracy: 0.9888\n",
            "Epoch 977/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0256 - accuracy: 0.9919 - val_loss: 0.0299 - val_accuracy: 0.9908\n",
            "Epoch 978/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0245 - accuracy: 0.9912 - val_loss: 0.0306 - val_accuracy: 0.9912\n",
            "Epoch 979/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0255 - accuracy: 0.9915 - val_loss: 0.0455 - val_accuracy: 0.9864\n",
            "Epoch 980/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0249 - accuracy: 0.9919 - val_loss: 0.0298 - val_accuracy: 0.9916\n",
            "Epoch 981/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0251 - accuracy: 0.9911 - val_loss: 0.0312 - val_accuracy: 0.9908\n",
            "Epoch 982/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0252 - accuracy: 0.9913 - val_loss: 0.0306 - val_accuracy: 0.9924\n",
            "Epoch 983/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0248 - accuracy: 0.9920 - val_loss: 0.0309 - val_accuracy: 0.9908\n",
            "Epoch 984/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0253 - accuracy: 0.9912 - val_loss: 0.0304 - val_accuracy: 0.9920\n",
            "Epoch 985/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0252 - accuracy: 0.9909 - val_loss: 0.0318 - val_accuracy: 0.9912\n",
            "Epoch 986/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0250 - accuracy: 0.9923 - val_loss: 0.0294 - val_accuracy: 0.9916\n",
            "Epoch 987/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0247 - accuracy: 0.9913 - val_loss: 0.0305 - val_accuracy: 0.9924\n",
            "Epoch 988/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0245 - accuracy: 0.9919 - val_loss: 0.0310 - val_accuracy: 0.9924\n",
            "Epoch 989/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0246 - accuracy: 0.9921 - val_loss: 0.0312 - val_accuracy: 0.9916\n",
            "Epoch 990/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0252 - accuracy: 0.9916 - val_loss: 0.0296 - val_accuracy: 0.9924\n",
            "Epoch 991/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0242 - accuracy: 0.9925 - val_loss: 0.0314 - val_accuracy: 0.9916\n",
            "Epoch 992/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0251 - accuracy: 0.9912 - val_loss: 0.0308 - val_accuracy: 0.9928\n",
            "Epoch 993/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0249 - accuracy: 0.9919 - val_loss: 0.0304 - val_accuracy: 0.9928\n",
            "Epoch 994/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0247 - accuracy: 0.9913 - val_loss: 0.0302 - val_accuracy: 0.9924\n",
            "Epoch 995/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0247 - accuracy: 0.9915 - val_loss: 0.0382 - val_accuracy: 0.9896\n",
            "Epoch 996/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0250 - accuracy: 0.9915 - val_loss: 0.0293 - val_accuracy: 0.9920\n",
            "Epoch 997/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0246 - accuracy: 0.9916 - val_loss: 0.0300 - val_accuracy: 0.9928\n",
            "Epoch 998/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0247 - accuracy: 0.9912 - val_loss: 0.0286 - val_accuracy: 0.9920\n",
            "Epoch 999/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0245 - accuracy: 0.9923 - val_loss: 0.0294 - val_accuracy: 0.9916\n",
            "Epoch 1000/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0244 - accuracy: 0.9915 - val_loss: 0.0306 - val_accuracy: 0.9928\n",
            "Epoch 1001/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0247 - accuracy: 0.9917 - val_loss: 0.0395 - val_accuracy: 0.9872\n",
            "Epoch 1002/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0245 - accuracy: 0.9920 - val_loss: 0.0317 - val_accuracy: 0.9912\n",
            "Epoch 1003/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0247 - accuracy: 0.9919 - val_loss: 0.0327 - val_accuracy: 0.9920\n",
            "Epoch 1004/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0242 - accuracy: 0.9915 - val_loss: 0.0326 - val_accuracy: 0.9900\n",
            "Epoch 1005/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0248 - accuracy: 0.9915 - val_loss: 0.0305 - val_accuracy: 0.9900\n",
            "Epoch 1006/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0250 - accuracy: 0.9916 - val_loss: 0.0298 - val_accuracy: 0.9924\n",
            "Epoch 1007/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0250 - accuracy: 0.9919 - val_loss: 0.0289 - val_accuracy: 0.9924\n",
            "Epoch 1008/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0251 - accuracy: 0.9919 - val_loss: 0.0301 - val_accuracy: 0.9924\n",
            "Epoch 1009/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0248 - accuracy: 0.9917 - val_loss: 0.0295 - val_accuracy: 0.9920\n",
            "Epoch 1010/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0242 - accuracy: 0.9916 - val_loss: 0.0299 - val_accuracy: 0.9928\n",
            "Epoch 1011/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0247 - accuracy: 0.9919 - val_loss: 0.0287 - val_accuracy: 0.9928\n",
            "Epoch 1012/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0242 - accuracy: 0.9925 - val_loss: 0.0307 - val_accuracy: 0.9928\n",
            "Epoch 1013/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0245 - accuracy: 0.9923 - val_loss: 0.0301 - val_accuracy: 0.9924\n",
            "Epoch 1014/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0244 - accuracy: 0.9921 - val_loss: 0.0330 - val_accuracy: 0.9912\n",
            "Epoch 1015/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0245 - accuracy: 0.9925 - val_loss: 0.0303 - val_accuracy: 0.9916\n",
            "Epoch 1016/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0243 - accuracy: 0.9919 - val_loss: 0.0288 - val_accuracy: 0.9928\n",
            "Epoch 1017/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0246 - accuracy: 0.9917 - val_loss: 0.0292 - val_accuracy: 0.9928\n",
            "Epoch 1018/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0244 - accuracy: 0.9915 - val_loss: 0.0299 - val_accuracy: 0.9928\n",
            "Epoch 1019/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0247 - accuracy: 0.9919 - val_loss: 0.0290 - val_accuracy: 0.9928\n",
            "Epoch 1020/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0246 - accuracy: 0.9916 - val_loss: 0.0296 - val_accuracy: 0.9928\n",
            "Epoch 1021/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0242 - accuracy: 0.9928 - val_loss: 0.0682 - val_accuracy: 0.9760\n",
            "Epoch 1022/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0245 - accuracy: 0.9912 - val_loss: 0.0325 - val_accuracy: 0.9912\n",
            "Epoch 1023/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0244 - accuracy: 0.9916 - val_loss: 0.0333 - val_accuracy: 0.9908\n",
            "Epoch 1024/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0247 - accuracy: 0.9917 - val_loss: 0.0287 - val_accuracy: 0.9920\n",
            "Epoch 1025/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0240 - accuracy: 0.9921 - val_loss: 0.0300 - val_accuracy: 0.9924\n",
            "Epoch 1026/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0241 - accuracy: 0.9917 - val_loss: 0.0295 - val_accuracy: 0.9928\n",
            "Epoch 1027/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0243 - accuracy: 0.9915 - val_loss: 0.0360 - val_accuracy: 0.9900\n",
            "Epoch 1028/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0239 - accuracy: 0.9919 - val_loss: 0.0307 - val_accuracy: 0.9912\n",
            "Epoch 1029/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0243 - accuracy: 0.9919 - val_loss: 0.0301 - val_accuracy: 0.9924\n",
            "Epoch 1030/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0245 - accuracy: 0.9919 - val_loss: 0.0296 - val_accuracy: 0.9920\n",
            "Epoch 1031/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 0.0306 - val_accuracy: 0.9928\n",
            "Epoch 1032/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0242 - accuracy: 0.9917 - val_loss: 0.0318 - val_accuracy: 0.9916\n",
            "Epoch 1033/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0240 - accuracy: 0.9925 - val_loss: 0.0300 - val_accuracy: 0.9912\n",
            "Epoch 1034/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0240 - accuracy: 0.9920 - val_loss: 0.0295 - val_accuracy: 0.9928\n",
            "Epoch 1035/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0238 - accuracy: 0.9927 - val_loss: 0.0310 - val_accuracy: 0.9928\n",
            "Epoch 1036/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0237 - accuracy: 0.9927 - val_loss: 0.0284 - val_accuracy: 0.9928\n",
            "Epoch 1037/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0235 - accuracy: 0.9917 - val_loss: 0.0362 - val_accuracy: 0.9900\n",
            "Epoch 1038/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0243 - accuracy: 0.9925 - val_loss: 0.0287 - val_accuracy: 0.9924\n",
            "Epoch 1039/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0235 - accuracy: 0.9924 - val_loss: 0.0307 - val_accuracy: 0.9924\n",
            "Epoch 1040/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0237 - accuracy: 0.9917 - val_loss: 0.0311 - val_accuracy: 0.9920\n",
            "Epoch 1041/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0237 - accuracy: 0.9921 - val_loss: 0.0287 - val_accuracy: 0.9932\n",
            "Epoch 1042/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0240 - accuracy: 0.9928 - val_loss: 0.0315 - val_accuracy: 0.9928\n",
            "Epoch 1043/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0238 - accuracy: 0.9921 - val_loss: 0.0293 - val_accuracy: 0.9920\n",
            "Epoch 1044/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0236 - accuracy: 0.9932 - val_loss: 0.0314 - val_accuracy: 0.9924\n",
            "Epoch 1045/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 0.0311 - val_accuracy: 0.9932\n",
            "Epoch 1046/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0238 - accuracy: 0.9927 - val_loss: 0.0279 - val_accuracy: 0.9924\n",
            "Epoch 1047/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0239 - accuracy: 0.9925 - val_loss: 0.0280 - val_accuracy: 0.9924\n",
            "Epoch 1048/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0239 - accuracy: 0.9915 - val_loss: 0.0317 - val_accuracy: 0.9908\n",
            "Epoch 1049/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0236 - accuracy: 0.9921 - val_loss: 0.0284 - val_accuracy: 0.9920\n",
            "Epoch 1050/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0235 - accuracy: 0.9925 - val_loss: 0.0286 - val_accuracy: 0.9928\n",
            "Epoch 1051/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0234 - accuracy: 0.9925 - val_loss: 0.0341 - val_accuracy: 0.9896\n",
            "Epoch 1052/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0233 - accuracy: 0.9923 - val_loss: 0.0323 - val_accuracy: 0.9920\n",
            "Epoch 1053/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0236 - accuracy: 0.9927 - val_loss: 0.0303 - val_accuracy: 0.9936\n",
            "Epoch 1054/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0235 - accuracy: 0.9920 - val_loss: 0.0284 - val_accuracy: 0.9928\n",
            "Epoch 1055/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0241 - accuracy: 0.9919 - val_loss: 0.0279 - val_accuracy: 0.9928\n",
            "Epoch 1056/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0235 - accuracy: 0.9923 - val_loss: 0.0290 - val_accuracy: 0.9928\n",
            "Epoch 1057/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0234 - accuracy: 0.9924 - val_loss: 0.0286 - val_accuracy: 0.9916\n",
            "Epoch 1058/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0233 - accuracy: 0.9917 - val_loss: 0.0275 - val_accuracy: 0.9924\n",
            "Epoch 1059/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0232 - accuracy: 0.9920 - val_loss: 0.0280 - val_accuracy: 0.9928\n",
            "Epoch 1060/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0232 - accuracy: 0.9921 - val_loss: 0.0285 - val_accuracy: 0.9920\n",
            "Epoch 1061/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0229 - accuracy: 0.9920 - val_loss: 0.0274 - val_accuracy: 0.9920\n",
            "Epoch 1062/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0235 - accuracy: 0.9919 - val_loss: 0.0324 - val_accuracy: 0.9908\n",
            "Epoch 1063/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0233 - accuracy: 0.9920 - val_loss: 0.0285 - val_accuracy: 0.9920\n",
            "Epoch 1064/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0234 - accuracy: 0.9921 - val_loss: 0.0296 - val_accuracy: 0.9920\n",
            "Epoch 1065/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0233 - accuracy: 0.9923 - val_loss: 0.0297 - val_accuracy: 0.9924\n",
            "Epoch 1066/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0232 - accuracy: 0.9928 - val_loss: 0.0293 - val_accuracy: 0.9932\n",
            "Epoch 1067/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0237 - accuracy: 0.9920 - val_loss: 0.0282 - val_accuracy: 0.9920\n",
            "Epoch 1068/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0230 - accuracy: 0.9925 - val_loss: 0.0275 - val_accuracy: 0.9932\n",
            "Epoch 1069/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0231 - accuracy: 0.9916 - val_loss: 0.0310 - val_accuracy: 0.9920\n",
            "Epoch 1070/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0232 - accuracy: 0.9929 - val_loss: 0.0297 - val_accuracy: 0.9920\n",
            "Epoch 1071/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0233 - accuracy: 0.9924 - val_loss: 0.0296 - val_accuracy: 0.9928\n",
            "Epoch 1072/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0231 - accuracy: 0.9924 - val_loss: 0.0280 - val_accuracy: 0.9928\n",
            "Epoch 1073/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0232 - accuracy: 0.9937 - val_loss: 0.0272 - val_accuracy: 0.9920\n",
            "Epoch 1074/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0234 - accuracy: 0.9917 - val_loss: 0.0298 - val_accuracy: 0.9924\n",
            "Epoch 1075/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0232 - accuracy: 0.9924 - val_loss: 0.0339 - val_accuracy: 0.9908\n",
            "Epoch 1076/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0233 - accuracy: 0.9916 - val_loss: 0.0308 - val_accuracy: 0.9928\n",
            "Epoch 1077/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0228 - accuracy: 0.9936 - val_loss: 0.0269 - val_accuracy: 0.9924\n",
            "Epoch 1078/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0224 - accuracy: 0.9928 - val_loss: 0.0291 - val_accuracy: 0.9928\n",
            "Epoch 1079/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0227 - accuracy: 0.9927 - val_loss: 0.0355 - val_accuracy: 0.9900\n",
            "Epoch 1080/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0226 - accuracy: 0.9929 - val_loss: 0.0294 - val_accuracy: 0.9920\n",
            "Epoch 1081/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0233 - accuracy: 0.9927 - val_loss: 0.0387 - val_accuracy: 0.9892\n",
            "Epoch 1082/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0229 - accuracy: 0.9921 - val_loss: 0.0299 - val_accuracy: 0.9928\n",
            "Epoch 1083/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0233 - accuracy: 0.9935 - val_loss: 0.0286 - val_accuracy: 0.9928\n",
            "Epoch 1084/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0227 - accuracy: 0.9925 - val_loss: 0.0293 - val_accuracy: 0.9904\n",
            "Epoch 1085/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0227 - accuracy: 0.9924 - val_loss: 0.0320 - val_accuracy: 0.9920\n",
            "Epoch 1086/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0226 - accuracy: 0.9924 - val_loss: 0.0282 - val_accuracy: 0.9920\n",
            "Epoch 1087/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0231 - accuracy: 0.9927 - val_loss: 0.0285 - val_accuracy: 0.9924\n",
            "Epoch 1088/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0226 - accuracy: 0.9932 - val_loss: 0.0310 - val_accuracy: 0.9920\n",
            "Epoch 1089/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0233 - accuracy: 0.9923 - val_loss: 0.0271 - val_accuracy: 0.9936\n",
            "Epoch 1090/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0225 - accuracy: 0.9931 - val_loss: 0.0279 - val_accuracy: 0.9928\n",
            "Epoch 1091/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0230 - accuracy: 0.9916 - val_loss: 0.0282 - val_accuracy: 0.9924\n",
            "Epoch 1092/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0227 - accuracy: 0.9925 - val_loss: 0.0285 - val_accuracy: 0.9920\n",
            "Epoch 1093/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0225 - accuracy: 0.9919 - val_loss: 0.0292 - val_accuracy: 0.9932\n",
            "Epoch 1094/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0229 - accuracy: 0.9923 - val_loss: 0.0338 - val_accuracy: 0.9916\n",
            "Epoch 1095/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0228 - accuracy: 0.9925 - val_loss: 0.0287 - val_accuracy: 0.9928\n",
            "Epoch 1096/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0225 - accuracy: 0.9927 - val_loss: 0.0289 - val_accuracy: 0.9932\n",
            "Epoch 1097/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0224 - accuracy: 0.9920 - val_loss: 0.0276 - val_accuracy: 0.9928\n",
            "Epoch 1098/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0229 - accuracy: 0.9929 - val_loss: 0.0296 - val_accuracy: 0.9912\n",
            "Epoch 1099/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0228 - accuracy: 0.9920 - val_loss: 0.0336 - val_accuracy: 0.9888\n",
            "Epoch 1100/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0228 - accuracy: 0.9920 - val_loss: 0.0285 - val_accuracy: 0.9924\n",
            "Epoch 1101/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0224 - accuracy: 0.9924 - val_loss: 0.0278 - val_accuracy: 0.9932\n",
            "Epoch 1102/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0228 - accuracy: 0.9920 - val_loss: 0.0277 - val_accuracy: 0.9928\n",
            "Epoch 1103/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9929 - val_loss: 0.0274 - val_accuracy: 0.9928\n",
            "Epoch 1104/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0224 - accuracy: 0.9929 - val_loss: 0.0303 - val_accuracy: 0.9900\n",
            "Epoch 1105/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0223 - accuracy: 0.9925 - val_loss: 0.0276 - val_accuracy: 0.9936\n",
            "Epoch 1106/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0222 - accuracy: 0.9925 - val_loss: 0.0347 - val_accuracy: 0.9912\n",
            "Epoch 1107/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0232 - accuracy: 0.9923 - val_loss: 0.0285 - val_accuracy: 0.9928\n",
            "Epoch 1108/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0226 - accuracy: 0.9929 - val_loss: 0.0312 - val_accuracy: 0.9912\n",
            "Epoch 1109/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0224 - accuracy: 0.9929 - val_loss: 0.0271 - val_accuracy: 0.9940\n",
            "Epoch 1110/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0231 - accuracy: 0.9927 - val_loss: 0.0270 - val_accuracy: 0.9928\n",
            "Epoch 1111/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0225 - accuracy: 0.9927 - val_loss: 0.0287 - val_accuracy: 0.9928\n",
            "Epoch 1112/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0222 - accuracy: 0.9927 - val_loss: 0.0277 - val_accuracy: 0.9924\n",
            "Epoch 1113/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0227 - accuracy: 0.9931 - val_loss: 0.0278 - val_accuracy: 0.9928\n",
            "Epoch 1114/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0222 - accuracy: 0.9932 - val_loss: 0.0268 - val_accuracy: 0.9940\n",
            "Epoch 1115/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0225 - accuracy: 0.9916 - val_loss: 0.0296 - val_accuracy: 0.9928\n",
            "Epoch 1116/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0226 - accuracy: 0.9927 - val_loss: 0.0294 - val_accuracy: 0.9916\n",
            "Epoch 1117/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0226 - accuracy: 0.9929 - val_loss: 0.0270 - val_accuracy: 0.9932\n",
            "Epoch 1118/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0225 - accuracy: 0.9927 - val_loss: 0.0281 - val_accuracy: 0.9928\n",
            "Epoch 1119/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0223 - accuracy: 0.9929 - val_loss: 0.0272 - val_accuracy: 0.9932\n",
            "Epoch 1120/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0225 - accuracy: 0.9927 - val_loss: 0.0278 - val_accuracy: 0.9940\n",
            "Epoch 1121/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0228 - accuracy: 0.9929 - val_loss: 0.0287 - val_accuracy: 0.9920\n",
            "Epoch 1122/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0222 - accuracy: 0.9928 - val_loss: 0.0273 - val_accuracy: 0.9932\n",
            "Epoch 1123/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0224 - accuracy: 0.9923 - val_loss: 0.0293 - val_accuracy: 0.9932\n",
            "Epoch 1124/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0223 - accuracy: 0.9928 - val_loss: 0.0308 - val_accuracy: 0.9932\n",
            "Epoch 1125/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0224 - accuracy: 0.9927 - val_loss: 0.0300 - val_accuracy: 0.9932\n",
            "Epoch 1126/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0220 - accuracy: 0.9932 - val_loss: 0.0267 - val_accuracy: 0.9936\n",
            "Epoch 1127/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 0.0296 - val_accuracy: 0.9916\n",
            "Epoch 1128/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0224 - accuracy: 0.9927 - val_loss: 0.0273 - val_accuracy: 0.9928\n",
            "Epoch 1129/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0219 - accuracy: 0.9927 - val_loss: 0.0278 - val_accuracy: 0.9932\n",
            "Epoch 1130/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0218 - accuracy: 0.9932 - val_loss: 0.0255 - val_accuracy: 0.9932\n",
            "Epoch 1131/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0220 - accuracy: 0.9929 - val_loss: 0.0299 - val_accuracy: 0.9920\n",
            "Epoch 1132/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0221 - accuracy: 0.9929 - val_loss: 0.0256 - val_accuracy: 0.9924\n",
            "Epoch 1133/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9923 - val_loss: 0.0281 - val_accuracy: 0.9932\n",
            "Epoch 1134/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0224 - accuracy: 0.9921 - val_loss: 0.0299 - val_accuracy: 0.9924\n",
            "Epoch 1135/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0220 - accuracy: 0.9928 - val_loss: 0.0273 - val_accuracy: 0.9928\n",
            "Epoch 1136/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0220 - accuracy: 0.9921 - val_loss: 0.0306 - val_accuracy: 0.9916\n",
            "Epoch 1137/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0222 - accuracy: 0.9925 - val_loss: 0.0276 - val_accuracy: 0.9928\n",
            "Epoch 1138/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0217 - accuracy: 0.9931 - val_loss: 0.0290 - val_accuracy: 0.9928\n",
            "Epoch 1139/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0219 - accuracy: 0.9925 - val_loss: 0.0265 - val_accuracy: 0.9928\n",
            "Epoch 1140/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0219 - accuracy: 0.9927 - val_loss: 0.0368 - val_accuracy: 0.9880\n",
            "Epoch 1141/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0214 - accuracy: 0.9932 - val_loss: 0.0278 - val_accuracy: 0.9916\n",
            "Epoch 1142/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0216 - accuracy: 0.9923 - val_loss: 0.0307 - val_accuracy: 0.9924\n",
            "Epoch 1143/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0219 - accuracy: 0.9931 - val_loss: 0.0265 - val_accuracy: 0.9928\n",
            "Epoch 1144/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0215 - accuracy: 0.9927 - val_loss: 0.0268 - val_accuracy: 0.9936\n",
            "Epoch 1145/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0210 - accuracy: 0.9927 - val_loss: 0.0284 - val_accuracy: 0.9928\n",
            "Epoch 1146/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0217 - accuracy: 0.9928 - val_loss: 0.0301 - val_accuracy: 0.9924\n",
            "Epoch 1147/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0222 - accuracy: 0.9931 - val_loss: 0.0266 - val_accuracy: 0.9936\n",
            "Epoch 1148/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0220 - accuracy: 0.9921 - val_loss: 0.0295 - val_accuracy: 0.9924\n",
            "Epoch 1149/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0218 - accuracy: 0.9929 - val_loss: 0.0294 - val_accuracy: 0.9916\n",
            "Epoch 1150/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 0.0269 - val_accuracy: 0.9936\n",
            "Epoch 1151/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 0.0283 - val_accuracy: 0.9940\n",
            "Epoch 1152/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0217 - accuracy: 0.9929 - val_loss: 0.0301 - val_accuracy: 0.9920\n",
            "Epoch 1153/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0218 - accuracy: 0.9924 - val_loss: 0.0268 - val_accuracy: 0.9932\n",
            "Epoch 1154/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0215 - accuracy: 0.9932 - val_loss: 0.0281 - val_accuracy: 0.9924\n",
            "Epoch 1155/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0218 - accuracy: 0.9923 - val_loss: 0.0290 - val_accuracy: 0.9908\n",
            "Epoch 1156/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0213 - accuracy: 0.9928 - val_loss: 0.0270 - val_accuracy: 0.9928\n",
            "Epoch 1157/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0211 - accuracy: 0.9940 - val_loss: 0.0301 - val_accuracy: 0.9916\n",
            "Epoch 1158/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0210 - accuracy: 0.9928 - val_loss: 0.0278 - val_accuracy: 0.9924\n",
            "Epoch 1159/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0218 - accuracy: 0.9929 - val_loss: 0.0261 - val_accuracy: 0.9936\n",
            "Epoch 1160/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0213 - accuracy: 0.9931 - val_loss: 0.0267 - val_accuracy: 0.9928\n",
            "Epoch 1161/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0208 - accuracy: 0.9932 - val_loss: 0.0317 - val_accuracy: 0.9908\n",
            "Epoch 1162/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0220 - accuracy: 0.9924 - val_loss: 0.0285 - val_accuracy: 0.9940\n",
            "Epoch 1163/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0216 - accuracy: 0.9929 - val_loss: 0.0272 - val_accuracy: 0.9944\n",
            "Epoch 1164/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0212 - accuracy: 0.9931 - val_loss: 0.0270 - val_accuracy: 0.9940\n",
            "Epoch 1165/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0214 - accuracy: 0.9925 - val_loss: 0.0293 - val_accuracy: 0.9928\n",
            "Epoch 1166/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0217 - accuracy: 0.9933 - val_loss: 0.0275 - val_accuracy: 0.9928\n",
            "Epoch 1167/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0213 - accuracy: 0.9928 - val_loss: 0.0265 - val_accuracy: 0.9936\n",
            "Epoch 1168/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0215 - accuracy: 0.9927 - val_loss: 0.0272 - val_accuracy: 0.9936\n",
            "Epoch 1169/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0207 - accuracy: 0.9936 - val_loss: 0.0370 - val_accuracy: 0.9888\n",
            "Epoch 1170/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0216 - accuracy: 0.9925 - val_loss: 0.0271 - val_accuracy: 0.9940\n",
            "Epoch 1171/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0208 - accuracy: 0.9935 - val_loss: 0.0275 - val_accuracy: 0.9940\n",
            "Epoch 1172/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0214 - accuracy: 0.9924 - val_loss: 0.0273 - val_accuracy: 0.9936\n",
            "Epoch 1173/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0213 - accuracy: 0.9932 - val_loss: 0.0342 - val_accuracy: 0.9916\n",
            "Epoch 1174/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0208 - accuracy: 0.9929 - val_loss: 0.0315 - val_accuracy: 0.9928\n",
            "Epoch 1175/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0213 - accuracy: 0.9940 - val_loss: 0.0286 - val_accuracy: 0.9924\n",
            "Epoch 1176/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0215 - accuracy: 0.9928 - val_loss: 0.0259 - val_accuracy: 0.9936\n",
            "Epoch 1177/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0207 - accuracy: 0.9937 - val_loss: 0.0285 - val_accuracy: 0.9928\n",
            "Epoch 1178/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0209 - accuracy: 0.9931 - val_loss: 0.0288 - val_accuracy: 0.9924\n",
            "Epoch 1179/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0211 - accuracy: 0.9932 - val_loss: 0.0264 - val_accuracy: 0.9932\n",
            "Epoch 1180/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0214 - accuracy: 0.9931 - val_loss: 0.0302 - val_accuracy: 0.9904\n",
            "Epoch 1181/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0205 - accuracy: 0.9937 - val_loss: 0.0354 - val_accuracy: 0.9920\n",
            "Epoch 1182/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0210 - accuracy: 0.9940 - val_loss: 0.0276 - val_accuracy: 0.9936\n",
            "Epoch 1183/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0207 - accuracy: 0.9936 - val_loss: 0.0260 - val_accuracy: 0.9940\n",
            "Epoch 1184/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0208 - accuracy: 0.9931 - val_loss: 0.0267 - val_accuracy: 0.9936\n",
            "Epoch 1185/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0208 - accuracy: 0.9936 - val_loss: 0.0287 - val_accuracy: 0.9912\n",
            "Epoch 1186/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0214 - accuracy: 0.9923 - val_loss: 0.0268 - val_accuracy: 0.9932\n",
            "Epoch 1187/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 0.0323 - val_accuracy: 0.9920\n",
            "Epoch 1188/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0213 - accuracy: 0.9929 - val_loss: 0.0281 - val_accuracy: 0.9932\n",
            "Epoch 1189/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0202 - accuracy: 0.9944 - val_loss: 0.0286 - val_accuracy: 0.9932\n",
            "Epoch 1190/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0207 - accuracy: 0.9937 - val_loss: 0.0293 - val_accuracy: 0.9932\n",
            "Epoch 1191/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0210 - accuracy: 0.9931 - val_loss: 0.0315 - val_accuracy: 0.9928\n",
            "Epoch 1192/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0214 - accuracy: 0.9929 - val_loss: 0.0294 - val_accuracy: 0.9932\n",
            "Epoch 1193/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0206 - accuracy: 0.9935 - val_loss: 0.0334 - val_accuracy: 0.9940\n",
            "Epoch 1194/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0208 - accuracy: 0.9940 - val_loss: 0.0271 - val_accuracy: 0.9940\n",
            "Epoch 1195/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0206 - accuracy: 0.9937 - val_loss: 0.0268 - val_accuracy: 0.9932\n",
            "Epoch 1196/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0204 - accuracy: 0.9939 - val_loss: 0.0271 - val_accuracy: 0.9940\n",
            "Epoch 1197/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0204 - accuracy: 0.9940 - val_loss: 0.0284 - val_accuracy: 0.9916\n",
            "Epoch 1198/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0204 - accuracy: 0.9932 - val_loss: 0.0270 - val_accuracy: 0.9940\n",
            "Epoch 1199/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0205 - accuracy: 0.9935 - val_loss: 0.0278 - val_accuracy: 0.9932\n",
            "Epoch 1200/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0206 - accuracy: 0.9937 - val_loss: 0.0273 - val_accuracy: 0.9928\n",
            "Epoch 1201/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0198 - accuracy: 0.9941 - val_loss: 0.0275 - val_accuracy: 0.9928\n",
            "Epoch 1202/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0201 - accuracy: 0.9939 - val_loss: 0.0291 - val_accuracy: 0.9940\n",
            "Epoch 1203/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0206 - accuracy: 0.9935 - val_loss: 0.0301 - val_accuracy: 0.9920\n",
            "Epoch 1204/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0206 - accuracy: 0.9932 - val_loss: 0.0270 - val_accuracy: 0.9928\n",
            "Epoch 1205/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0200 - accuracy: 0.9943 - val_loss: 0.0279 - val_accuracy: 0.9928\n",
            "Epoch 1206/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0199 - accuracy: 0.9932 - val_loss: 0.0297 - val_accuracy: 0.9924\n",
            "Epoch 1207/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0205 - accuracy: 0.9936 - val_loss: 0.0275 - val_accuracy: 0.9936\n",
            "Epoch 1208/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0207 - accuracy: 0.9928 - val_loss: 0.0281 - val_accuracy: 0.9932\n",
            "Epoch 1209/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 0.0269 - val_accuracy: 0.9936\n",
            "Epoch 1210/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0203 - accuracy: 0.9931 - val_loss: 0.0269 - val_accuracy: 0.9944\n",
            "Epoch 1211/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0204 - accuracy: 0.9933 - val_loss: 0.0296 - val_accuracy: 0.9920\n",
            "Epoch 1212/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0205 - accuracy: 0.9935 - val_loss: 0.0283 - val_accuracy: 0.9936\n",
            "Epoch 1213/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0209 - accuracy: 0.9933 - val_loss: 0.0261 - val_accuracy: 0.9936\n",
            "Epoch 1214/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0203 - accuracy: 0.9940 - val_loss: 0.0277 - val_accuracy: 0.9924\n",
            "Epoch 1215/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0202 - accuracy: 0.9937 - val_loss: 0.0279 - val_accuracy: 0.9932\n",
            "Epoch 1216/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.0280 - val_accuracy: 0.9936\n",
            "Epoch 1217/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.0266 - val_accuracy: 0.9944\n",
            "Epoch 1218/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0206 - accuracy: 0.9939 - val_loss: 0.0298 - val_accuracy: 0.9928\n",
            "Epoch 1219/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0205 - accuracy: 0.9936 - val_loss: 0.0290 - val_accuracy: 0.9932\n",
            "Epoch 1220/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0202 - accuracy: 0.9943 - val_loss: 0.0299 - val_accuracy: 0.9924\n",
            "Epoch 1221/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0205 - accuracy: 0.9939 - val_loss: 0.0290 - val_accuracy: 0.9928\n",
            "Epoch 1222/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0203 - accuracy: 0.9932 - val_loss: 0.0277 - val_accuracy: 0.9924\n",
            "Epoch 1223/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0201 - accuracy: 0.9932 - val_loss: 0.0269 - val_accuracy: 0.9936\n",
            "Epoch 1224/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0199 - accuracy: 0.9943 - val_loss: 0.0337 - val_accuracy: 0.9928\n",
            "Epoch 1225/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 0.0340 - val_accuracy: 0.9924\n",
            "Epoch 1226/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0205 - accuracy: 0.9940 - val_loss: 0.0275 - val_accuracy: 0.9932\n",
            "Epoch 1227/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0200 - accuracy: 0.9929 - val_loss: 0.0271 - val_accuracy: 0.9936\n",
            "Epoch 1228/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0199 - accuracy: 0.9933 - val_loss: 0.0279 - val_accuracy: 0.9932\n",
            "Epoch 1229/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0199 - accuracy: 0.9944 - val_loss: 0.0268 - val_accuracy: 0.9936\n",
            "Epoch 1230/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0204 - accuracy: 0.9939 - val_loss: 0.0266 - val_accuracy: 0.9944\n",
            "Epoch 1231/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0201 - accuracy: 0.9943 - val_loss: 0.0273 - val_accuracy: 0.9928\n",
            "Epoch 1232/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0200 - accuracy: 0.9933 - val_loss: 0.0291 - val_accuracy: 0.9924\n",
            "Epoch 1233/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0204 - accuracy: 0.9935 - val_loss: 0.0274 - val_accuracy: 0.9928\n",
            "Epoch 1234/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.0281 - val_accuracy: 0.9936\n",
            "Epoch 1235/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0198 - accuracy: 0.9937 - val_loss: 0.0298 - val_accuracy: 0.9932\n",
            "Epoch 1236/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 0.0288 - val_accuracy: 0.9932\n",
            "Epoch 1237/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0200 - accuracy: 0.9937 - val_loss: 0.0308 - val_accuracy: 0.9928\n",
            "Epoch 1238/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0193 - accuracy: 0.9940 - val_loss: 0.0265 - val_accuracy: 0.9944\n",
            "Epoch 1239/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0199 - accuracy: 0.9941 - val_loss: 0.0265 - val_accuracy: 0.9940\n",
            "Epoch 1240/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0196 - accuracy: 0.9939 - val_loss: 0.0278 - val_accuracy: 0.9936\n",
            "Epoch 1241/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0202 - accuracy: 0.9941 - val_loss: 0.0266 - val_accuracy: 0.9936\n",
            "Epoch 1242/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0208 - accuracy: 0.9928 - val_loss: 0.0268 - val_accuracy: 0.9940\n",
            "Epoch 1243/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0192 - accuracy: 0.9949 - val_loss: 0.0274 - val_accuracy: 0.9940\n",
            "Epoch 1244/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0193 - accuracy: 0.9951 - val_loss: 0.0280 - val_accuracy: 0.9940\n",
            "Epoch 1245/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0196 - accuracy: 0.9937 - val_loss: 0.0300 - val_accuracy: 0.9936\n",
            "Epoch 1246/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0201 - accuracy: 0.9932 - val_loss: 0.0275 - val_accuracy: 0.9936\n",
            "Epoch 1247/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0195 - accuracy: 0.9944 - val_loss: 0.0274 - val_accuracy: 0.9932\n",
            "Epoch 1248/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0202 - accuracy: 0.9936 - val_loss: 0.0294 - val_accuracy: 0.9916\n",
            "Epoch 1249/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0198 - accuracy: 0.9936 - val_loss: 0.0320 - val_accuracy: 0.9932\n",
            "Epoch 1250/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0199 - accuracy: 0.9933 - val_loss: 0.0265 - val_accuracy: 0.9932\n",
            "Epoch 1251/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0193 - accuracy: 0.9948 - val_loss: 0.0293 - val_accuracy: 0.9936\n",
            "Epoch 1252/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 0.0277 - val_accuracy: 0.9932\n",
            "Epoch 1253/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0201 - accuracy: 0.9931 - val_loss: 0.0264 - val_accuracy: 0.9932\n",
            "Epoch 1254/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0198 - accuracy: 0.9936 - val_loss: 0.0297 - val_accuracy: 0.9932\n",
            "Epoch 1255/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0201 - accuracy: 0.9940 - val_loss: 0.0280 - val_accuracy: 0.9944\n",
            "Epoch 1256/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0193 - accuracy: 0.9939 - val_loss: 0.0272 - val_accuracy: 0.9936\n",
            "Epoch 1257/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0196 - accuracy: 0.9937 - val_loss: 0.0287 - val_accuracy: 0.9932\n",
            "Epoch 1258/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0193 - accuracy: 0.9945 - val_loss: 0.0263 - val_accuracy: 0.9944\n",
            "Epoch 1259/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0198 - accuracy: 0.9935 - val_loss: 0.0272 - val_accuracy: 0.9940\n",
            "Epoch 1260/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0192 - accuracy: 0.9941 - val_loss: 0.0271 - val_accuracy: 0.9936\n",
            "Epoch 1261/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0194 - accuracy: 0.9937 - val_loss: 0.0267 - val_accuracy: 0.9940\n",
            "Epoch 1262/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0198 - accuracy: 0.9941 - val_loss: 0.0292 - val_accuracy: 0.9928\n",
            "Epoch 1263/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0191 - accuracy: 0.9936 - val_loss: 0.0283 - val_accuracy: 0.9940\n",
            "Epoch 1264/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0195 - accuracy: 0.9940 - val_loss: 0.0265 - val_accuracy: 0.9944\n",
            "Epoch 1265/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0193 - accuracy: 0.9937 - val_loss: 0.0690 - val_accuracy: 0.9772\n",
            "Epoch 1266/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0198 - accuracy: 0.9928 - val_loss: 0.0291 - val_accuracy: 0.9936\n",
            "Epoch 1267/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0192 - accuracy: 0.9941 - val_loss: 0.0337 - val_accuracy: 0.9924\n",
            "Epoch 1268/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0197 - accuracy: 0.9936 - val_loss: 0.0289 - val_accuracy: 0.9932\n",
            "Epoch 1269/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0195 - accuracy: 0.9939 - val_loss: 0.0273 - val_accuracy: 0.9940\n",
            "Epoch 1270/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.0271 - val_accuracy: 0.9940\n",
            "Epoch 1271/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0196 - accuracy: 0.9940 - val_loss: 0.0272 - val_accuracy: 0.9936\n",
            "Epoch 1272/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0201 - accuracy: 0.9935 - val_loss: 0.0284 - val_accuracy: 0.9928\n",
            "Epoch 1273/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0195 - accuracy: 0.9937 - val_loss: 0.0294 - val_accuracy: 0.9936\n",
            "Epoch 1274/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0189 - accuracy: 0.9947 - val_loss: 0.0274 - val_accuracy: 0.9936\n",
            "Epoch 1275/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0193 - accuracy: 0.9933 - val_loss: 0.0277 - val_accuracy: 0.9940\n",
            "Epoch 1276/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0191 - accuracy: 0.9944 - val_loss: 0.0266 - val_accuracy: 0.9940\n",
            "Epoch 1277/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0190 - accuracy: 0.9941 - val_loss: 0.0345 - val_accuracy: 0.9908\n",
            "Epoch 1278/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0194 - accuracy: 0.9944 - val_loss: 0.0266 - val_accuracy: 0.9932\n",
            "Epoch 1279/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0192 - accuracy: 0.9944 - val_loss: 0.0290 - val_accuracy: 0.9944\n",
            "Epoch 1280/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 0.0278 - val_accuracy: 0.9932\n",
            "Epoch 1281/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
            "Epoch 1282/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0186 - accuracy: 0.9945 - val_loss: 0.0274 - val_accuracy: 0.9932\n",
            "Epoch 1283/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0192 - accuracy: 0.9939 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
            "Epoch 1284/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0192 - accuracy: 0.9940 - val_loss: 0.0274 - val_accuracy: 0.9940\n",
            "Epoch 1285/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0184 - accuracy: 0.9940 - val_loss: 0.0275 - val_accuracy: 0.9936\n",
            "Epoch 1286/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.0309 - val_accuracy: 0.9932\n",
            "Epoch 1287/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0194 - accuracy: 0.9936 - val_loss: 0.0279 - val_accuracy: 0.9936\n",
            "Epoch 1288/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0187 - accuracy: 0.9944 - val_loss: 0.0265 - val_accuracy: 0.9932\n",
            "Epoch 1289/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0193 - accuracy: 0.9935 - val_loss: 0.0294 - val_accuracy: 0.9944\n",
            "Epoch 1290/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0191 - accuracy: 0.9944 - val_loss: 0.0390 - val_accuracy: 0.9868\n",
            "Epoch 1291/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0190 - accuracy: 0.9941 - val_loss: 0.0266 - val_accuracy: 0.9932\n",
            "Epoch 1292/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0190 - accuracy: 0.9941 - val_loss: 0.0259 - val_accuracy: 0.9944\n",
            "Epoch 1293/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0195 - accuracy: 0.9936 - val_loss: 0.0265 - val_accuracy: 0.9936\n",
            "Epoch 1294/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0186 - accuracy: 0.9943 - val_loss: 0.0267 - val_accuracy: 0.9936\n",
            "Epoch 1295/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.0276 - val_accuracy: 0.9940\n",
            "Epoch 1296/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0193 - accuracy: 0.9944 - val_loss: 0.0269 - val_accuracy: 0.9944\n",
            "Epoch 1297/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.0272 - val_accuracy: 0.9936\n",
            "Epoch 1298/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0193 - accuracy: 0.9933 - val_loss: 0.0293 - val_accuracy: 0.9936\n",
            "Epoch 1299/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0187 - accuracy: 0.9943 - val_loss: 0.0278 - val_accuracy: 0.9936\n",
            "Epoch 1300/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0189 - accuracy: 0.9944 - val_loss: 0.0263 - val_accuracy: 0.9944\n",
            "Epoch 1301/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0188 - accuracy: 0.9944 - val_loss: 0.0305 - val_accuracy: 0.9928\n",
            "Epoch 1302/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0183 - accuracy: 0.9948 - val_loss: 0.0272 - val_accuracy: 0.9940\n",
            "Epoch 1303/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0190 - accuracy: 0.9943 - val_loss: 0.0283 - val_accuracy: 0.9936\n",
            "Epoch 1304/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0184 - accuracy: 0.9944 - val_loss: 0.0272 - val_accuracy: 0.9944\n",
            "Epoch 1305/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0191 - accuracy: 0.9943 - val_loss: 0.0279 - val_accuracy: 0.9932\n",
            "Epoch 1306/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0183 - accuracy: 0.9944 - val_loss: 0.0314 - val_accuracy: 0.9928\n",
            "Epoch 1307/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0196 - accuracy: 0.9937 - val_loss: 0.0281 - val_accuracy: 0.9932\n",
            "Epoch 1308/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0181 - accuracy: 0.9948 - val_loss: 0.0337 - val_accuracy: 0.9928\n",
            "Epoch 1309/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0189 - accuracy: 0.9944 - val_loss: 0.0272 - val_accuracy: 0.9940\n",
            "Epoch 1310/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0190 - accuracy: 0.9935 - val_loss: 0.0268 - val_accuracy: 0.9940\n",
            "Epoch 1311/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0190 - accuracy: 0.9937 - val_loss: 0.0278 - val_accuracy: 0.9936\n",
            "Epoch 1312/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0188 - accuracy: 0.9945 - val_loss: 0.0273 - val_accuracy: 0.9940\n",
            "Epoch 1313/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0186 - accuracy: 0.9944 - val_loss: 0.0315 - val_accuracy: 0.9928\n",
            "Epoch 1314/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0188 - accuracy: 0.9937 - val_loss: 0.0279 - val_accuracy: 0.9940\n",
            "Epoch 1315/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0186 - accuracy: 0.9937 - val_loss: 0.0294 - val_accuracy: 0.9936\n",
            "Epoch 1316/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0184 - accuracy: 0.9941 - val_loss: 0.0268 - val_accuracy: 0.9936\n",
            "Epoch 1317/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0188 - accuracy: 0.9947 - val_loss: 0.0267 - val_accuracy: 0.9940\n",
            "Epoch 1318/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0182 - accuracy: 0.9944 - val_loss: 0.0280 - val_accuracy: 0.9936\n",
            "Epoch 1319/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.0261 - val_accuracy: 0.9948\n",
            "Epoch 1320/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0187 - accuracy: 0.9935 - val_loss: 0.0270 - val_accuracy: 0.9944\n",
            "Epoch 1321/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0185 - accuracy: 0.9941 - val_loss: 0.0273 - val_accuracy: 0.9940\n",
            "Epoch 1322/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0185 - accuracy: 0.9948 - val_loss: 0.0275 - val_accuracy: 0.9940\n",
            "Epoch 1323/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0184 - accuracy: 0.9949 - val_loss: 0.0272 - val_accuracy: 0.9940\n",
            "Epoch 1324/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0185 - accuracy: 0.9939 - val_loss: 0.0272 - val_accuracy: 0.9944\n",
            "Epoch 1325/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0188 - accuracy: 0.9944 - val_loss: 0.0298 - val_accuracy: 0.9928\n",
            "Epoch 1326/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0179 - accuracy: 0.9949 - val_loss: 0.0280 - val_accuracy: 0.9940\n",
            "Epoch 1327/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0185 - accuracy: 0.9943 - val_loss: 0.0279 - val_accuracy: 0.9940\n",
            "Epoch 1328/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0182 - accuracy: 0.9953 - val_loss: 0.0282 - val_accuracy: 0.9944\n",
            "Epoch 1329/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.0266 - val_accuracy: 0.9936\n",
            "Epoch 1330/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0186 - accuracy: 0.9947 - val_loss: 0.0275 - val_accuracy: 0.9940\n",
            "Epoch 1331/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0181 - accuracy: 0.9943 - val_loss: 0.0273 - val_accuracy: 0.9944\n",
            "Epoch 1332/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.0304 - val_accuracy: 0.9928\n",
            "Epoch 1333/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0190 - accuracy: 0.9943 - val_loss: 0.0307 - val_accuracy: 0.9924\n",
            "Epoch 1334/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0182 - accuracy: 0.9945 - val_loss: 0.0282 - val_accuracy: 0.9932\n",
            "Epoch 1335/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0186 - accuracy: 0.9939 - val_loss: 0.0268 - val_accuracy: 0.9944\n",
            "Epoch 1336/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0183 - accuracy: 0.9941 - val_loss: 0.0269 - val_accuracy: 0.9940\n",
            "Epoch 1337/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0184 - accuracy: 0.9943 - val_loss: 0.0271 - val_accuracy: 0.9944\n",
            "Epoch 1338/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.0286 - val_accuracy: 0.9932\n",
            "Epoch 1339/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.0291 - val_accuracy: 0.9924\n",
            "Epoch 1340/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0186 - accuracy: 0.9945 - val_loss: 0.0267 - val_accuracy: 0.9940\n",
            "Epoch 1341/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0182 - accuracy: 0.9943 - val_loss: 0.0266 - val_accuracy: 0.9952\n",
            "Epoch 1342/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.0283 - val_accuracy: 0.9936\n",
            "Epoch 1343/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0176 - accuracy: 0.9949 - val_loss: 0.0287 - val_accuracy: 0.9940\n",
            "Epoch 1344/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0180 - accuracy: 0.9943 - val_loss: 0.0269 - val_accuracy: 0.9936\n",
            "Epoch 1345/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0185 - accuracy: 0.9937 - val_loss: 0.0270 - val_accuracy: 0.9952\n",
            "Epoch 1346/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0182 - accuracy: 0.9947 - val_loss: 0.0276 - val_accuracy: 0.9936\n",
            "Epoch 1347/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0178 - accuracy: 0.9948 - val_loss: 0.0278 - val_accuracy: 0.9940\n",
            "Epoch 1348/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.0279 - val_accuracy: 0.9940\n",
            "Epoch 1349/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0183 - accuracy: 0.9945 - val_loss: 0.0279 - val_accuracy: 0.9940\n",
            "Epoch 1350/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0181 - accuracy: 0.9941 - val_loss: 0.0274 - val_accuracy: 0.9956\n",
            "Epoch 1351/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0180 - accuracy: 0.9943 - val_loss: 0.0303 - val_accuracy: 0.9936\n",
            "Epoch 1352/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.0334 - val_accuracy: 0.9932\n",
            "Epoch 1353/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0179 - accuracy: 0.9941 - val_loss: 0.0311 - val_accuracy: 0.9928\n",
            "Epoch 1354/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0186 - accuracy: 0.9941 - val_loss: 0.0291 - val_accuracy: 0.9924\n",
            "Epoch 1355/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0179 - accuracy: 0.9939 - val_loss: 0.0274 - val_accuracy: 0.9940\n",
            "Epoch 1356/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0183 - accuracy: 0.9945 - val_loss: 0.0260 - val_accuracy: 0.9952\n",
            "Epoch 1357/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 0.0275 - val_accuracy: 0.9944\n",
            "Epoch 1358/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0180 - accuracy: 0.9944 - val_loss: 0.0267 - val_accuracy: 0.9932\n",
            "Epoch 1359/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0181 - accuracy: 0.9949 - val_loss: 0.0316 - val_accuracy: 0.9932\n",
            "Epoch 1360/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0180 - accuracy: 0.9948 - val_loss: 0.0822 - val_accuracy: 0.9692\n",
            "Epoch 1361/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 0.0274 - val_accuracy: 0.9936\n",
            "Epoch 1362/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0181 - accuracy: 0.9948 - val_loss: 0.0265 - val_accuracy: 0.9948\n",
            "Epoch 1363/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 0.0276 - val_accuracy: 0.9944\n",
            "Epoch 1364/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0179 - accuracy: 0.9943 - val_loss: 0.0278 - val_accuracy: 0.9940\n",
            "Epoch 1365/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0181 - accuracy: 0.9937 - val_loss: 0.0276 - val_accuracy: 0.9936\n",
            "Epoch 1366/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0179 - accuracy: 0.9945 - val_loss: 0.0280 - val_accuracy: 0.9936\n",
            "Epoch 1367/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0182 - accuracy: 0.9945 - val_loss: 0.0264 - val_accuracy: 0.9944\n",
            "Epoch 1368/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0180 - accuracy: 0.9951 - val_loss: 0.0269 - val_accuracy: 0.9948\n",
            "Epoch 1369/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0180 - accuracy: 0.9943 - val_loss: 0.0292 - val_accuracy: 0.9928\n",
            "Epoch 1370/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0177 - accuracy: 0.9944 - val_loss: 0.0287 - val_accuracy: 0.9944\n",
            "Epoch 1371/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0171 - accuracy: 0.9953 - val_loss: 0.0270 - val_accuracy: 0.9944\n",
            "Epoch 1372/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0176 - accuracy: 0.9953 - val_loss: 0.0267 - val_accuracy: 0.9940\n",
            "Epoch 1373/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 0.0267 - val_accuracy: 0.9940\n",
            "Epoch 1374/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0177 - accuracy: 0.9944 - val_loss: 0.0267 - val_accuracy: 0.9940\n",
            "Epoch 1375/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0178 - accuracy: 0.9945 - val_loss: 0.0275 - val_accuracy: 0.9940\n",
            "Epoch 1376/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0175 - accuracy: 0.9949 - val_loss: 0.0310 - val_accuracy: 0.9920\n",
            "Epoch 1377/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0176 - accuracy: 0.9945 - val_loss: 0.0295 - val_accuracy: 0.9944\n",
            "Epoch 1378/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0180 - accuracy: 0.9947 - val_loss: 0.0267 - val_accuracy: 0.9944\n",
            "Epoch 1379/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0179 - accuracy: 0.9952 - val_loss: 0.0275 - val_accuracy: 0.9948\n",
            "Epoch 1380/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0182 - accuracy: 0.9947 - val_loss: 0.0272 - val_accuracy: 0.9944\n",
            "Epoch 1381/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0179 - accuracy: 0.9947 - val_loss: 0.0261 - val_accuracy: 0.9952\n",
            "Epoch 1382/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0174 - accuracy: 0.9947 - val_loss: 0.0258 - val_accuracy: 0.9948\n",
            "Epoch 1383/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0175 - accuracy: 0.9944 - val_loss: 0.0281 - val_accuracy: 0.9936\n",
            "Epoch 1384/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.0293 - val_accuracy: 0.9936\n",
            "Epoch 1385/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 0.0273 - val_accuracy: 0.9948\n",
            "Epoch 1386/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0171 - accuracy: 0.9948 - val_loss: 0.0285 - val_accuracy: 0.9944\n",
            "Epoch 1387/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0179 - accuracy: 0.9943 - val_loss: 0.0260 - val_accuracy: 0.9944\n",
            "Epoch 1388/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0173 - accuracy: 0.9947 - val_loss: 0.0304 - val_accuracy: 0.9916\n",
            "Epoch 1389/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0185 - accuracy: 0.9945 - val_loss: 0.0255 - val_accuracy: 0.9960\n",
            "Epoch 1390/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.0270 - val_accuracy: 0.9944\n",
            "Epoch 1391/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0176 - accuracy: 0.9940 - val_loss: 0.0263 - val_accuracy: 0.9944\n",
            "Epoch 1392/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.0288 - val_accuracy: 0.9928\n",
            "Epoch 1393/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.0267 - val_accuracy: 0.9952\n",
            "Epoch 1394/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0171 - accuracy: 0.9944 - val_loss: 0.0269 - val_accuracy: 0.9944\n",
            "Epoch 1395/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0178 - accuracy: 0.9947 - val_loss: 0.0260 - val_accuracy: 0.9952\n",
            "Epoch 1396/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0172 - accuracy: 0.9951 - val_loss: 0.0261 - val_accuracy: 0.9948\n",
            "Epoch 1397/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0175 - accuracy: 0.9949 - val_loss: 0.0284 - val_accuracy: 0.9928\n",
            "Epoch 1398/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0174 - accuracy: 0.9951 - val_loss: 0.0278 - val_accuracy: 0.9940\n",
            "Epoch 1399/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0173 - accuracy: 0.9949 - val_loss: 0.0288 - val_accuracy: 0.9936\n",
            "Epoch 1400/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0170 - accuracy: 0.9945 - val_loss: 0.0281 - val_accuracy: 0.9940\n",
            "Epoch 1401/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0178 - accuracy: 0.9944 - val_loss: 0.0265 - val_accuracy: 0.9944\n",
            "Epoch 1402/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0175 - accuracy: 0.9949 - val_loss: 0.0266 - val_accuracy: 0.9948\n",
            "Epoch 1403/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0176 - accuracy: 0.9949 - val_loss: 0.0264 - val_accuracy: 0.9948\n",
            "Epoch 1404/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0171 - accuracy: 0.9949 - val_loss: 0.0293 - val_accuracy: 0.9932\n",
            "Epoch 1405/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0177 - accuracy: 0.9941 - val_loss: 0.0261 - val_accuracy: 0.9952\n",
            "Epoch 1406/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0175 - accuracy: 0.9949 - val_loss: 0.0265 - val_accuracy: 0.9940\n",
            "Epoch 1407/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0173 - accuracy: 0.9952 - val_loss: 0.0264 - val_accuracy: 0.9944\n",
            "Epoch 1408/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.0275 - val_accuracy: 0.9940\n",
            "Epoch 1409/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0171 - accuracy: 0.9953 - val_loss: 0.0266 - val_accuracy: 0.9948\n",
            "Epoch 1410/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.0278 - val_accuracy: 0.9944\n",
            "Epoch 1411/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.0272 - val_accuracy: 0.9940\n",
            "Epoch 1412/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0175 - accuracy: 0.9947 - val_loss: 0.0348 - val_accuracy: 0.9936\n",
            "Epoch 1413/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0174 - accuracy: 0.9955 - val_loss: 0.0272 - val_accuracy: 0.9944\n",
            "Epoch 1414/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.0270 - val_accuracy: 0.9944\n",
            "Epoch 1415/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0169 - accuracy: 0.9953 - val_loss: 0.0368 - val_accuracy: 0.9880\n",
            "Epoch 1416/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0179 - accuracy: 0.9948 - val_loss: 0.0281 - val_accuracy: 0.9948\n",
            "Epoch 1417/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0175 - accuracy: 0.9944 - val_loss: 0.0267 - val_accuracy: 0.9948\n",
            "Epoch 1418/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0170 - accuracy: 0.9951 - val_loss: 0.0273 - val_accuracy: 0.9940\n",
            "Epoch 1419/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 0.0265 - val_accuracy: 0.9944\n",
            "Epoch 1420/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0170 - accuracy: 0.9953 - val_loss: 0.0265 - val_accuracy: 0.9944\n",
            "Epoch 1421/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0174 - accuracy: 0.9945 - val_loss: 0.0276 - val_accuracy: 0.9944\n",
            "Epoch 1422/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0169 - accuracy: 0.9955 - val_loss: 0.0269 - val_accuracy: 0.9948\n",
            "Epoch 1423/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0168 - accuracy: 0.9955 - val_loss: 0.0274 - val_accuracy: 0.9952\n",
            "Epoch 1424/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0168 - accuracy: 0.9949 - val_loss: 0.0655 - val_accuracy: 0.9756\n",
            "Epoch 1425/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0173 - accuracy: 0.9955 - val_loss: 0.0263 - val_accuracy: 0.9940\n",
            "Epoch 1426/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.0263 - val_accuracy: 0.9944\n",
            "Epoch 1427/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 0.0287 - val_accuracy: 0.9928\n",
            "Epoch 1428/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0171 - accuracy: 0.9951 - val_loss: 0.0264 - val_accuracy: 0.9952\n",
            "Epoch 1429/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0170 - accuracy: 0.9948 - val_loss: 0.0278 - val_accuracy: 0.9940\n",
            "Epoch 1430/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0170 - accuracy: 0.9949 - val_loss: 0.0269 - val_accuracy: 0.9944\n",
            "Epoch 1431/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0171 - accuracy: 0.9948 - val_loss: 0.0269 - val_accuracy: 0.9960\n",
            "Epoch 1432/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0170 - accuracy: 0.9953 - val_loss: 0.0276 - val_accuracy: 0.9940\n",
            "Epoch 1433/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.0283 - val_accuracy: 0.9936\n",
            "Epoch 1434/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 0.0268 - val_accuracy: 0.9940\n",
            "Epoch 1435/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0173 - accuracy: 0.9949 - val_loss: 0.0270 - val_accuracy: 0.9944\n",
            "Epoch 1436/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 0.0267 - val_accuracy: 0.9940\n",
            "Epoch 1437/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0166 - accuracy: 0.9953 - val_loss: 0.0267 - val_accuracy: 0.9936\n",
            "Epoch 1438/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 0.0288 - val_accuracy: 0.9940\n",
            "Epoch 1439/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0169 - accuracy: 0.9953 - val_loss: 0.0305 - val_accuracy: 0.9940\n",
            "Epoch 1440/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0171 - accuracy: 0.9948 - val_loss: 0.0286 - val_accuracy: 0.9916\n",
            "Epoch 1441/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0167 - accuracy: 0.9953 - val_loss: 0.0271 - val_accuracy: 0.9944\n",
            "Epoch 1442/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0169 - accuracy: 0.9947 - val_loss: 0.0265 - val_accuracy: 0.9944\n",
            "Epoch 1443/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0167 - accuracy: 0.9955 - val_loss: 0.0268 - val_accuracy: 0.9940\n",
            "Epoch 1444/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0171 - accuracy: 0.9947 - val_loss: 0.0285 - val_accuracy: 0.9940\n",
            "Epoch 1445/1500\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 0.0172 - accuracy: 0.9945 - val_loss: 0.0330 - val_accuracy: 0.9916\n",
            "Epoch 1446/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0173 - accuracy: 0.9947 - val_loss: 0.0263 - val_accuracy: 0.9940\n",
            "Epoch 1447/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0169 - accuracy: 0.9959 - val_loss: 0.0270 - val_accuracy: 0.9956\n",
            "Epoch 1448/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0171 - accuracy: 0.9948 - val_loss: 0.0269 - val_accuracy: 0.9940\n",
            "Epoch 1449/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0167 - accuracy: 0.9955 - val_loss: 0.0265 - val_accuracy: 0.9952\n",
            "Epoch 1450/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0169 - accuracy: 0.9955 - val_loss: 0.0262 - val_accuracy: 0.9948\n",
            "Epoch 1451/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0166 - accuracy: 0.9951 - val_loss: 0.0265 - val_accuracy: 0.9944\n",
            "Epoch 1452/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.0275 - val_accuracy: 0.9944\n",
            "Epoch 1453/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.0258 - val_accuracy: 0.9952\n",
            "Epoch 1454/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0162 - accuracy: 0.9955 - val_loss: 0.0263 - val_accuracy: 0.9944\n",
            "Epoch 1455/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 0.0281 - val_accuracy: 0.9948\n",
            "Epoch 1456/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0167 - accuracy: 0.9949 - val_loss: 0.0269 - val_accuracy: 0.9940\n",
            "Epoch 1457/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0166 - accuracy: 0.9952 - val_loss: 0.0294 - val_accuracy: 0.9944\n",
            "Epoch 1458/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0166 - accuracy: 0.9951 - val_loss: 0.0265 - val_accuracy: 0.9948\n",
            "Epoch 1459/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0170 - accuracy: 0.9945 - val_loss: 0.0266 - val_accuracy: 0.9952\n",
            "Epoch 1460/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0168 - accuracy: 0.9951 - val_loss: 0.0265 - val_accuracy: 0.9948\n",
            "Epoch 1461/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0166 - accuracy: 0.9953 - val_loss: 0.0260 - val_accuracy: 0.9952\n",
            "Epoch 1462/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 0.0297 - val_accuracy: 0.9928\n",
            "Epoch 1463/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0164 - accuracy: 0.9955 - val_loss: 0.0275 - val_accuracy: 0.9940\n",
            "Epoch 1464/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0170 - accuracy: 0.9944 - val_loss: 0.0266 - val_accuracy: 0.9948\n",
            "Epoch 1465/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0162 - accuracy: 0.9955 - val_loss: 0.0273 - val_accuracy: 0.9944\n",
            "Epoch 1466/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0162 - accuracy: 0.9949 - val_loss: 0.0281 - val_accuracy: 0.9940\n",
            "Epoch 1467/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0169 - accuracy: 0.9944 - val_loss: 0.0608 - val_accuracy: 0.9792\n",
            "Epoch 1468/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 0.0269 - val_accuracy: 0.9944\n",
            "Epoch 1469/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0165 - accuracy: 0.9951 - val_loss: 0.0274 - val_accuracy: 0.9948\n",
            "Epoch 1470/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0177 - accuracy: 0.9939 - val_loss: 0.0259 - val_accuracy: 0.9948\n",
            "Epoch 1471/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0172 - accuracy: 0.9947 - val_loss: 0.0275 - val_accuracy: 0.9944\n",
            "Epoch 1472/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 0.0315 - val_accuracy: 0.9932\n",
            "Epoch 1473/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0162 - accuracy: 0.9956 - val_loss: 0.0283 - val_accuracy: 0.9940\n",
            "Epoch 1474/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0166 - accuracy: 0.9952 - val_loss: 0.0300 - val_accuracy: 0.9944\n",
            "Epoch 1475/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0167 - accuracy: 0.9956 - val_loss: 0.0273 - val_accuracy: 0.9944\n",
            "Epoch 1476/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0162 - accuracy: 0.9955 - val_loss: 0.0264 - val_accuracy: 0.9940\n",
            "Epoch 1477/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0167 - accuracy: 0.9951 - val_loss: 0.0270 - val_accuracy: 0.9944\n",
            "Epoch 1478/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.0263 - val_accuracy: 0.9956\n",
            "Epoch 1479/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0164 - accuracy: 0.9955 - val_loss: 0.0258 - val_accuracy: 0.9948\n",
            "Epoch 1480/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0163 - accuracy: 0.9957 - val_loss: 0.0273 - val_accuracy: 0.9952\n",
            "Epoch 1481/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0161 - accuracy: 0.9953 - val_loss: 0.0318 - val_accuracy: 0.9932\n",
            "Epoch 1482/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0162 - accuracy: 0.9953 - val_loss: 0.0308 - val_accuracy: 0.9920\n",
            "Epoch 1483/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0165 - accuracy: 0.9948 - val_loss: 0.0266 - val_accuracy: 0.9948\n",
            "Epoch 1484/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0163 - accuracy: 0.9952 - val_loss: 0.0272 - val_accuracy: 0.9944\n",
            "Epoch 1485/1500\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0160 - accuracy: 0.9953 - val_loss: 0.0267 - val_accuracy: 0.9948\n",
            "Epoch 1486/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.0261 - val_accuracy: 0.9948\n",
            "Epoch 1487/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0162 - accuracy: 0.9953 - val_loss: 0.0264 - val_accuracy: 0.9948\n",
            "Epoch 1488/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0163 - accuracy: 0.9953 - val_loss: 0.0338 - val_accuracy: 0.9924\n",
            "Epoch 1489/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0166 - accuracy: 0.9952 - val_loss: 0.0279 - val_accuracy: 0.9948\n",
            "Epoch 1490/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0165 - accuracy: 0.9956 - val_loss: 0.0274 - val_accuracy: 0.9944\n",
            "Epoch 1491/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0164 - accuracy: 0.9952 - val_loss: 0.0267 - val_accuracy: 0.9940\n",
            "Epoch 1492/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0161 - accuracy: 0.9953 - val_loss: 0.0293 - val_accuracy: 0.9936\n",
            "Epoch 1493/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0169 - accuracy: 0.9948 - val_loss: 0.0267 - val_accuracy: 0.9944\n",
            "Epoch 1494/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0157 - accuracy: 0.9956 - val_loss: 0.0261 - val_accuracy: 0.9944\n",
            "Epoch 1495/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0162 - accuracy: 0.9951 - val_loss: 0.0274 - val_accuracy: 0.9948\n",
            "Epoch 1496/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0161 - accuracy: 0.9953 - val_loss: 0.0272 - val_accuracy: 0.9944\n",
            "Epoch 1497/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0161 - accuracy: 0.9952 - val_loss: 0.0274 - val_accuracy: 0.9940\n",
            "Epoch 1498/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0161 - accuracy: 0.9948 - val_loss: 0.0269 - val_accuracy: 0.9936\n",
            "Epoch 1499/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0161 - accuracy: 0.9951 - val_loss: 0.0291 - val_accuracy: 0.9940\n",
            "Epoch 1500/1500\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0162 - accuracy: 0.9955 - val_loss: 0.0320 - val_accuracy: 0.9932\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "y_pred_class_nn_1 = (model_sup.predict(X_test_norm) > 0.5).astype(\"int32\")\n",
        "y_pred_prob_nn_1 = model_sup.predict(X_test_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jEBczvpSFsIC",
        "outputId": "28a73b08-b6cf-40d1-d2b7-753963f1116f"
      },
      "id": "jEBczvpSFsIC",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 0s 1ms/step\n",
            "79/79 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "xIyVv5_jF5pK",
        "outputId": "270f0958-db36-48ee-da4c-620d81feadd0"
      },
      "id": "xIyVv5_jF5pK",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.993\n",
            "roc-auc is 0.998\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqQAAAKTCAYAAADPORq8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABOkUlEQVR4nO3de5iN9f7/8dfMmIPBNMpZJB1Q2grxU7td+Tm0t5Rf2cYhJMewqSlCZRwjcqiMYyaJOci2pcwX08iWTZRDW0VyijDD5DCaMTNrZt2/P/Y2X4fBrDmsz1r3ej6uy3WZ21qzXsvHmNe8P/e9lp9lWZYAAAAAQ/xNBwAAAIBvo5ACAADAKAopAAAAjKKQAgAAwCgKKQAAAIyikAIAAMAoCikAAACMKmM6QGE4nU4dP35cFSpUkJ+fn+k4AAAAuIJlWTp//rxq1Kghf3/XZp5eUUiPHz+uWrVqmY4BAACAGzh69KhuvfVWl+7jFYW0QoUKkv7zBMPCwvKPOxwOrVu3Tm3atFFgYKCpeChFrLFvYJ19A+tsf6yxb7jWOqenp6tWrVr5vc0VXlFIL27Th4WFXVVIQ0NDFRYWxj98m2KNfQPr7BtYZ/tjjX3Djda5KKdXunxR08aNG9W+fXvVqFFDfn5+Wrly5Q3vs2HDBjVu3FjBwcG68847tWjRIpeDAgAAwJ5cnpBmZGSoUaNGeuGFF/TMM8/c8PaHDh1Su3btNGDAAC1dulTJycnq06ePqlevrrZt2xYpNAAA3s6yLGVmZpqOUaIcDoeysrKUkZHBhNTGLq6zZVkl9jldLqR//vOf9ec//7nQt587d65uv/12TZs2TZLUoEEDbdq0STNmzLhmIc3OzlZ2dnb+x+np6ZL+8xfgcDjyj1/8/aXHYC+ssW/wpnW2Y4lwl4vfxM6ePevzZcWyLD3++OP67rvvTEcBiuzkyZMKDw/P/7g4/4eX+jmkW7ZsUatWrS471rZtW7300kvXvM+kSZM0duzYq46vW7dOoaGhVx1PSkoqdk5TLMu6rHyjYJ999pnpCHADT19ny7I0atQoHTp0yHQUADBu/fr1CgkJyf+4OD+sl3ohTUlJUdWqVS87VrVqVaWnp+vChQsqW7bsVfcZOXKkIiMj8z++eNVWmzZtrrqoKSkpSa1bt77uT9ueOtHgJ2QA8G2NGjXSl19+aZvX2HY4HFq/fr1atmzp81NwO9q/f78iIyMVHR2tH3/8UU8++aSCgoLy//zijnZReORV9sHBwQoODr7qeGBgYIH/wAMDA1WmTJkCS6dlWXrkkUe0a9eu0ogKwAfdf//9+uqrr2xTItzF4XBo7dq1atu2LWXlv0JDQ23178jhcCgkJETh4eGssc1YlqXjx48rISFBlSpV0sGDBxUUFHTZOhdnzUu9kFarVk2pqamXHUtNTVVYWFiB09GicDqdaty4sdeWTr65XRvfwHyDt62z3UqEu1wsK+XKlfOKdQbwH3v37tW4ceMUGxsrqXTO9y/1QtqiRQslJiZediwpKUktWrQokc9vWZaaN29+w21vTy59fHO7Nr6B+QbWGQA804kTJzRo0CAtXbq0VB/H5UL6+++/a//+/fkfHzp0SLt27dLNN9+s2rVra+TIkTp27JgWL14sSRowYIBmzZql4cOH64UXXtD69eu1bNkyrV69ukSeQHZ2dn4Zveuuu7Rjx44Cyx2lDwAAoPB++uknVa5cWStWrNBNN91Uqo/l8gvjf/vtt3rggQf0wAMPSJIiIyP1wAMPaPTo0ZL+06SPHDmSf/vbb79dq1evVlJSkho1aqRp06bpgw8+KLHXIL30NbB27Nih8uXLq1y5clf9oowCAAAUzg8//KBBgwYpNze31MuoVIQJ6WOPPXbdF0It6F2YHnvsMe3cudPVh7ohp9OpV155Jf9jSicAAEDxLVu2TLGxsapSpYpbHs8jr7IvjIvnjh4/flzSf84RLeg1SgEAAFA4u3fvVlJSUoGvB1+avLaQZmZm5p87euedd2r79u1MSAEAAIpo9+7dioyMVFxcnNsf2+VzSD3Rtm3b5O9vi6cCAADgdmlpaQoPD1dcXJwqVark9se3RYtjMgoAAFA0u3btUpcuXVSlShUjZVSySSEFAACA63JycjR+/HglJCQU+C6Z7uK155ACAACg6Hbs2KGMjAwtX77c+G4zE1IAAAAfs337do0YMUINGzY0XkYlJqQAAAA+xel06tdff9WyZcsUHh5uOo4kJqQAAAA+45tvvlHv3r319NNPe0wZlZiQAgAA+ISDBw/qzTffVEJCgukoV2FCCgAAYHM7d+7UzTffrL///e9ueW96V1FIAQAAbGzLli0aNWqU/P39Va5cOdNxCkQhBQAAsLE1a9YoISFBYWFhpqNcE+eQAgAA2NDmzZu1Y8cOjR071nSUG6KQAgAA2MyWLVs0ceJExcfHm45SKBRSAAAAG0lJSVGNGjWUkJCg8uXLm45TKJxDCgAAYBMbN25U3759VbNmTa8poxKFFAAAwBYyMjIUHR2t+Ph4lSnjXZvg3pUWAAAAV9mwYYNCQ0M98kXvC4MJKQAAgBf78ssvNX36dDVs2NB0lCKjkAIAAHip3NxcnT9/XvHx8QoNDTUdp8jYsgcAAPBCX3zxhVasWKHZs2ebjlJsFFIAAAAv8/3332vWrFmKi4szHaVEsGUPAADgRTZv3qzatWsrPj5eZcuWNR2nRFBIAQAAvMTatWv1zjvvKCgoSCEhIabjlBgKKQAAgBewLEtbtmxRbGysrcqoxDmkAAAAHi8xMVHHjx/XmDFjTEcpFRRSAAAAD7Z27Vp9+OGHWrJkiekopYYtewAAAA919OhRNWjQQEuWLFFwcLDpOKWGQgoAAOCBVq1apWHDhqlWrVq2LqMShRQAAMDjnD59WitWrNDixYvl5+dnOk6p4xxSAAAAD7Jy5UrdfvvtWrRokekobsOEFAAAwEOsWLFCCQkJuueee0xHcSsKKQAAgAfIyclRUFCQFi9erMDAQNNx3IotewAAAMOWL1+urVu3aurUqaajGEEhBQAAMOjrr7/WypUrfeqc0SuxZQ8AAGDIF198oXvvvVeLFi1SmTK+OyekkAIAABgQFxenxYsXq2zZsj5dRiUKKQAAgNvl5eXp0KFDiomJ8fkyKnEOKQAAgFstXbpUfn5+GjVqlOkoHoMJKQAAgJskJCQoOTlZERERpqN4FCakAAAAbnDw4EE9/PDD6tixowICAkzH8ShMSAEAAErZokWLNHnyZN16662U0QJQSAEAAErRiRMn9M0332ju3Lmmo3gsCikAAEAp+eijj3T+/HlFR0fL35/adS38zQAAAJSCDz74QFu2bNGdd95pOorH46ImAACAEpaVlaVbb71VL7zwApPRQqCQAgAAlKB58+YpNTVVo0ePNh3Fa1BIAQAASkhSUpJ2796t999/33QUr0IhBQAAKAGffvqpWrdurVatWsnPz890HK/CSQ0AAADFFB0drfXr16ts2bKU0SKgkAIAABRDTk6OsrKyNHPmTMpoEbFlDwAAUETvvvuu6tSpo1deecV0FK/GhBQAAKAI5s2bpyNHjuipp54yHcXrMSEFAABw0d69e9W+fXtVr16dbfoSwIQUAADABdOmTdOiRYtUo0YNymgJoZACAAAU0oEDB3T69GlNmjTJdBRboZACAAAUwsyZMxUUFKSJEycyGS1hnEMKAABwA5MnT9b58+d16623mo5iSxRSAACA68jIyFDz5s312GOPMRktJRRSAACAa5gwYYLCwsI0ZMgQ01FsjXNIAQAACrB8+XI5HA797W9/Mx3F9piQAgAAXCEuLk7PPvusOnbsaDqKT6CQAgAAXGLMmDHy9/dXUFCQ6Sg+g0IKAAAgybIsZWZmqnr16urfv7/pOD6Fc0gBAIDPsyxLo0eP1rZt2yijBlBIAQCAz5s8ebJCQ0P1+OOPm47ik9iyBwAAPsuyLO3evVt9+vRR5cqVTcfxWUxIAQCAT7IsSyNHjtTatWspo4YxIQUAAD5p9+7dqly5sl555RXTUXweE1IAAOBTLMvS2LFjVb16dcqoh6CQAgAAn2FZloYNG6awsDC26T0IW/YAAMAnWJal8+fP65lnntFDDz1kOg4uwYQUAADYnmVZioyM1KeffkoZ9UAUUgAAYHsffvih6tatq+7du5uOggKwZQ8AAGzLsizFxMTo+eefV0BAgOk4uAYmpAAAwJYsy9KQIUOUk5NDGfVwTEgBAIDtWJalc+fOqUWLFuratavpOLgBJqQAAMBWnE6nBg0apP3791NGvQSFFAAA2MqIESP0wAMPqGnTpqajoJDYsgcAALbgdDq1Y8cOjRgxQjfffLPpOHABE1IAAOD1nE6nBgwYoN27d1NGvRCFFAAAeL2tW7eqRYsW6tWrl+koKAIKKQAA8Fp5eXl69dVXde+991JGvRiFFAAAeCWn06l+/fqpUaNGCgsLMx0HxcBFTQAAwOvk5eXp/PnzGjhwoJo0aWI6DoqJCSkAAPAqeXl56t27t7766ivKqE1QSAEAgFeZNWuW2rRpo/bt25uOghLClj0AAPAKubm5WrBggYYMGSI/Pz/TcVCCmJACAACPl5ubq169eunmm2+mjNoQE1IAAODRnE6nzpw5o06dOrFNb1NMSAEAgMdyOBzq3r27fvvtN8qojVFIAQCAx/rb3/6mZ555RvXr1zcdBaWILXsAAOBxHA6HduzYoSlTpvCi9z6ACSkAAPAoOTk5eu6553TixAnKqI9gQgoAADzKV199pa5du+rpp582HQVuQiEFAAAeIScnRy+//LKmTZumkJAQ03HgRmzZAwAA4xwOh5577jn9+c9/poz6ICakAADAqOzsbGVmZmr06NFq2LCh6TgwgAkpAAAwJisrS127dtV3331HGfVhFFIAAGDMjBkz1KdPHz322GOmo8AgtuwBAIDbZWVlaeHChRoxYgTvTQ8mpAAAwL2ysrLUpUsX3XXXXZRRSGJCCgAA3CgvL0+nT5/WkCFD9Pjjj5uOAw/BhBQAALhFZmamnnnmGeXm5lJGcRkKKQAAcIt+/fpp6NChql27tuko8DBs2QMAgFKVmZmpXbt2ad68eSpXrpzpOPBATEgBAECpycjIUEREhBwOB2UU10QhBQAApebLL7/Uq6++qkcffdR0FHiwIhXS6Oho1alTRyEhIWrevLm2bdt23dvPnDlT9erVU9myZVWrVi29/PLLysrKKlJgAADg+X7//Xf17dtXTzzxBGUUN+RyIU1ISFBkZKSioqK0Y8cONWrUSG3bttXJkycLvH1sbKxGjBihqKgo7dmzRwsXLlRCQoJGjRpV7PAAAMDzXLhwQZ07d1bPnj1VpgyXq+DGXC6k06dPV9++fdWrVy/dc889mjt3rkJDQxUTE1Pg7Tdv3qyHH35YXbt2VZ06ddSmTRt16dLlhlNVAADgfS5cuKDs7GxNnz5df/zjH03HgZdw6ceWnJwcbd++XSNHjsw/5u/vr1atWmnLli0F3uehhx7SkiVLtG3bNjVr1kwHDx5UYmKiunfvfs3Hyc7OVnZ2dv7H6enpkiSHwyGHw5H/+4suPQ57KWi9YT+ss29gne3v9OnTmjp1qmrVqqVmzZqx1jZ1ra/l4qy3S4U0LS1NeXl5qlq16mXHq1atqr179xZ4n65duyotLU1//OMfZVmWcnNzNWDAgOtu2U+aNEljx4696vi6desUGhoqSZedg7p+/XqFhIS48lTgZZKSkkxHgBuwzr6BdbavuLg4derUSWlpaUpMTDQdB6Xsyq/lzMzMIn+uUj+xY8OGDXrrrbc0e/ZsNW/eXPv379fQoUM1fvx4vfnmmwXeZ+TIkYqMjMz/OD09XbVq1VKbNm0UFhYm6T8vI3FRy5YtFR4eXqrPA2Y4HA4lJSWpdevWCgwMNB0HpYR19g2ss32dO3dOS5YsUUxMDGvsA671tXxxR7soXCqklSpVUkBAgFJTUy87npqaqmrVqhV4nzfffFPdu3dXnz59JEn33XefMjIy1K9fP73++uvy97/6NNbg4GAFBwdfdTwwMDD/iV/6F3DpcdgTa+wbWGffwDrby7lz5/Tcc89p3Lhxl32PZo3t78p1Ls6au3RRU1BQkJo0aaLk5OT8Y06nU8nJyWrRokWB98nMzLyqdAYEBEiSLMtyNS8AAPAQDodDZ8+e1YQJE9SsWTPTceDFXL7KPjIyUgsWLNBHH32kPXv26MUXX1RGRoZ69eolSerRo8dlFz21b99ec+bMUXx8vA4dOqSkpCS9+eabat++fX4xBQAA3uXs2bN68sknFRoaqqZNm5qOAy/n8jmkEREROnXqlEaPHq2UlBTdf//9WrNmTf6FTkeOHLlsIvrGG2/Iz89Pb7zxho4dO6bKlSurffv2mjhxYsk9CwAA4DaWZemFF17QxIkTVblyZdNxYANFuqhp8ODBGjx4cIF/tmHDhssfoEwZRUVFKSoqqigPBQAAPMiZM2e0Z88excbG8go3KDG8lz0AACiU06dPKyIiQiEhIZRRlCjezwsAABTKhg0b9Pbbb+uBBx4wHQU2QyEFAADX9dtvv2nYsGFauHCh/Pz8TMeBDbFlDwAAruncuXPq3LmzXnrpJcooSg0TUgAAUKC0tDQFBgbqgw8+0G233WY6DmyMCSkAALjKqVOn1LlzZ504cYIyilJHIQUAAFeZMWOGZs6cqfr165uOAh/Alj0AAMh38uRJLVu2TG+99ZbpKPAhTEgBAIAkKTU1VV26dFHLli1NR4GPYUIKAACUnZ2t33//XbNmzVKDBg1Mx4GPYUIKAICPO3HihNq1a6fKlStTRmEEhRQAAB/mdDrVt29fRUdHKywszHQc+Ci27AEA8FHHjx/XL7/8ohUrVigoKMh0HPgwJqQAAPigY8eO6bnnnlOlSpUoozCOQgoAgA/atGmT5s2bp7vuust0FIBCCgCAL/n111/Vu3dvderUiTIKj8E5pAAA+IiTJ0+qR48eWrBggfz8/EzHAfJRSAEA8AG//vqrwsLCtHTpUlWvXt10HOAybNkDAGBzv/zyi3r06KGzZ89SRuGRKKQAANjcrFmzFBMTo9q1a5uOAhSILXsAAGzq8OHDSkxM1NSpU01HAa6LCSkAADZ06NAhvfDCC3ryySdNRwFuiEIKAIDNZGZmKicnR4sWLWKbHl6BQgoAgI0cOHBATz31lG677TbKKLwGhRQAAJtwOBz629/+pkWLFikkJMR0HKDQuKgJAAAb+Pnnn3XmzBmtWrVKZcrw7R3ehQkpAABe7ueff1b//v1Vs2ZNyii8Ev9qAQDwYpZl6ZtvvtGSJUtUo0YN03GAIqGQAgDgpX766SdNmzZN8+fPNx0FKBYKKQAAXujIkSMaOHCgli5dajoKUGycQwoAgJc5cOCAKlasqGXLlqlatWqm4wDFRiEFAMCL/Pjjj+rXr5+ysrJ0yy23mI4DlAgKKQAAXmThwoWKi4tT5cqVTUcBSgznkAIA4AW+//57bdmyRdOmTTMdBShxTEgBAPBwu3fv1ksvvaQOHTqYjgKUCiakAAB4sPPnz6tMmTKKj49XpUqVTMcBSgUTUgAAPNR3332njh076q677qKMwtYopAAAeKDMzEyNGjVKsbGxvB0obI9/4QAAeJidO3dKkj777DP5+zM7gv3xrxwAAA+yY8cOvfbaa7rtttsoo/AZTEgBAPAQlmXpxx9/VEJCgipWrGg6DuA2FFIAADzAt99+qw8//FDR0dGmowBuRyEFAMCwvXv36vXXX1dCQoLpKIARnJwCAIBBP/zwg2rWrKlPPvlE4eHhpuMARlBIAQAwZOvWrXr11VdlWZbCwsJMxwGMoZACAGCAZVlKSEhQQkICZRQ+j3NIAQBwsy1btuinn37S9OnTTUcBPAITUgAA3Gjz5s0aP368nn32WdNRAI9BIQUAwE3OnDmj8PBwJSQkqEKFCqbjAB6DQgoAgBt89dVXev7551W/fn3KKHAFCikAAKXs7Nmzmj59upYuXcrbgQIF4KImAABK0T//+U9VqlRJK1askJ+fn+k4gEfixzQAAErJhg0b9M4776hOnTqUUeA6mJACAFAKnE6njh07poSEBIWGhpqOA3g0CikAACUsOTlZiYmJmjZtmukogFegkAIAUIK2b9+u9957T/Hx8aajAF6Dc0gBACgh3377rerVq6f4+HiVLVvWdBzAa1BIAQAoAWvXrtXEiRNVpkwZyijgIgopAADF5HQ69cUXXyguLk4hISGm4wBeh3NIAQAohjVr1ujs2bOaOnWq6SiA12JCCgBAEf3P//yPPvjgA/2///f/TEcBvBqFFACAIjh16pTq1KmjpUuXKjg42HQcwKtRSAEAcNFnn32moUOHqn79+pRRoARQSAEAcEFKSori4uK0aNEi3g4UKCEUUgAACunzzz/X77//rqVLlyooKMh0HMA2KKQAABTCP/7xDy1ZskS33XYbk1GghFFIAQC4gby8PGVlZenjjz9WYGCg6TiA7fA6pAAAXMff//537dq1S+PHjzcdBbAtCikAANfwz3/+UytWrNCiRYtMRwFsjUIKAEABNm3apCZNmuijjz5SmTJ8uwRKE+eQAgBwhYSEBM2fP18hISGUUcANKKQAAFzC4XDo3//+t2JiYiijgJvwlQYAwH/FxsaqfPnymjhxoukogE9hQgoAgKS4uDglJSWpXbt2pqMAPocJKQDA5x0/flyNGzdWp06dFBAQYDoO4HMopAAAn7Z48WJt3rxZc+fONR0F8FkUUgCAzzp06JD+9a9/afbs2aajAD6Nc0gBAD5p6dKlKlOmjObNm8c2PWAYhRQA4HNiYmL01VdfqWbNmqajABCFFADgY3JzcxUWFqbZs2fL359vg4An4BxSAIDPmD9/vs6ePavhw4ebjgLgEhRSAIBP+Oyzz/Tdd9/p/fffNx0FwBUopAAA20tKSlLLli3Vrl07tukBD8RXJQDA1mbPnq1Vq1YpNDSUMgp4KL4yAQC2lZmZqTNnzui9996Tn5+f6TgAroEtewCALc2aNUsNGjTQ66+/bjoKgBtgQgoAsJ3Zs2fr4MGDatmypekoAAqBCSkAwFaOHDmitm3b6sUXX2SbHvASTEgBALYxY8YMzZ07V3fccQdlFPAiTEgBALbw/fffKzU1VZMmTTIdBYCLmJACALzenDlzVKVKFU2ePJnJKOCFmJACALzalClTdObMGVWuXNl0FABFRCEFAHit7Oxs1a9fX+3bt2cyCngxCikAwCu99dZbuuWWW9S/f3/TUQAUE+eQAgC8zscff6ysrCz169fPdBQAJYAJKQDAq6xatUp//etfFRwczDY9YBNMSAEAXmPcuHHauXOnQkJCKKOAjTAhBQB4hbNnz+qmm27S0KFDTUcBUMKYkAIAPJplWRozZoz27dtHGQVsikIKAPBoEydOVGBgoJo1a2Y6CoBSwpY9AMAjWZalAwcOqEePHqpdu7bpOABKERNSAIDHsSxLr7/+uj799FPKKOADKKQAAI+zdetWhYeH65VXXjEdBYAbUEgBAB7DsixNnjxZDRo00PDhw03HAeAmFFIAgEewLEuvvfaagoKCdNNNN5mOA8CNuKgJAGCcZVm6cOGCWrVqpTZt2piOA8DNKKQAAKMsy9Irr7yi5s2bKyIiwnQcAAawZQ8AMCo6Olp16tShjAI+jAkpAMAIy7L0ySefaMCAASpThm9HgC9jQgoAcDvLsjR06FCdOnWKMgqgaIX04vZKSEiImjdvrm3btl339mfPntWgQYNUvXp1BQcH6+6771ZiYmKRAgMAvN/Jkyf1wAMPaNCgQaajAPAALhfShIQERUZGKioqSjt27FCjRo3Utm1bnTx5ssDb5+TkqHXr1jp8+LCWL1+un376SQsWLFDNmjWLHR4A4F2cTqdeeukl/fbbb+rVq5fpOAA8hMv7JNOnT1ffvn3z/yOZO3euVq9erZiYGI0YMeKq28fExOj06dPavHmzAgMDJUl16tQpXmoAgFdatGiRnnjiCd1zzz2mowDwIC4V0pycHG3fvl0jR47MP+bv769WrVppy5YtBd5n1apVatGihQYNGqRPP/1UlStXVteuXfXaa68pICCgwPtkZ2crOzs7/+P09HRJksPhkMPhyP/9RZceh70UtN6wH9bZ/pxOp3788Ud16NBBERERrLVN8bXsG661zsVZd5cKaVpamvLy8lS1atXLjletWlV79+4t8D4HDx7U+vXr1a1bNyUmJmr//v0aOHCgHA6HoqKiCrzPpEmTNHbs2KuOr1u3TqGhoZKkrKys/OPr169XSEiIK08FXiYpKcl0BLgB62xPTqdT8+bN0913363/+3//L+vsA1hj33DlOmdmZhb5c/lZlmUV9sbHjx9XzZo1tXnzZrVo0SL/+PDhw/XPf/5TW7duveo+d999t7KysnTo0KH8iej06dM1depUnThxosDHKWhCWqtWLaWlpSksLEySlJGRoYoVK0r6z8nx4eHhhX0a8CIOh0NJSUlq3bp1/ikfsB/W2d6Sk5N19OhRdevWjXW2Ob6WfcO11jk9PV2VKlXSuXPn8vtaYbk0Ia1UqZICAgKUmpp62fHU1FRVq1atwPtUr15dgYGBl23PN2jQQCkpKcrJyVFQUNBV9wkODlZwcPBVxwMDA/Of+KV/AZcehz2xxr6BdbYXp9OpqKgojRo1SmXLls3fzmOd7Y819g1XrnNx1tylq+yDgoLUpEkTJScn5x9zOp1KTk6+bGJ6qYcfflj79++X0+nMP7Zv3z5Vr169wDIKAPB+eXl56tevn+68806VLVvWdBwAHs7ll32KjIzUggUL9NFHH2nPnj168cUXlZGRkX/VfY8ePS676OnFF1/U6dOnNXToUO3bt0+rV6/WW2+9xWvPAYBN5eXl6cKFC+rZs6d69uxpOg4AL+Dyyz5FRETo1KlTGj16tFJSUnT//fdrzZo1+Rc6HTlyRP7+/9tza9WqpbVr1+rll1/WH/7wB9WsWVNDhw7Va6+9VnLPAgDgEfLy8tSnTx9FREToiSeeMB0HgJco0vu1DR48WIMHDy7wzzZs2HDVsRYtWujrr78uykMBALzIlClT1KpVK8ooAJfwBsIAgGLLzc1VQkKChg8ffs3XmAaAaynSe9kDAHBRbm6uXnjhBQUEBFBGARQJE1IAQJFZlqUTJ07o6aef1rPPPms6DgAvxYQUAFAkubm56tmzp5xOJ2UUQLFQSAEARdK/f3899dRTuu2220xHAeDl2LIHALjE4XBo3759mjx5sipXrmw6DgAbYEIKACg0h8OhHj166Oeff6aMAigxFFIAQKElJiYqIiJCHTp0MB0FgI2wZQ8AuKGcnByNGjVKkydPVpkyfOsAULKYkAIArisnJ0fPPfecHn30UcoogFLB/ywAgGvKzs5WTk6Ohg0bpgcffNB0HAA2xYQUAFCg7OxsdevWTf/+978powBKFYUUAFCg8ePH64UXXtDDDz9sOgoAm2PLHgBwmaysLCUkJGj8+PHy8/MzHQeAD2BCCgDIl5WVpS5duqhatWqUUQBuw4QUACBJsixLv/76qwYOHKjWrVubjgPAhzAhBQDowoUL6tixo8LCwiijANyOQgoAPs6yLPXs2VMDBw5UlSpVTMcB4IPYsgcAH5aZmakDBw5o/vz5Cg8PNx0HgI9iQgoAPiojI0MRERFKS0ujjAIwigkpAPiozz77TK+88ooee+wx01EA+DgKKQD4mIyMDL3++uuaPn26/P3ZKANgHv8TAYAPubhN/+yzz1JGAXgMJqQA4CN+//13SdKkSZN03333GU4DAP+LH48BwAecP39enTp10oEDByijADwOhRQAfMDYsWP1xhtvqFGjRqajAMBV2LIHABtLT0/XihUrNHXqVN6bHoDHYkIKADZ17tw5derUSfXr16eMAvBoTEgBwIacTqeOHTumsWPHqnnz5qbjAMB1MSEFAJs5e/as2rdvr5o1a1JGAXgFCikA2IjT6dRzzz2nMWPG6KabbjIdBwAKhS17ALCJM2fO6OjRo4qLi1OFChVMxwGAQmNCCgA2cObMGUVERCg3N5cyCsDrUEgBwAZWrVqlyZMnq3HjxqajAIDL2LIHAC92+vRpjRkzRu+++y4v7QTAazEhBQAvdebMGXXu3Fm9e/emjALwakxIAcALnT59WoGBgYqOjtZdd91lOg4AFAsTUgDwMmlpaerUqZNSUlIoowBsgUIKAF5m7NixmjFjBmUUgG2wZQ8AXuLkyZNKTEzUe++9xzmjAGyFCSkAeIGTJ0+qS5cuatasGWUUgO1QSAHAw+Xm5urEiRN6//33dc8995iOAwAljkIKAB4sJSVF7dq10913300ZBWBbFFIA8FAOh0M9e/bUu+++q7Jly5qOAwClhouaAMADnThxQr/99pv+8Y9/KDQ01HQcAChVTEgBwMMcP35c3bp1U1BQEGUUgE9gQgoAHiYxMVHz5s3jdUYB+AwKKQB4iGPHjmnKlCl69913TUcBALeikAKABzhx4oS6d++u+fPnm44CAG5HIQUAw1JSUlS+fHktWrRItWvXNh0HANyOi5oAwKAjR46oS5cuSk9Pp4wC8FkUUgAwaNKkSYqJiVHNmjVNRwEAY9iyBwADfvnlF23cuFFz5swxHQUAjGNCCgBudvjwYfXq1Ut/+tOfTEcBAI9AIQUAN8rJydFvv/2mDz/8ULfddpvpOADgESikAOAmBw8e1FNPPaU//OEPlFEAuATnkAKAG1y4cEH9+/dXTEyMAgMDTccBAI9CIQWAUrZ//345HA59/vnnCg4ONh0HADwOW/YAUIr279+v/v37KywsjDIKANdAIQWAUpScnKzFixfzOqMAcB1s2QNAKdi3b5/mzZunadOmmY4CAB6PQgoAJezgwYN68cUXtWTJEtNRAMArUEgBoAQdOXJElStXVmxsrKpWrWo6DgB4Bc4hBYASsmfPHvXq1Us5OTmUUQBwAYUUAEqAZVmaMWOGYmNjdcstt5iOAwBehS17ACimH374Qf/+9781f/5801EAwCsxIQWAYvj+++81dOhQtWrVynQUAPBaFFIAKKKsrCxlZmYqLi5OlStXNh0HALwWhRQAiuDf//63OnbsqKZNm1JGAaCYOIcUAFx07tw5DRs2TLGxsfL35+d6ACguCikAuGDXrl0qV66cPv/8cwUGBpqOAwC2wI/2AFBIO3fu1PDhw3XLLbdQRgGgBFFIAaCQtm7dqvj4eN18882mowCArbBlDwA3sH37dn3yySeaPHmy6SgAYEsUUgC4ju+//16jRo1SQkKC6SgAYFts2QPANfz888+qXbu2EhISFB4ebjoOANgWhRQACrBt2zYNHjxYfn5+lFEAKGUUUgC4gtPp1MKFC7Vs2TJVqFDBdBwAsD3OIQWAS3z99dc6duyY5s2bZzoKAPgMJqQA8F9btmzRuHHj1Lp1a9NRAMCnMCEFAEkZGRkKCAhQQkIC2/QA4GZMSAH4vE2bNqlnz5568MEHKaMAYAATUgA+7eTJk3r77bcVFxcnPz8/03EAwCcxIQXgszZt2qTMzEytXLlS5cuXNx0HAHwWhRSAT/rnP/+pt99+W5UrV1ZAQIDpOADg0yikAHyOZVnas2eP4uPjVa5cOdNxAMDncQ4pAJ/y5ZdfasOGDRo7dqzpKACA/6KQAvAZX3/9tWbOnKm4uDjTUQAAl2DLHoBP+P7779WgQQPFxcUpNDTUdBwAwCUopABsLykpSW+++aaCg4MpowDggSikAGwtNzdXK1euVFxcnEJCQkzHAQAUgHNIAdjW2rVr5XA4FB0dbToKAOA6mJACsKU1a9Zo/vz5atWqlekoAIAbYEIKwHbS09N1yy23KDY2VsHBwabjAABugAkpAFv5/PPP9be//U0PPvggZRQAvAQTUgC28csvv2jx4sX6+OOPTUcBALiACSkAW/if//kflSlTRvHx8UxGAcDLUEgBeL1PP/1UH330kSpXrix/f/5bAwBvw//cALyaZVlKTU3V4sWLFRQUZDoOAKAIOIcUgNdasWKF9u3bpxEjRpiOAgAoBgopAK+UlJSk5cuX66OPPjIdBQBQTBRSAF5n+/btatasmR577DEFBgaajgMAKCbOIQXgVZYtW6YZM2aoXLlylFEAsAkKKQCvceHCBX399ddatGiRypRhgwcA7IL/0QF4hfj4eFWpUkXTp083HQUAUMKYkALweHFxcVqzZo3+9Kc/mY4CACgFTEgBeLTTp0+rfv366tSpkwICAkzHAQCUAgopAI/18ccfa+vWrZo1a5bpKACAUkQhBeCRfvzxR23YsEHz5883HQUAUMo4hxSAx/nkk09UuXJlffDBB2zTA4APKFIhjY6OVp06dRQSEqLmzZtr27ZthbpffHy8/Pz81KFDh6I8LAAf8OGHHyopKUm33HKL/Pz8TMcBALiBy4U0ISFBkZGRioqK0o4dO9SoUSO1bdtWJ0+evO79Dh8+rFdffVWPPPJIkcMCsDen0ylJmjt3rvz92cABAF/h8v/406dPV9++fdWrVy/dc889mjt3rkJDQxUTE3PN++Tl5albt24aO3as6tatW6zAAOwpKSlJc+bMUa9evSijAOBjXLqoKScnR9u3b9fIkSPzj/n7+6tVq1basmXLNe83btw4ValSRb1799ZXX311w8fJzs5WdnZ2/sfp6emSJIfDIYfDkf/7iy49DnspaL1hP8uWLdOBAwc0efJk1trG+Hq2P9bYN1xrnYuz7i4V0rS0NOXl5alq1aqXHa9atar27t1b4H02bdqkhQsXateuXYV+nEmTJmns2LFXHV+3bp1CQ0MlSVlZWfnH169fr5CQkEJ/fnifpKQk0xFQSvbu3avatWurX79+Sk5ONh0HbsDXs/2xxr7hynXOzMws8ucq1Zd9On/+vLp3764FCxaoUqVKhb7fyJEjFRkZmf9xenq6atWqpTZt2igsLEySlJGRkf/nLVu2VHh4eInlhudwOBxKSkpS69atFRgYaDoOStj8+fP1yy+/aPDgwfriiy9YZ5vj69n+WGPfcK11vrijXRQuFdJKlSopICBAqamplx1PTU1VtWrVrrr9gQMHdPjwYbVv3z7/2MWLFsqUKaOffvpJd9xxx1X3Cw4OVnBw8FXHAwMD85/4pX8Blx6HPbHG9nPu3DmdOHFC0dHRys3NlcQ6+wrW2f5YY99w5ToXZ81dunIgKChITZo0uWxbzel0Kjk5WS1atLjq9vXr19fu3bu1a9eu/F9PPfWUHn/8ce3atUu1atUqcnAA3mv27Nnau3evJkyYwEs7AQBc37KPjIxUz5491bRpUzVr1kwzZ85URkaGevXqJUnq0aOHatasqUmTJikkJEQNGza87P4Xt9avPA7AN0RHR+vnn3/Wiy++aDoKAMBDuFxIIyIidOrUKY0ePVopKSm6//77tWbNmvwLnY4cOcJLtgAo0MmTJ/XII49o4MCBTEYBAPmKdFHT4MGDNXjw4AL/bMOGDde976JFi4rykAC83MyZM5WWlqYJEyaYjgIA8DClepU9AEjStm3b9Ouvv2rq1KmmowAAPBB76wBK1cKFC1WvXj1NnTqVbXoAQIGYkAIoNVOnTtVvv/2msLAwyigA4JoopABKRW5urmrUqKFXX32VMgoAuC4KKYASN3nyZFWvXl09e/Y0HQUA4AU4hxRAiVq4cKEyMjLUo0cP01EAAF6CCSmAErN+/Xp17txZoaGhbNMDAAqNQgqgRIwfP155eXlq2bKl6SgAAC9DIQVQbCdPnlRwcLCGDx9uOgoAwAtxDimAYhk3bpxOnjxJGQUAFBmFFECRjRs3Tv7+/mrYsKHpKAAAL8aWPQCXWZalEydOqFOnTqpfv77pOAAAL8eEFIBLLMvSm2++qfj4eMooAKBEUEgBuCQ5OVnly5dXZGSk6SgAAJtgyx5AoViWpXfffVf9+/dXq1atTMcBANgIE1IAN2RZlkaMGKHc3FyVLVvWdBwAgM0wIQVwXZZlKTs7Wy1atFCHDh1MxwEA2BCFFMA1WZalYcOG6Y9//CNlFABQatiyB3BN06dPV61atSijAIBSxYQUwFUsy9KaNWs0aNAghYSEmI4DALA5JqQALmNZll566SUdOHCAMgoAcAsmpAAuc+TIEd17773q16+f6SgAAB/BhBSApP9MRl9++WU5nU7KKADArSikACRJL7/8surVq6fbb7/ddBQAgI9hyx7wcU6nU7/++quGDBmiunXrmo4DAPBBTEgBH+Z0OjVo0CCtX7+eMgoAMIZCCviwVatWqUmTJnr++edNRwEA+DC27AEf5HQ6NWnSJA0fPlyBgYGm4wAAfBwTUsDHOJ1O9e/fXzVr1qSMAgA8AhNSwIfk5eUpKytLHTt2VNu2bU3HAQBAEhNSwGfk5eWpb9++2rZtG2UUAOBRKKSAjxg7dqxatmypxx9/3HQUAAAuw5Y9YHN5eXlavXq13njjDQUFBZmOAwDAVZiQAjaWm5urF154QRkZGZRRAIDHYkIK2NiBAwfUrl07derUyXQUAACuiQkpYEO5ubnq3bu3brrpJsooAMDjUUgBm7EsS71799YTTzyhatWqmY4DAMANsWUP2IjD4dCvv/6qCRMmqFatWqbjAABQKExIAZtwOBzq0aOHvvvuO8ooAMCrUEgBm1i2bJn++te/qkOHDqajAADgErbsAS+Xk5OjiRMnKioqSv7+/IwJAPA+fPcCvFhOTo66d++uxo0bU0YBAF6LCSngpXJycpSdna3BgwfrkUceMR0HAIAiY6QCeKHs7Gx169ZNe/fupYwCALwehRTwQqNGjdLzzz+vBx980HQUAACKjS17wItkZWUpMTFRb7/9tsqU4csXAGAPTEgBL5GVlaWuXbsqNDSUMgoAsBW+qwFeYt++ferfv7/atm1rOgoAACWKCSng4S5cuKDOnTurdu3alFEAgC1RSAEP5nQ61a1bN/Xu3Vvh4eGm4wAAUCrYsgc8VGZmplJSUjR79mxVq1bNdBwAAEoNE1LAA2VmZqpLly765ZdfKKMAANujkAIeKDY2VkOHDtXjjz9uOgoAAKWOLXvAg2RkZOitt97ShAkT5OfnZzoOAABuwYQU8BAZGRmKiIhQmzZtKKMAAJ/ChBTwAJmZmcrLy9OYMWPUtGlT03EAAHArJqSAYb///rv++te/6tixY5RRAIBPopAChg0bNkyjRo1SgwYNTEcBAMAItuwBQ86fP69169YpOjpa/v78bAgA8F18FwQMSE9PV6dOnVSjRg3KKADA5zEhBdzMsizt3btXUVFR+j//5/+YjgMAgHGMZgA3OnfunJ555hk1bNiQMgoAwH9RSAE3yc3NVefOnTVy5EiFhoaajgMAgMdgyx5wg7Nnz+r06dP6+OOPValSJdNxAADwKExIgVJ25swZderUSadPn6aMAgBQACakQCmLi4vTpEmT1KRJE9NRAADwSBRSoJScPn1a06ZN08SJE01HAQDAo7FlD5SC06dPq3PnzurYsaPpKAAAeDwmpEAJS09PV0BAgGbOnKl77rnHdBwAADweE1KgBKWlpemZZ57RmTNnKKMAABQShRQoQcOHD9f06dNVp04d01EAAPAabNkDJeDUqVPauHGjFi5cKD8/P9NxAADwKkxIgWI6efKkOnfurHr16lFGAQAoAiakQDFYlqV9+/bpvffe07333ms6DgAAXokJKVBEqampevrpp9W8eXPKKAAAxcCEFCiCrKwsdevWTe+//74CAwNNxwEAwKtRSAEXnThxQtnZ2Vq+fLnCw8NNxwEAwOuxZQ+44MSJE+rWrZuys7MpowAAlBAKKeCChIQEzZkzR/Xq1TMdBQAA22DLHiiEY8eOac6cOZowYYLpKAAA2A4TUuAGjh8/rh49euj55583HQUAAFtiQgpcx2+//aayZctqwYIFqlu3ruk4AADYEhNS4BqOHj2qv/71r8rJyaGMAgBQiiikQAEsy9KoUaP0wQcfqGrVqqbjAABga2zZA1f45ZdftGPHDi1evJj3pgcAwA2YkAKXOHz4sHr16qUHHniAMgoAgJtQSIH/ysvL0+HDhxUTE6M6deqYjgMAgM+gkAKSDh06pGeeeUZ/+tOfKKMAALgZ55DC56Wnp6t3795atGiR/P35GQ0AAHejkMKnHThwQEFBQVq1apXKly9vOg4AAD6JcRB81v79+9WvXz/5+/tTRgEAMIhCCp/16aefavHixapZs6bpKAAA+DS27OFzfv75Zy1ZskRjx441HQUAAIhCCh+zf/9+DRgwQB9//LHpKAAA4L8opPAZKSkpuvnmm7VkyRJVr17ddBwAAPBfnEMKn7B371517dpV/v7+lFEAADwMhRS2Z1mWxo8fr9jYWIWHh5uOAwAArsCWPWztxx9/1IEDB7R06VLTUQAAwDUwIYVt/fDDDxoyZIiaN29uOgoAALgOCilsKTc3V6mpqYqNjVWVKlVMxwEAANdBIYXt7N69W507d9bjjz9OGQUAwAtwDils5dSpU4qMjFRcXJz8/PxMxwEAAIXAhBS2sXv3bjkcDq1atUqVKlUyHQcAABQShRS2sGvXLr3yyisKDg5W2bJlTccBAAAuYMsetpCUlKT4+HjdfPPNpqMAAAAXUUjh1Xbs2KHExES98cYbpqMAAIAiopDCa3333XcaOXKk4uPjTUcBAADFwDmk8EpHjx5VjRo1FB8fr4oVK5qOAwAAioFCCq/zzTffqE+fPipXrhxlFAAAG6CQwqvk5ubq3Xff1bJlyxQaGmo6DgAAKAFFKqTR0dGqU6eOQkJC1Lx5c23btu2at12wYIEeeeQRVaxYURUrVlSrVq2ue3vgWrZu3ark5GQtWbJEN910k+k4AACghLhcSBMSEhQZGamoqCjt2LFDjRo1Utu2bXXy5MkCb79hwwZ16dJFX375pbZs2aJatWqpTZs2OnbsWLHDw3ds3bpVY8aMUYsWLUxHAQAAJczlq+ynT5+uvn37qlevXpKkuXPnavXq1YqJidGIESOuuv3SpUsv+/iDDz7Q3//+dyUnJ6tHjx4FPkZ2drays7PzP05PT5ckORwOORyO/N9fdOlx2MvFtT137pyWLFmismXLstY2VNDXNeyHdbY/1tg3XGudi7PuLhXSnJwcbd++XSNHjsw/5u/vr1atWmnLli2F+hyZmZlyOBzXfQHzSZMmaezYsVcdX7duXf55g1lZWfnH169fr5CQkMI+DXiRvXv3KjExUZGRkdq0aZPpOChlSUlJpiPADVhn+2ONfcOV65yZmVnkz+VSIU1LS1NeXp6qVq162fGqVatq7969hfocr732mmrUqKFWrVpd8zYjR45UZGRk/sfp6en5W/1hYWGSpIyMjPw/b9mypcLDw114JvAGR44c0Zw5c/Tiiy+qdevWCgwMNB0JpcThcCgpKYl1tjnW2f5YY99wrXW+uKNdFG59YfzJkycrPj5eGzZsuO5EMzg4WMHBwVcdDwwMzH/il/4FXHoc9vD111+rbt26Wr58uZKTk1ljH8E6+wbW2f5YY99w5ToXZ81duqipUqVKCggIUGpq6mXHU1NTVa1ateve95133tHkyZO1bt06/eEPf3A9KXzGxo0bNXHiRJUrV67AH0wAAIC9uFRIg4KC1KRJEyUnJ+cfczqdSk5Ovu7Vz1OmTNH48eO1Zs0aNW3atOhp4RO2bdum+Ph4lStXznQUAADgBi5v2UdGRqpnz55q2rSpmjVrppkzZyojIyP/qvsePXqoZs2amjRpkiTp7bff1ujRoxUbG6s6deooJSVFklS+fHmVL1++BJ8KvN2GDRv0zTffaNiwYaajAAAAN3K5kEZEROjUqVMaPXq0UlJSdP/992vNmjX5FzodOXJE/v7/O3idM2eOcnJy1LFjx8s+T1RUlMaMGVO89LCNTZs2afr06YqPjzcdBQAAuFmRLmoaPHiwBg8eXOCfbdiw4bKPDx8+XJSHgA85cOCA6tWrp/j4eN4OFAAAH8R72cOoL774QpGRkQoPD6eMAgDgoyikMCYrK0uxsbGKj4/n5UEAAPBhbn0dUuCidevWKTg4WDExMaajAAAAw5iQwu3Wrl2ruXPnqnnz5qajAAAAD0AhhVtlZWUpKChIsbGx1323LgAA4DvYsofbJCYmauXKlZo/f77pKAAAwINQSOEWe/fu1YcffqglS5aYjgIAADwMW/YodcnJyapcubLi4uJ4b3oAAHAVCilK1apVqzRv3jxVqFBBZcowkAcAAFejkKLUWJal/fv3a8mSJQoKCjIdBwAAeChGVigVK1eu1NGjRxUZGWk6CgAA8HAUUpS4xMREJSQkaPHixaajAAAAL0AhRYnas2ePHnzwQbVu3Zq3AwUAAIXCOaQoMcuXL9eECRN0yy23UEYBAEChUUhRItLT07V+/Xp99NFH8vfnnxUAACg8tuxRbAkJCbr99ts1e/Zs01EAAIAXYpSFYomPj9fq1avVuHFj01EAAICXopCiyH7//XfVqFFDMTExvOg9AAAoMloEimTJkiXasWOHpk+fbjoKAADwchRSuOzbb7/V+vXrtWDBAtNRAACADbBlD5d8+umnuuuuu7RgwQIFBASYjgMAAGyAQopCW7RokT7//HNVqFCBMgoAAEoMhRSF4nQ6lZ6ernnz5vE6owAAoERxDiluKCYmRpI0ZMgQw0kAAIAdMerCdcXFxWnbtm16/vnnTUcBAAA2xYQU1/Tdd9+pdevWioiIYJseAACUGloGCjRv3jzNnz9ft9xyC2UUAACUKpoGrnLq1CkdOHBAs2bNkp+fn+k4AADA5iikuMzcuXOVkpKiKVOmUEYBAIBbUEiRLzo6Wnv27FHDhg1NRwEAAD6Ei5ogSTp37pwaN26sgQMHMhkFAABuRSGF3n33XZ09e1ZRUVGmowAAAB9EIfVxX375pY4cOaJ33nnHdBQAAOCjKKQ+bOnSperQoYMee+wxtukBAIAxXNTko6ZNm6bvvvtOoaGhlFEAAGAUE1If5HA4FBYWpsjISMooAAAwjkLqY6ZMmaLbb79dffv2NR0FAABAElv2PmXOnDk6d+6cOnbsaDoKAABAPiakPuKbb75R586dFR4ezjY9AADwKExIfcDEiRO1atUqVaxYkTIKAAA8DoXU5o4cOSJJGjdunOEkAAAABaOQ2tikSZOUm5ur119/nckoAADwWJxDalNjx46Vn5+f6tatazoKAADAdVFIbcayLJ0+fVpPPvmkmjRpYjoOAADADVFIbcSyLI0ePVqVK1fWkCFDTMcBAAAoFM4htZFVq1YpNDSUMgoAALwKE1IbsCxL8+fPV69evfT000+bjgMAAOASJqRezrIsjRw5Uunp6QoKCjIdBwAAwGVMSL2YZVnKysrSfffdp27dupmOAwAAUCRMSL2UZVl67bXXtHHjRsooAADwahRSLzVp0iRVr15dbdu2NR0FAACgWNiy9zKWZelf//qXBg8erLCwMNNxAAAAio0JqRexLEuRkZHasWMHZRQAANgGE1Ivsm/fPt11110aOHCg6SgAAAAlhgmpF7AsS8OHD1dYWBhlFAAA2A6F1MNZlqWhQ4fq9ttvV/Xq1U3HAQAAKHFs2Xswp9OptLQ09evXTw0bNjQdBwAAoFQwIfVQTqdTgwcP1tq1aymjAADA1iikHio2NlYPPPCAunfvbjoKAABAqWLL3sM4nU699957GjJkiPz9+XkBAADYH43HgzidTg0YMEBhYWGUUQAA4DOYkHoIp9OpjIwMtWvXTk8//bTpOAAAAG7DGM4D5OXlqV+/fvr+++8powAAwOdQSD3AqFGj9Oijj6pFixamowAAALgdW/YG5eXlaePGjYqKilJoaKjpOAAAAEYwITUkLy9Pffr00fHjxymjAADApzEhNWT37t1q06aNunTpYjoKAACAUUxI3Sw3N1cvvviibrvtNsooAACAKKRuZVmWevXqpccee0wVK1Y0HQcAAMAjsGXvJrm5uUpLS9Mbb7yhevXqmY4DAADgMZiQuoHD4VDPnj31zTffUEYBAACuQCF1g5iYGD3zzDNq37696SgAAAAehy37UuRwODRjxgwNGzZMfn5+puMAAAB4JCakpSQnJ0fdu3fX3XffTRkFAAC4DiakpcDhcCgzM1N9+vRRq1atTMcBAADwaExIS1hOTo66deumo0ePUkYBAAAKgUJawl5++WX16NFD9913n+koAAAAXoEt+xKSnZ2tjRs3atq0aQoJCTEdBwAAwGswIS0B2dnZ6tatm3JzcymjAAAALmJCWgK2b9+uPn366IknnjAdBQAAwOswIS2GrKwsPf/882rUqBFlFAAAoIgopEWUm5urLl26qGvXripXrpzpOAAAAF6LLfsiuHDhgs6dO6fp06fr9ttvNx0HAADAqzEhdVFmZqY6d+6sn376iTIKAABQAiikLpo/f76GDBmiRx991HQUAAAAW2DLvpAyMjL03nvvaeTIkaajAAAA2AoT0kLIyMhQ586d1aJFC9NRAAAAbIcJ6Q1kZ2crKytLo0aNopACAACUAiak1/H777/r2Wef1blz5yijAAAApYRCeh2DBw/WiBEjVLduXdNRAAAAbIst+wKcP39eW7Zs0YIFCxQYGGg6DgAAgK0xIb3C+fPnFRERofLly1NGAQAA3IAJ6RW++eYbvfnmm5wzCgAA4CYU0v9KT0/XgAEDtGjRIgUFBZmOAwAA4DPYspeUlZWlTp066aWXXqKMAgAAuJnPT0jPnj2r7OxsLVy4UDVr1jQdBwAAwOf49IT07NmzioiI0LFjxyijAAAAhvh0IZ03b54mTpyoxo0bm44CAADgs3xyy/7MmTOaO3euRo4caToKAACAz/O5Cenp06cVERGhtm3bmo4CAAAA+diENDMzU7m5uZo6daoaNWpkOg4AAADkQxPS3377TU8//bTy8vIoowAAAB7EZwrpoEGD9M4776h69eqmowAAAOAStt+yT0tL044dO7RkyRKVKWP7pwsAAOB1bD0hPXXqlDp37qwaNWpQRgEAADyUbQupZVnavn27Zs6cqYYNG5qOAwAAgGuwZSE9efKkOnfurNatW1NGAQAAPJzt9rHPnz+vrl276r333lNAQIDpOAAAALgBWxXSlJQUBQQEaOnSpapatarpOAAAACiEIm3ZR0dHq06dOgoJCVHz5s21bdu2697+k08+Uf369RUSEqL77rtPiYmJRQp7PSdOnFC3bt105swZyigAAIAXcbmQJiQkKDIyUlFRUdqxY4caNWqktm3b6uTJkwXefvPmzerSpYt69+6tnTt3qkOHDurQoYO+//77Yoe/1MKFCzV79mzdfffdJfp5AQAAULpcLqTTp09X37591atXL91zzz2aO3euQkNDFRMTU+Dt3333XT3xxBMaNmyYGjRooPHjx6tx48aaNWtWscNfNGPGDL3xxhuqV69eiX1OAAAAuIdL55Dm5ORo+/btGjlyZP4xf39/tWrVSlu2bCnwPlu2bFFkZORlx9q2bauVK1de83Gys7OVnZ2d/3F6erokyeFwyOFw5P/+or/85S+XfQz7KGi9YT+ss29gne2PNfYN11rn4qy7S4U0LS1NeXl5V52jWbVqVe3du7fA+6SkpBR4+5SUlGs+zqRJkzR27Nirjq9bt06hoaGSpKysrPzjhw8fvu7ng/dLSkoyHQFuwDr7BtbZ/lhj33DlOmdmZhb5c3nkVfYjR468bKqanp6uWrVqqU2bNgoLC5P0nxe+P3nypNavX68nn3xSQUFBpuKiFDkcDiUlJal169YKDAw0HQelhHX2Dayz/bHGvuFa63xxR7soXCqklSpVUkBAgFJTUy87npqaqmrVqhV4n2rVqrl0e0kKDg5WcHDwVccDAwMve+Lh4eEKCQlRUFAQ//Bt7sq1hz2xzr6BdbY/1tg3XLnOxVlzly5qCgoKUpMmTZScnJx/zOl0Kjk5WS1atCjwPi1atLjs9tJ/RrzXuj0AAAB8i8tb9pGRkerZs6eaNm2qZs2aaebMmcrIyFCvXr0kST169FDNmjU1adIkSdLQoUP16KOPatq0aWrXrp3i4+P17bffav78+SX7TAAAAOCVXC6kEREROnXqlEaPHq2UlBTdf//9WrNmTf6FS0eOHJG///8OXh966CHFxsbqjTfe0KhRo3TXXXdp5cqVLr3HvGVZkq4+N8HhcCgzM1Pp6elsDdgUa+wbWGffwDrbH2vsG661zhd72sXe5go/qyj3crNff/1VtWrVMh0DAAAAN3D06FHdeuutLt3HKwqp0+nU8ePHVaFCBfn5+eUfv3j1/dGjR/Ovvoe9sMa+gXX2Dayz/bHGvuFa62xZls6fP68aNWpctlteGB75sk9X8vf3v27TDgsL4x++zbHGvoF19g2ss/2xxr6hoHW+6aabivS5XH7rUAAAAKAkUUgBAABglFcX0uDgYEVFRRX4IvqwB9bYN7DOvoF1tj/W2DeUxjp7xUVNAAAAsC+vnpACAADA+1FIAQAAYBSFFAAAAEZRSAEAAGAUhRQAAABGeXwhjY6OVp06dRQSEqLmzZtr27Zt1739J598ovr16yskJET33XefEhMT3ZQUReXKGi9YsECPPPKIKlasqIoVK6pVq1Y3/DcBz+Dq1/JF8fHx8vPzU4cOHUo3IIrN1TU+e/asBg0apOrVqys4OFh33303/2d7AVfXeebMmapXr57Kli2rWrVq6eWXX1ZWVpab0sJVGzduVPv27VWjRg35+flp5cqVN7zPhg0b1LhxYwUHB+vOO+/UokWLXH9gy4PFx8dbQUFBVkxMjPXDDz9Yffv2tcLDw63U1NQCb/+vf/3LCggIsKZMmWL9+OOP1htvvGEFBgZau3fvdnNyFJara9y1a1crOjra2rlzp7Vnzx7r+eeft2666Sbr119/dXNyuMLVdb7o0KFDVs2aNa1HHnnEevrpp90TFkXi6hpnZ2dbTZs2tf7yl79YmzZtsg4dOmRt2LDB2rVrl5uTwxWurvPSpUut4OBga+nSpdahQ4estWvXWtWrV7defvllNydHYSUmJlqvv/66tWLFCkuS9Y9//OO6tz948KAVGhpqRUZGWj/++KP1/vvvWwEBAdaaNWtcelyPLqTNmjWzBg0alP9xXl6eVaNGDWvSpEkF3r5Tp05Wu3btLjvWvHlzq3///qWaE0Xn6hpfKTc316pQoYL10UcflVZElICirHNubq710EMPWR988IHVs2dPCqmHc3WN58yZY9WtW9fKyclxV0SUAFfXedCgQVbLli0vOxYZGWk9/PDDpZoTJaMwhXT48OHWvffee9mxiIgIq23bti49lsdu2efk5Gj79u1q1apV/jF/f3+1atVKW7ZsKfA+W7Zsuez2ktS2bdtr3h5mFWWNr5SZmSmHw6Gbb765tGKimIq6zuPGjVOVKlXUu3dvd8REMRRljVetWqUWLVpo0KBBqlq1qho2bKi33npLeXl57ooNFxVlnR966CFt3749f1v/4MGDSkxM1F/+8he3ZEbpK6nuVaYkQ5WktLQ05eXlqWrVqpcdr1q1qvbu3VvgfVJSUgq8fUpKSqnlRNEVZY2v9Nprr6lGjRpXfTHAcxRlnTdt2qSFCxdq165dbkiI4irKGh88eFDr169Xt27dlJiYqP3792vgwIFyOByKiopyR2y4qCjr3LVrV6WlpemPf/yjLMtSbm6uBgwYoFGjRrkjMtzgWt0rPT1dFy5cUNmyZQv1eTx2QgrcyOTJkxUfH69//OMfCgkJMR0HJeT8+fPq3r27FixYoEqVKpmOg1LidDpVpUoVzZ8/X02aNFFERIRef/11zZ0713Q0lKANGzborbfe0uzZs7Vjxw6tWLFCq1ev1vjx401Hg4fx2AlppUqVFBAQoNTU1MuOp6amqlq1agXep1q1ai7dHmYVZY0veueddzR58mR98cUX+sMf/lCaMVFMrq7zgQMHdPjwYbVv3z7/mNPplCSVKVNGP/30k+64447SDQ2XFOVruXr16goMDFRAQED+sQYNGiglJUU5OTkKCgoq1cxwXVHW+c0331T37t3Vp08fSdJ9992njIwM9evXT6+//rr8/ZmLebtrda+wsLBCT0clD56QBgUFqUmTJkpOTs4/5nQ6lZycrBYtWhR4nxYtWlx2e0lKSkq65u1hVlHWWJKmTJmi8ePHa82aNWratKk7oqIYXF3n+vXra/fu3dq1a1f+r6eeekqPP/64du3apVq1arkzPgqhKF/LDz/8sPbv35//w4Yk7du3T9WrV6eMeqiirHNmZuZVpfPiDyH/uWYG3q7Eupdr11u5V3x8vBUcHGwtWrTI+vHHH61+/fpZ4eHhVkpKimVZltW9e3drxIgR+bf/17/+ZZUpU8Z65513rD179lhRUVG87JOHc3WNJ0+ebAUFBVnLly+3Tpw4kf/r/Pnzpp4CCsHVdb4SV9l7PlfX+MiRI1aFChWswYMHWz/99JP1+eefW1WqVLEmTJhg6imgEFxd56ioKKtChQpWXFycdfDgQWvdunXWHXfcYXXq1MnUU8ANnD9/3tq5c6e1c+dOS5I1ffp0a+fOndYvv/xiWZZljRgxwurevXv+7S++7NOwYcOsPXv2WNHR0fZ72SfLsqz333/fql27thUUFGQ1a9bM+vrrr/P/7NFHH7V69ux52e2XLVtm3X333VZQUJB17733WqtXr3ZzYrjKlTW+7bbbLElX/YqKinJ/cLjE1a/lS1FIvYOra7x582arefPmVnBwsFW3bl1r4sSJVm5urptTw1WurLPD4bDGjBlj3XHHHVZISIhVq1Yta+DAgdaZM2fcHxyF8uWXXxb4ffbiuvbs2dN69NFHr7rP/fffbwUFBVl169a1PvzwQ5cf18+ymJkDAADAHI89hxQAAAC+gUIKAAAAoyikAAAAMIpCCgAAAKMopAAAADCKQgoAAACjKKQAAAAwikIKAAAAoyikAAAAMIpCCgAAAKMopAAAADDq/wNnpU2C6DeTnwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "EVoSypRuGPJa",
        "outputId": "339dff9c-2d9f-41f3-85f4-8e1057fd403b"
      },
      "id": "EVoSypRuGPJa",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7b655dc77d60>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Interpret your result\n",
        "'''\n",
        "Due to really high number of epoch, we can see some abnormalities to the trajectory of\n",
        "loss function, we can see the validation loss suddenly going up at times but goes\n",
        "down. This shows overfitting and inconsistency of our model\n",
        "'''"
      ],
      "metadata": {
        "id": "4Ykjta62MNhB"
      },
      "id": "4Ykjta62MNhB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "intimate-factory",
      "metadata": {
        "id": "intimate-factory"
      },
      "source": [
        "#### Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "broad-appointment",
      "metadata": {
        "id": "broad-appointment"
      },
      "source": [
        "This activity made me undestood how creating a neural network link is done.\n",
        "With the help of given codes and dataset I was able to make my first neural network model and interpret its results. By not only looking at accuracy, I was given the proper idea on how well does a model perform especially with the loss functions. It also successfully shown how important getting the right amount of epoch for the training of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O1dPkjeXOIPP"
      },
      "id": "O1dPkjeXOIPP",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}